<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>控制好微服务之间的连接数量</title>
      <link href="/2020/12/06/micro-service-subsetting/"/>
      <url>/2020/12/06/micro-service-subsetting/</url>
      
        <content type="html"><![CDATA[<p>在微服务的架构模式下服务间通过长连接进行通信，通常情况下每个客户端实例都会与每个服务实例建立连接，如果服务实例数达到几千几万个那么相互之间建立的连接数将指数级上升，这样带来的坏处是：</p><ol><li>客户端的连接池里的连接数变多，消耗的资源增加</li><li>对应的服务端维护的长连接增多，尤其在一个连接一个线程的模式下消耗的资源很可观</li><li>长连接定期的健康检查消耗一定的CPU</li></ol><p>为了避免过多的资源消耗客户端可以选择服务集群实例的某个子集来建立连接，这样可有效的减少资源消耗。这个子集的选择方案必须满足以下几个条件：</p><ol><li>子集的大小要足够客户端使用</li><li>后端服务的连接数要负载均衡</li><li>能够在服务重启、滚动升级、客户端和服务端进行集群大小调整时持续均衡，避免大量连接的重建、迁移或者各服务实例的连接数产生较大的波动</li></ol><p>接下来看看Google是如何解决这个问题的</p><h2 id="随机选择"><a href="#随机选择" class="headerlink" title="随机选择"></a>随机选择</h2><p>在确定好子集的大小后采用完全随机的方式为每个客户端选择固定大小的子集，但经过实验这种方式负载的效果非常差，要想达到比较均匀的负载则子集大小至少要在75%，这对于大规模部署的集群来说是不可接受的。</p><p>个人认为之所以完全随机表现的不够好是因为连接的建立次数是有限的，只在服务初始化时建立。这就好比抛硬币正反面出现的概率各占50%，但是如果我们只抛四次有可能出现三次正面一次反面，只有抛的次数足够多才能无限接近概率。而每次连接的建立就好比一次抛硬币，如果连接建立的次数足够多那负载会比较均衡，扩大子集的规模一定程度上增加了抛硬币的次数，如果每次请求都新建连接那么负载的效果会比较好但每次新建连接的成本太高，所以该方法不可靠。</p><h2 id="确定性算法"><a href="#确定性算法" class="headerlink" title="确定性算法"></a>确定性算法</h2><p>随后Google抛弃了完全随机的算法，采用了一种相对确定的算法：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Subset</span><span class="params">(backends []<span class="keyword">string</span>, clientID, subsetSize <span class="keyword">int</span>)</span> []<span class="title">string</span></span> &#123;</span><br><span class="line"><span class="comment">// 计算一轮可满足几个客户端</span></span><br><span class="line">subsetCount := <span class="built_in">len</span>(backends)/subsetSize</span><br><span class="line"><span class="comment">// 计算本次客户端属于哪一轮，每一轮使用相同的随机列表</span></span><br><span class="line">round := clientID/subsetCount</span><br><span class="line"> r := rand.New(rand.NewSource(<span class="keyword">int64</span>(round)))</span><br><span class="line"> r.Shuffle(<span class="built_in">len</span>(backends), <span class="function"><span class="keyword">func</span><span class="params">(i, j <span class="keyword">int</span>)</span></span> &#123; backends[i], backends[j] = backends[j], backends[i] &#125;)</span><br><span class="line"> <span class="comment">// 计算客户端在本轮中的位置</span></span><br><span class="line"> subsetID := clientID % subsetCount</span><br><span class="line"> start := subsetID * subsetSize</span><br><span class="line"> <span class="keyword">return</span> backends[start: start+subsetSize]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>假设我们有13个后端实例，有10个客户端，子集的大小为3。那么每轮我们最多可以给4个客户端分配后端实例：<code>subsetCount = 12/3</code>，每一轮里一个后端实例只会被分配给一个且仅一个客户端，当客户端数量不够时有些实例没有被分配，但没有被分配的实例在每一轮中是随机的。总共有10个实例所以我们要分配三轮，每次产生的随机列表可能如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Round 0: [0, 6, 3, 5, 12, 1, 7, 11, 9, 2, 4, 8, 10]</span><br><span class="line"></span><br><span class="line">Round 1: [8, 11, 4, 12, 0, 5, 6, 10, 3, 2, 7, 9, 1]</span><br><span class="line"></span><br><span class="line">Round 2: [8, 3, 7, 2, 1, 4, 12, 9, 10, 6, 5, 0, 11]</span><br></pre></td></tr></table></figure><p>例如clientID为2每个client需要3个连接则roud=2/4=0，subsetID= 2%4 = 2，那分配给该客户端的实例为[7, 11, 9]。注意，在最后一轮中只有2个客户端需要分配，所以剩下的两组后端实例是没有被分配连接的。</p><p>只要clientID是连续的则分配到每个后端的连接数也是均匀的</p><h3 id="滚动更新及扩容"><a href="#滚动更新及扩容" class="headerlink" title="滚动更新及扩容"></a>滚动更新及扩容</h3><h4 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h4><p>某个client的下线不会影响其他client的连接分布，所以当某个client下线时只会导致某些backend实例连接数比其他实例少1</p><p>client集群扩容时clientID从后面依次递增按照上述算法的描述连接依然是均匀的</p><h4 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h4><p>与client情况类似，当某个server实例下线时会导致跟这台实例有连接的部分client连接发生变化，但因每个server随机分配给不同的client从整体来看计算结果不会有大变化</p><p>server集群扩容时相当于每一轮能满足的client数变多，round变小连接依然是均匀的</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>确定性算法为什么比完全随机要负载更均匀呢？确定性算法将客户端划分为多轮，在同一轮之中使用相同的随机序列使一轮之中连接的分配是均匀的，而每轮序列的不同又增加了一定的随机性</p><p>要使用该算法还需要考虑以下几个问题：</p><ol><li>clientID是需要连续的，这将增加外部依赖</li><li>如果clientID并非滚动升级那么极端情况下会挑选出一批client使得某台服务实例连接数为0</li><li>如果一次滚动升级的服务实例数较多囊括了某个client所选择的全部实例则会导致该client无连接可用</li></ol><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p>[1] <a href="https://sre.google/sre-book/load-balancing-datacenter/" target="_blank" rel="noopener">https://sre.google/sre-book/load-balancing-datacenter/</a></p>]]></content>
      
      
      <categories>
          
          <category> 系统设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Architecture &amp; Design </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微服务中的服务过载</title>
      <link href="/2020/12/05/micro-service-overload/"/>
      <url>/2020/12/05/micro-service-overload/</url>
      
        <content type="html"><![CDATA[<p>在微服务中某个服务的请求突然升高会造成服务的过载，服务一旦过载进入异常状态之后会对服务的上下游都造成一定的影响。当服务出现过载的时候常见的处理方法是调用方进行熔断，服务方进行降级、流量抛弃等。</p><h2 id="资源耗尽"><a href="#资源耗尽" class="headerlink" title="资源耗尽"></a>资源耗尽</h2><p>假设一个服务最多能处理1000QPS的请求，当QPS超过1000之后随着请求量的增多会发生什么：</p><ol><li>CPU不足以应对这么多的请求则所有请求的响应时间变慢</li><li>响应时间变慢进而导致积压的in-flight请求变多</li><li>in-flight请求增多会导致内存、活跃线程数(在每个请求一个线程的模式下)、文件描述符等资源的消耗增加</li><li>请求队列填满，所有请求都要排队进一步增加响应时间同时会使用更多的内存</li><li>如果跑的是带有垃圾回收的runtime程序内存使用率上升会导致GC触发的次数增多，进而导致CPU资源进一步减少</li><li>内存的过多消耗会导致内存中的缓存命中率降低，未命中缓存的请求发送给下游获取数据进而导致下游服务的连锁反应</li></ol><p>当发生过载的情况时往往会伴随着高延迟、高错误率或者低质量的响应发生</p><h2 id="应对过载"><a href="#应对过载" class="headerlink" title="应对过载"></a>应对过载</h2><h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><p>当服务发生过载错误率升高的时候对于调用方可以进行熔断容错处理，常见的是Netflix的Hystrix框架。当检测到错误率达到一定阈值之后调用方进行熔断，不再向服务方发送请求同时要对此进行容错处理，过一段时间之后再尝试向服务方发送一部分流量探测服务方是否正常，如果正常则恢复请求，如果不正常则继续熔断。</p><p>该熔断策略不好之处在于“一刀切”，熔断之后所有请求都不发送给服务方，调用方不能及时的感知到服务方的状态，动态调整的能力较弱。Google提出的一种自适应的机制可动态调整请求的发送量，客户端通过滑动窗口记录过去两分钟的请求数量(requests)和被服务端正常接受的请求数量(accepts)。</p><p>正常情况下这两个数值是相等的，当后端开始出现请求超时、返回错误等拒绝一部分请求时，accepts的值将降低，直到超过<code>requests = K*accepts</code>时客户端开始自行节流熔断，请求将以一定的概率被客户端直接拒绝，概率计算如下：$$ drop=max(0, \frac {requests -K * accetps} {requests+1})$$ K通常设置为2，开始时requests=accetps，drop值为0。当后端开始拒绝服务导致<code>requests &gt; K*accepts</code>此时客户端开始拒绝请求，requests会继续上升导致拒绝的概率变大。当后端服务恢复之后accepts值增大<br>且由于K的存在K*accepts的增速比requests快因此会逐渐降低drop值最终恢复正常的状态。</p><h3 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h3><p>服务端应对过载常见的做法有以下几种：</p><ol><li>流量抛弃，当请求速率超过线程处理速率时会产生排队，此时线程池和队列都会饱和，当出现队列饱和时可以尽早的拒绝请求。对于一些排队很久的请求可以不处理因为客户端可能已经发起重试了，对这种请求进行处理没有意义。如果请求有优先级可对某些低优先级的请求进行拒绝，进一步降低资源消耗</li><li>降级，通过降低响应的质量来减少资源的消耗，例如：推荐系统可以减少召回数量或者直接返回静态数据等</li><li>传递和判断请求的截止时间，在多层级的RPC请求中传递截止时间，如果已经超过截止时间则不再向下传递请求</li><li>为预防过载服务端针对不同的客户端设置一定配额的限流，防止某个客户端的流量突增导致整个服务不可用进而影响其他客户端</li></ol><h3 id="小心负载均衡和重试"><a href="#小心负载均衡和重试" class="headerlink" title="小心负载均衡和重试"></a>小心负载均衡和重试</h3><p>当某个集群实例发生过载而崩溃时负载均衡会把请求转发到其他的集群，这会导致其他的集群也相继过载从而导致整个服务过载，如同滚雪球一样整个服务进入循环崩溃且比较难以恢复，一旦某个实例恢复就会被流量立即打垮。</p><p>对于重试应注意以下几点：</p><ol><li>区分可重试与不可重试的错误处理，对于服务端明确返回的不可重试错误不应进行重试</li><li>限制请求重试次数，不能无限重试</li><li>客户端设置全局重试次数</li><li>在较长的调用链路中避免多级重试，进而放大重试次数</li><li>使用随机的、指数避让式的重试，避免同一时刻发起大量重试</li></ol><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>服务一旦出现滚雪球式的过载往往对整个系统造成较大影响，需要在平时把容量估算、水位监控、限流、降级等工作做好，才能防患未然。</p>]]></content>
      
      
      <categories>
          
          <category> 系统设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Architecture &amp; Design </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes使用DevicePlugin 管理 GPU</title>
      <link href="/2020/02/01/k8s-with-gpu/"/>
      <url>/2020/02/01/k8s-with-gpu/</url>
      
        <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>近几年随着大量数据的积累和算力的发展使AI有了更多的落地场景并再次成为人们口中的“明日之星”，这其中云计算是其背后的一个重要推手。而云计算领域Kubernetes作为云OS的事实标准也成为了关注的焦点，云原生和AI的快速发展使得用Kubernetes管理GPU的诉求也越来越多，使用Kubernetes管理GPU有什么好处呢？</p><p>首先，使用k8s管理GPU可以加速部署。使用容器技术可以将部署的过程固化以复用，减少准备部署环境所耗费的时间，目前许多AI框架都提供相关的容器镜像。</p><p>其次，提升资源使用率。当公司的GPU资源达到一定数量后通过k8s统一资源调度将GPU资源池化，进行分时复用，使得GPU可以用时申请，用完释放提升GPU使用效率降低成本。</p><p>最后，通过容器化可以将GPU资源进行隔离，有效的防止各任务之间的相互影响，提升系统的稳定性。</p><h3 id="Docker下如何使用GPU"><a href="#Docker下如何使用GPU" class="headerlink" title="Docker下如何使用GPU"></a>Docker下如何使用GPU</h3><p>首先我们看一下如何在Docker容器里使用GPU，要在Docker容器里使用GPU主要有两点：</p><ol><li>GPU Device，在容器里能够找到 GPU设备，比如：/dev/nvidia0</li><li>GPU驱动，在容器里能够找到对应的GPU驱动目录，比如：/usr/local/nvidia/*</li></ol><p>以上两点可以通过配置docker启动参数来实现，GPU设备路径可以通过容器启动时Devices参数来配置，设备驱动目录可以通过容器启动时Volume参数来配置。</p><p>准备相关的Docker镜像有两种方式：</p><ul><li>下载官方镜像</li></ul><p>比如TensorFlow、PyTorch、Caffe等均提供了官方的镜像可在docker.hub上下载，简单便捷。</p><ul><li>基于Nvidia CUDA基础镜像进行构建</li></ul><p>如果因官方镜像无法满足需求而对其进行了改动那么就需要自己来构建镜像，在这种情况下最好是以NVIDIA 官方镜像为基础镜像来进行构建。例如PyTorch就是以nvidia cuda为基础镜像来构建的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">FROM nvidia/cuda:10.1-cudnn7-devel-ubuntu16.04</span><br><span class="line">ARG PYTHON_VERSION=3.8</span><br><span class="line">ARG WITH_TORCHVISION=1</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \</span><br><span class="line">         build-essential \</span><br><span class="line">         cmake \</span><br><span class="line">         git \</span><br><span class="line">         curl \</span><br><span class="line">         ca-certificates \</span><br><span class="line">         libjpeg-dev \</span><br><span class="line">         libpng-dev &amp;&amp; \</span><br><span class="line">     rm -rf /var/lib/apt/lists/*</span><br><span class="line">     ……</span><br></pre></td></tr></table></figure><h3 id="Nvidia-docker原理"><a href="#Nvidia-docker原理" class="headerlink" title="Nvidia-docker原理"></a>Nvidia-docker原理</h3><p>以上我们了解了在Docker中使用GPU的关键点，与在物理机中直接使用GPU的区别如下图：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/docker-gpu.jpg" alt="gpu in docker" title>                </div>                <div class="image-caption">gpu in docker</div>            </figure><p>要在物理机里运行一个AI程序，其运行环境如图左侧所示，首先底层是GPU的驱动，再往上是cuda lib，在cuda之上是基于TensorFlow、PyTorch等框架的应用，通常情况下AI应用框架对cuda库的版本有要求，如果AI应用框架版本变化后对应的cuda版本也要跟着变化，二者耦合较紧，而底层的GPU驱动则不会有大的变化。</p><p>如上图右侧所示，NVIDIA GPU容器化的方案是将GPU驱动安装到宿主机，将cuda lib及TensorFlow、PyTorch等打到镜像中，使用该镜像运行容器时将GPU驱动映射到容器中，这样就可以在一台宿主机上运行不同版本的cuda及对应的应用容器。</p><p>大家习惯使用 Nvidia-docker 来运行 GPU 容器，而 Nvidia-docker 的实际工作就是来自动化将宿主机的设备和 Nvidia 驱动库映射到容器中。</p><h3 id="k8s-Device-Plugin原理"><a href="#k8s-Device-Plugin原理" class="headerlink" title="k8s Device Plugin原理"></a>k8s Device Plugin原理</h3><p>当使用K8S时我们期望在pod的对象里声明需要的GPU资源后k8s在调度时即可为我们分配所需的GPU资源，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: cuda-vector-add</span><br><span class="line">spec:</span><br><span class="line">  restartPolicy: OnFailure</span><br><span class="line">  containers:</span><br><span class="line">    - name: cuda-vector-add</span><br><span class="line">      image: &quot;k8s.gcr.io/cuda-vector-add:v0.1&quot;</span><br><span class="line">      resources:</span><br><span class="line">        limits:</span><br><span class="line">          nvidia.com/gpu: 1</span><br></pre></td></tr></table></figure><p>在上述 Pod 的 limits 字段里，这个资源的名称是nvidia.com/gpu，它的值是 1。即这个 Pod 声明了自己要使用一个 NVIDIA 类型的 GPU。这当中使用了一种叫作 Extended Resource特殊字段来传递所需GPU信息。</p><p>为了能够让kube-scheduler知道每台宿主机GPU资源可用量就需要宿主机能够向API Server汇报自己的该类型资源的可用量，每种资源的可用量实际表现为Node对象Status字段的内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Node</span><br><span class="line">...</span><br><span class="line">Status:</span><br><span class="line">  Capacity:</span><br><span class="line">   cpu:  2</span><br><span class="line">   memory:  2049008Ki</span><br><span class="line">   nvidia.com/gpu: 1</span><br></pre></td></tr></table></figure><p>那么如何为Node对象添加GPU资源的可用量呢？有两种方式：</p><ul><li>Extend Resources 属于 Node-level 的 api，完全可以独立于 Device Plugin 使用，只需通过一个 PACTH API 对 Node 对象进行 status 部分更新即可。这样在 Kubernetes 调度器中就能够记录这个节点的 GPU 类型，它所对应的资源数量是 1。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ curl --header &quot;Content-Type: application/json-patch+json&quot; \</span><br><span class="line">--request PATCH \</span><br><span class="line">--data &apos;[&#123;&quot;op&quot;: &quot;add&quot;, &quot;path&quot;: &quot;/status/capacity/nvidia.com/gpu&quot;, &quot;value&quot;: &quot;1&quot;&#125;]&apos; \</span><br><span class="line">http://localhost:8001/api/v1/nodes/&lt;your-node-name&gt;/status</span><br></pre></td></tr></table></figure><ul><li>使用Device Plugin，在k8s中所有硬件资源的管理都是通过Deveice Plugin插件来完成的，这当中当然也包括对Extended Resource汇报的逻辑，如下图所示：</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/k8s-gpu.jpg" alt="gpu in k8s" title>                </div>                <div class="image-caption">gpu in k8s</div>            </figure><p>Device Plugin的工作主要分为两部分：资源上报和资源使用时的调度。</p><h4 id="资源上报"><a href="#资源上报" class="headerlink" title="资源上报"></a>资源上报</h4><p>首先Device Plugin通过GRPC与kubelet的Device Plugin Manager进行通信并将自己注册给k8s，让kubelet知道三件事：我是谁，即该Device Plugin管理的设备是什么；我在哪，即Device Plugin所监听的socket所在位置，kubelet通过此来进行调用Device Plugin；交互协议，即API版本号；</p><p>然后Device Plugin启动一个GRPC Server让kubelet来访问。</p><p>第三步，kubelet与Device Plugin建立一个 ListAndWatch的长连接，用来发现设备 ID 以及设备的健康状态，Device Plugin定期向 kubelet 汇报该 Node 上 GPU 的列表。</p><p>第四步，kubelet 会将这些设备暴露到 Node 节点的状态中，在kubelet向 api-server发送心跳里以 Extended Resource 的方式，加上这些 GPU 的数量，比如nvidia.com/gpu=3。后续调度器可以根据这些信息进行调度。</p><p>kubelet 在向 api-server 进行汇报的时候，只会汇报该 GPU 对应的数量。而 kubelet 自身的 Device Plugin Manager 会对这个 GPU 的 ID 列表进行保存，并用来具体的设备分配。而对于 Kubernetes scheduler来说，它不知道这个 GPU 的 ID 列表，它只知道 GPU 的数量。</p><h4 id="资源调度使用"><a href="#资源调度使用" class="headerlink" title="资源调度使用"></a>资源调度使用</h4><p>当某个pod要使用GPU资源时只需要在api对象里声明所需资源的数量，接下来scheduler会在自己缓存里找到能够满足要求的node，然后将其GPU减掉相应的数量并完成node与pod的绑定。</p><p>当kubelet发现该pod被分配到自己的节点上时会从自己持有的GPU列表里为该pod分配一个GPU，此时kubelet向Device Plugin发起Allocate()请求，参数为分配给该pod的设备id。当 Device Plugin 收到 Allocate 请求之后根据 kubelet 传递过来的设备 ID找到这些设备对应的设备路径和驱动目录。这些信息正是 Device Plugin 周期性的从本机查询到的。比如，在 NVIDIA Device Plugin 的实现里它会定期访问 nvidia-docker 插件，从而获取到本机的 GPU 信息。</p><p>被分配 的GPU 对应的设备路径和驱动目录信息被返回给 kubelet 之后就完成了为一个容器分配 GPU 的操作。接下来，kubelet 会把这些信息追加在创建该容器所对应的 CRI（Container Runtime Interface）请求当中。当这个 CRI 请求发给 Docker 之后，Docker 为你创建出来的容器里就会出现这个 GPU 设备，并把它所需要的驱动目录挂载进去。这个过程与上面提到的通过docker启动参数挂载设备和驱动原理是一致的。</p><p>至此通过k8s为一个pod分配GPU的过程就完成了。</p><h3 id="Device-Pulgin的不足"><a href="#Device-Pulgin的不足" class="headerlink" title="Device Pulgin的不足"></a>Device Pulgin的不足</h3><p>虽然通过Device Plugin可以让k8s在调度时一定程度上满足Extended Resource的调度，但也只是基于数量调度，如果设备是异构的、硬件的属性比较复杂并且pod也关心硬件的某些属性，那么不能简单的通过数量来进行调度此时这个方案就不能满足需求，另外对于资源分配时quota限制粒度也较大。</p><p>针对以上问题目前有一种方案通过node label和node selector来解决该问题，但这种方式也只能通过将同一种类型的硬件挂载到同一个节点来解决对某种类型资源的分配，不能使其他更详细资源属性参与到调度中，比如：某个节点挂载了显存不同的NVIDIA Tesla K80，某个应用想要使用显存大于10G的GPU。</p><p>另外一种方案是通过CRD(CustomResourceDefinition)以及Scheduler Extender 机制来满足异构设备调度的需求，但多多少少都会涉及到改动k8s源码。</p><p>因此目前为止官方提供的Device Plugin可以用来进行设备的管理和资源分配但在调度方面由于向scheduler暴露的设备属性信息太少还无法满足复杂的调度需求。</p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> k8s </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于Kubernetes的思考</title>
      <link href="/2019/06/02/k8s-thinking/"/>
      <url>/2019/06/02/k8s-thinking/</url>
      
        <content type="html"><![CDATA[<p>随着这些年的发展Kubernetes已经成为容器编排调度的事实标准，它的出现将改变软件部署交付的方式而它本身的设计理念也十分值得深思和借鉴。</p><h3 id="声明式API和编程范式"><a href="#声明式API和编程范式" class="headerlink" title="声明式API和编程范式"></a>声明式API和编程范式</h3><p>当你开始尝试在k8s中部署一个pod时，它所给你带来的最直接的感受就是k8s的API是声明式而不是命令式的。如果是命令式的API，那么你就需要通过API来告诉k8s具体要执行的动作是什么，比如启动或停止容器。而声明式的API只需要我们使用声明式的配置，比如：json、yaml等，来指定我们想要的目标状态，同时k8s会获取当前资源状态，当目标状态和当前状态不一致时k8s会不断的调整资源的状态直到使其达到目标状态。这样做的好处是什么呢？</p><p>首先是可以简化API，通过声明式的API只需提供合适的Spec定义即可，用户通过修改Spec来通知系统他所期望的状态是什么。如果是命令式API则需要向用户暴露几十上百个接口用以应对不同资源的不同的操作，用户使用起来也会觉得头大。另外k8s提供一些用于特殊场景的api，比如：扩缩容、修改镜像等，但其底层依然是对Spec的修改。</p><p>再者是稳定，声明式和命令式分别代表着两种不同的动作触发模式：水平触发和边缘触发。举个例子：<br>比如一个开关，我们进行了开、关、开三次操作，对于命令式API这意味着要发三次命令，如果网络出现了问题最后一次开的命令丢失了则这个开关会一直处于错误的状态，所以如果是边缘触发则需要配合补偿机制。如果是声明式API即使网络出了问题系统停留在错误的状态，但是当网络恢复之后系统依然可以调整到所期望的状态。设想我们在对系统做扩缩容的操作时，如果每次告诉k8s要增加或减少一个实例，一但这个代表具体操作的命令发生了丢失那么系统的状态就乱了，更好的做法是告诉k8s我们所期望的实例个数是多少，即使这期间网络发生了问题或者控制器出了问题，等到网络或者出问题的组件恢复后k8s依然可以为我们把实例调整到我们所期望的个数。</p><p>第三是便于处理多写的操作，k8s API的客户端有多种，以kubectl为例它除了提供kubectl create、kubectl replace等操作外还提供了kubectl apply，kubectl apply 与 kubectl create、kubectl replace的不同之处在于前者是声明式的操作而后两者是命令式的操作。以Kubectl replace为例，它是使用新的yaml文件里的api对象来替换旧的对象而kubectl apply则是对原有的对象做patch操作。二者最大的区别是对于声明式请求一次可以处理多个写操作并且具备merge能力。Service Mesh是最近比较火的一个概念，其中一个代表型的项目叫Istio，它最主要的一个组件是Envoy。为了实现服务发现与治理的功能Istio需要为每个pod里安装一个Envoy容器，这过程中Istio通过k8s的Dynamic Admission Control功能所做的事情就是对新建的pod声明对象patch一个Envoy的容器配置，这样随后创建的pod中就注入了一个Envoy容器。</p><p>在声明式API基础上所形成的Kubernetes编程范式即：使用控制器监听Kubernetes里API对象的状态变化，为不同的事件注册相应的操作函数，当其状态发生变化时执行对应的函数进行相应的操作进而完成用户业务逻辑的编写。</p><h3 id="list-watch机制"><a href="#list-watch机制" class="headerlink" title="list-watch机制"></a>list-watch机制</h3><p>我们知道k8s中API对象的状态都存储在etcd当中，而所有跟etcd的交互都必须通过api server来进行。之前我们提到在声明式API的基础上控制器以及调度器等都需要监听API对象状态的变化，当API对象声明的状态发生变化后需要作出相应的动作。在这种需求下一般会引入MQ，而k8s为了降低系统本身对其他组件的依赖并没有使用任何的消息中间件也没有使用轮询的方式而是提供了一种list-watch的机制。该机制的list部分主要通过提供list接口来实现对api对象及其状态的查询，watch部分则是通过提供watch api来实现对资源变更事件的监听。watch实现的关键是http1.1中的<a href="https://zh.wikipedia.org/zh-hans/%E5%88%86%E5%9D%97%E4%BC%A0%E8%BE%93%E7%BC%96%E7%A0%81" target="_blank" rel="noopener">Chunked transfer encoding(分块传输编码)</a></p><p>list和watch相互配合，通过list获取全量数据，通过watch可以获取增量数据。当某个时间点watch连接中断后会发生消息丢失的问题而此时通过调用list接口则可以解决该问题保证消息的可靠性。通过watch可以在保证消息实时性的同时降低系统的开销，同时事件中的resourceVersion标签可以保证消息的顺序性，当客户端并发处理同一个资源的事件时，可以对比 resourceVersion来保证资源最终的状态和最新的事件所期望的状态保持一致。</p><p>通过list-watch机制API Server相当于充当了消息总线的角色，k8s中的控制器、调度器、kubelet等其他组件只需通过该机制监听自己所关心的对象状态即可，相互之间并不知道彼此的存在。比如pod的调度，调度器通过监听发现有新的pod创建出来且尚未对其调度，调度器开始执行自己的调度逻辑为该pod选择node节点，然后调用API Server接口把要绑定的node信息写入pod对象的Node字段中即完成了调度。同时node节点上的kubelet组件通过订阅事件发现有一个pod调度到该节点上了，那么它就会通过API Server获取该pod对象的配置信息，根据pod的Spec完成部署。整个过程中kubelet并不知道scheduler的存在，通过这种机制对各组件的依赖关系进行了解耦。</p><h3 id="系统抽象"><a href="#系统抽象" class="headerlink" title="系统抽象"></a>系统抽象</h3><p>在系统抽象方面尤其在存储方面的抽象Kubernetes做的很精彩。</p><p>首先通过卷(Volume)来抽象出存储方式，卷描述的是底层的存储能力。但是底层的文件存储系统(NFS、Ceph等)一般都有相关人员来负责，如果仅仅有Volume那么k8s的使用者每次部署pod的时候需要指定存储系统的相关配置，对开发人员不友好。</p><p>于是k8s抽象出持久卷PV和和持久卷声明PVC的概念，系统管理员可以先配置PV映射到底层的存储系统，用户只需要创建PVC来关联PV，然后在创建Pod的时候引用PVC即可。PVC并不关注底层存储的具体细节，只关注容量需求和操作权限。PV这层抽象描述的是底层存储系统能提供出来的卷的资源，PVC这层抽象描述的是用户希望为Pod申请的存储资源请求。</p><p>但是总是需要系统管理员先创建好PV还是不方便，于是k8s又提供了StorageClass这层抽象，通过把PVC不直接关联到PV而是联到StorageClass，由StorageClass根据PVC的需求描述来动态创建PV并完成PVC与PV的绑定(包括动态绑定和延迟绑定)。下图引自《Kubernetes in Action》</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/k8s-volume.png" alt="The complete picture of dynamic provisioning of PersistentVolumes" title>                </div>                <div class="image-caption">The complete picture of dynamic provisioning of PersistentVolumes</div>            </figure><h3 id="系统扩展"><a href="#系统扩展" class="headerlink" title="系统扩展"></a>系统扩展</h3><p>为了方便系统的扩展k8s提供了许多interface，比如CNI(Container Network Interface),CRI(Container Runtime Interface),CSI(Container Storage Interface)等。</p><p>除此之外k8s还提供了CRD(Custom Resource Definition),CR(Custom Resuorce)和Operator机制方便用户自定义资源以及编写对应的Operator。所谓的Operator可以理解为操作用户自定义资源的controller，社区提供的kube-builder和coreos提供的operator-framework可以帮助我们生成Operator的基础代码：初始化 Kubernetes客户端，建立Watch等。Operator甚至可以将应用集群当做一种资源，通过Operator可以完成集群的部署、高可用、故障恢复等，将运维经验代码化。比如：通过<a href="https://github.com/coreos/etcd-operator" target="_blank" rel="noopener">etcd-opeator</a>完成etcd集群的搭建。</p><h3 id="面向k8s交付，甚至面向Operator交付"><a href="#面向k8s交付，甚至面向Operator交付" class="headerlink" title="面向k8s交付，甚至面向Operator交付"></a>面向k8s交付，甚至面向Operator交付</h3><p>随着技术的发展软件的交付方式也发生了几次迭代：</p><ul><li>交付源代码：最初根据客户现场的环境不同需要交付方带着源代码到客户现场进行现场编译、部署、运行</li><li>交付可执行文件：后来java提出了“Build once, Run everywhere”，以及Go交叉编译出的可执行二进制文件，使得我们可以直接交付可执行文件，但对于系统底层的依赖依然解决的不彻底</li><li>交付镜像：近几年Docker的盛行解决了因开发环境与运行环境的差异所带来的问题，提升了单体软件的交付效率，对于包含多个组件的复杂系统交付(比如：包含服务发现、负载均衡等组件的系统)仍然显得力不从心</li></ul><p>Kubernetes的出现解决了早些年PaaS系统想解决但没有解决好的问题，如果将来某一天客户现场的OS都是Kubernetes(听说工商银行一次招标的标书中明确写着要求Kubernetes技术栈)，对于ToB项目的交付是不是可以带着一堆镜像和yaml文件就可以完成交付，而这些yaml文件中很可能会包含用户自定义的资源和Operator。对于ToC的业务，目前大部分创业公司会选择将自己的服务跑在云上而不再是自己买服务器建IDC。目前来看没有哪一家云计算服务厂商是不支持k8s的，那么这就意味着如果你的服务是可以跑在k8s上的只需要很小的代价即可完成在不同的云厂商之间的切换。</p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>云原生（Cloud Native）这个词随着CNCF的崛起也变得火热起来，什么是云原生让人很难说清楚，但比较明确的是目前国内的云服务厂商开始尝试在正确合理的使用Kubernetes基础上构建新的PaaS平台，同时越来越多的公司开始借此机会来完成自身基础技术体系的转型升级，而在这当中Kubernetes也将会发挥越来越重要的作用。</p><p>最后，how about runing kubernetes on kubernetes</p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> k8s </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go 中的nil channel</title>
      <link href="/2018/05/19/nil-channel/"/>
      <url>/2018/05/19/nil-channel/</url>
      
        <content type="html"><![CDATA[<h3 id="从一个问题开始"><a href="#从一个问题开始" class="headerlink" title="从一个问题开始"></a>从一个问题开始</h3><p>要求写一个函数，该函数将从两个channel里获取值并将获取到的值放到一个新的channel里，最后将新的channel返回:<br><code>func merge(a,b &lt;-chan int) &lt;-chan int</code></p><h3 id="一种思路"><a href="#一种思路" class="headerlink" title="一种思路"></a>一种思路</h3><p>首先有一个生成a,b这两个channel的函数：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getChan</span><span class="params">(vs []<span class="keyword">int</span>)</span> &lt;-<span class="title">chan</span> <span class="title">int</span></span> &#123;</span><br><span class="line">c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">for</span> _, v := <span class="keyword">range</span> vs&#123;</span><br><span class="line">c &lt;- v</span><br><span class="line">time.Sleep(time.Duration(rand.Intn(<span class="number">1000</span>)) * time.Millisecond)</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">close</span>(c)</span><br><span class="line">&#125;()</span><br><span class="line"><span class="keyword">return</span> c</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接着来实现merge函数，需要注意的是何时关闭channel：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">merge</span><span class="params">(a, b &lt;-<span class="keyword">chan</span> <span class="keyword">int</span>)</span> &lt;-<span class="title">chan</span> <span class="title">int</span></span> &#123;</span><br><span class="line">c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">defer</span> <span class="built_in">close</span>(c)</span><br><span class="line">aClosed, bClosed := <span class="literal">false</span>, <span class="literal">false</span></span><br><span class="line"><span class="keyword">for</span> !aClosed || !bClosed &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> v, ok := &lt;-a:</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line">fmt.Println(<span class="string">"channel a is closed"</span>)</span><br><span class="line">aClosed = <span class="literal">true</span></span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line">c&lt;-v</span><br><span class="line"><span class="keyword">case</span> v, ok := &lt;-b:</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line">fmt.Println(<span class="string">"channel b is closed"</span>)</span><br><span class="line">bClosed = <span class="literal">true</span></span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line">c&lt;-v</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line"><span class="keyword">return</span> c</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>跑一下这个代码看到以下的结果：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"></span><br><span class="line">a := getChan([]<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>&#125;)</span><br><span class="line">b := getChan([]<span class="keyword">int</span>&#123;<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>&#125;)</span><br><span class="line">c := merge(a, b)</span><br><span class="line"><span class="keyword">for</span> v := <span class="keyword">range</span> c &#123;</span><br><span class="line">fmt.Println(v)</span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(<span class="string">"done"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;go run main.go</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">channel a is closed</span><br><span class="line">channel a is closed</span><br><span class="line">channel a is closed</span><br><span class="line">channel a is closed</span><br><span class="line">...</span><br><span class="line">channel b is closed</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>然后会发现在<code>channel b close</code>之前输出了好多<code>channel a is closed</code>，原因是在两个channel都没有数据到来前select语句会阻塞在那里，但是一旦channel a 关闭了select则不会阻塞所以在channel b 数据到来之前select会一直选择channel a，此时进入了忙等待的状态。</p><h3 id="另一种思路"><a href="#另一种思路" class="headerlink" title="另一种思路"></a>另一种思路</h3><p>如果一个channel close掉了，那么我们将这个channel置为nil看看效果会怎样。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">merge</span><span class="params">(a, b &lt;-<span class="keyword">chan</span> <span class="keyword">int</span>)</span> &lt;-<span class="title">chan</span> <span class="title">int</span></span> &#123;</span><br><span class="line">c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">defer</span> <span class="built_in">close</span>(c)</span><br><span class="line"><span class="keyword">for</span> a!=<span class="literal">nil</span> || b!=<span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> v, ok := &lt;-a:</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line">fmt.Println(<span class="string">"channel a is closed"</span>)</span><br><span class="line">a = <span class="literal">nil</span></span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line">c &lt;- v</span><br><span class="line"><span class="keyword">case</span> v, ok := &lt;-b:</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line">fmt.Println(<span class="string">"channel b is closed"</span>)</span><br><span class="line">b = <span class="literal">nil</span></span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line">c &lt;- v</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line"><span class="keyword">return</span> c</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行main.go得到如下结果：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line"><span class="number">6</span></span><br><span class="line"><span class="number">7</span></span><br><span class="line"><span class="number">8</span></span><br><span class="line">channel a is closed</span><br><span class="line">channel b is closed</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>这一次没有再出现疯狂输出<code>channel a is closed</code>，原因是一个值为nil的channel有以下特性：</p><ul><li>&lt;-c 从channel中获取值的操作将一直被block</li><li>-&gt;c 向channel中放入值的操作将一直被block</li><li>close(c)关闭一个值为nil的channel将产生panic</li></ul><p>最后留一个问题，如何merge N 个channel，N是一个动态传入的参数。</p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>会话管理(Dialog Management)</title>
      <link href="/2018/04/01/DM/"/>
      <url>/2018/04/01/DM/</url>
      
        <content type="html"><![CDATA[<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>会话管理(以下简称DM)是人机多轮对话系统的核心部分。它主要的功能包括：</p><ul><li>对话状态维护(dialog state tracking, DST)<ul><li>维护更新会话状态。当前的会话状态依赖于之前的系统状态和之前的系统响应以及当前时刻的用户输入。</li></ul></li><li>产生决策(dialog strategy)<ul><li>根据DST中会话状态做出系统决策，决定下一步做什么。</li></ul></li><li>与其他后端系统交互 </li></ul><p>下图是一个经典的对话系统结构图，可以看到DM的位置，在NLU(Linguistic Analysis)之后在NLG(Text Generation)之前，简单来说DM控制着人机对话的过程和走向，根据对话上下文信息来决定此刻系统对用户的输入做出的响应。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/DM.svg" alt="Architecture of dialog system" title>                </div>                <div class="image-caption">Architecture of dialog system</div>            </figure><p>在展开描述DM之前先简单说一下NLU(Natural Language Understanding)。NLU主要的工作是分析用户说的话并确定这句话的意图(Intent)是什么。同一个意图通常会有多种表达方式，例如：“今天天气怎么样”、“今天会下雨吗？”、“我想查询一下天气”等等，这些都是在表达同一个意图：查询天气。意图不应该关心句子的某些具体细节，例如：“告诉我去车站怎么走”与“怎么去最近的酒店”所表达的意图都是查询路线，不同的是二者的目的地不同，所以意图应该跟这句话所触发的Action相对应。而至于具体的细节，例如目的地，被当做意图的slot来填充。</p><h2 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h2><p>DM的实现方式有多种，每一种都有自己的优势和劣势，下面简单介绍几种。</p><h3 id="Structure-based-Approaches"><a href="#Structure-based-Approaches" class="headerlink" title="Structure-based Approaches"></a>Structure-based Approaches</h3><p>本质上是一种关键词匹配的做法，例如ELIZA和AIML（人工智能标记语言），通常是通过捕捉用户输入语句的关键词和短语来进行回应，通过增加变量并按topic来组织规则等方法能够一定程度上支持简单的多轮对话。</p><h3 id="FSM-based-Approaches"><a href="#FSM-based-Approaches" class="headerlink" title="FSM-based Approaches"></a>FSM-based Approaches</h3><p>这种方法通常将对话建模成一棵树或者有限状态机。系统根据用户的输入在有限的状态集合内进行状态跳转并选择下一步输出，如果从开始节点走到了终止节点则任务就完成了。</p><p>该方法的特点是：</p><ul><li>提前设定好对话流程并由系统主导</li><li>建模简单，适用于简单任务</li><li>将用户的回答限定在有限的集合内</li><li>表达能力有限，灵活性不高</li></ul><h3 id="Frame-based-Approaches"><a href="#Frame-based-Approaches" class="headerlink" title="Frame-based Approaches"></a>Frame-based Approaches</h3><p>在以完成任务为导向的对话系统中，Frame-based的方法是一种较为合适的方法。该方法将对话建模成一个填槽(slot filling)的过程。槽是多轮对话过程中将初步用户意图转化为明确用户指令所需要补全的信息。一个槽与一件事情的处理中所需要获取的一种信息相对应。例如上文提到的：“告诉我去车站怎么走”，其中目的地是一个槽位，“车站”是该槽位所填充的值。槽位又可细分为，平行槽位、依赖槽位、单值槽位和多值槽位等。另外，为了引导用户填充槽位会有对应的澄清话术。例如：“目的地”对应的澄清话术是“您想从哪出发呢？”，“出发时间”对应的澄清话术是“您想什么时间出发呢？”<br>该方法的特点是：</p><ul><li>支持混合主导型系统，用户和系统都可以获取对话的主导权</li><li>输入相对灵活，用户回答可以包含一个或多个槽位信息</li><li>对槽位提取准确度的要求比较高</li><li>适用于相对复杂的多轮对话</li></ul><h3 id="Agenda-Frame-CMU-Communicator"><a href="#Agenda-Frame-CMU-Communicator" class="headerlink" title="Agenda + Frame(CMU Communicator)"></a>Agenda + Frame(CMU Communicator)</h3><p>Agenda + Frame(CMU Communicator)对Frame-based的方法进行了改进，增加了层次的概念支持话题切换、回退等操作。</p><p>该方法首先将会话构建成一棵树，这棵树是动态的，可以在会话过程中对树进行添加子树或挪动子树等操作。树上的每一个节点对应一个handler，handler有优先级，此外还构建了任务计划，该计划包含了话题的有序列表。</p><p>从左到右、深度优先遍历这颗树生成handler的顺序。当用户输入时，系统按照顺序调用每个 handler，每个 handler 尝试解释并回应用户输入。如果handler捕获到信息就把信息标记为consumed，这保证了一个 information item只能被一个handler消费。如果用户输入不被 handler处理，那么系统将会进入output pass，每个handler都有机会产生自己的 prompt。</p><p>handler可以通过返回码声明自己为当前对话焦点，这个handler就被提升到树的顶端。同时这里使用sub-tree promotion 的方法保留特定主题的上下文，handler被提升到兄弟节点中最左边的节点，父节点同样以此方式提升。</p><h2 id="DM设计"><a href="#DM设计" class="headerlink" title="DM设计"></a>DM设计</h2><p>刚开始要做DM的时候可能比较容易想到状态机、马尔科夫决策过程、end2end等方法，但实际操作起来去发现问题多多。</p><h3 id="模型化困难"><a href="#模型化困难" class="headerlink" title="模型化困难"></a>模型化困难</h3><ul><li>训练数据来源不容易找到及标准成本很高</li><li>在产品策略发生变化时需要重新标注语料</li><li>如何将与DM交互的其他service结果融入模型</li></ul><p>个人目前的做法是NLU是单独实现好的，那么DM要做的是多轮会话topic切换(场景打断与恢复)，基于context的语义信息筛选，多轮对话的容错，与其他service交互以及各下游服务结果的rank等。</p><p>人与人之间的对话是及其复杂的，想用一个模型来刻画描述这个过程十分困难，无论在理论研究还是在工程实践领域仍有大量的工作要做，相信将来人机对话的体验会越来越好。</p><p><strong>参考链接</strong></p><p><a href="https://www.inf.uni-hamburg.de/en/inst/ab/lt/publications/2016-schnelleetal-workshop-smartobjects.pdf" target="_blank" rel="noopener">NLU vs. Dialog Management: To Whom am I Speaking?</a></p><p><a href="http://www.cs.cmu.edu/~xw/asru99-agenda.pdf" target="_blank" rel="noopener">AN AGENDA-BASED DIALOG MANAGEMENT<br>ARCHITECTURE FOR SPOKEN LANGUAGE SYSTEMS</a></p><p><a href="https://tutorials.botsfloor.com/dialog-management-799c20a39aad" target="_blank" rel="noopener">Dialog management</a></p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于机器人的一些思考</title>
      <link href="/2018/03/25/robot/"/>
      <url>/2018/03/25/robot/</url>
      
        <content type="html"><![CDATA[<p>前几天在猎豹在水立方开的机器人之夜发布会引起了人们的关注和讨论，在发布会上傅盛把机器人行业的几位大佬都给diss了一遍，RFC(Robot Funder Club)圈内人士也在讨论/吐槽此事，猎豹可谓赚足了眼球。恰好我在做一些机器人有关的事情也接触了一些RFC的成员下面说一下我对机器人的一些思考。</p><p>机器人根据场景不同可以分为很多类型，比如：机械臂，服务机器人，陪伴机器人，商用机器人等。关于机械臂了解的不是很多，主要关注服务机器人，例如猎豹发布会里展示的迎宾机器人。要完成这样的一个机器人涉及到的技术有很多，从整体架构层面上来说我认为可以分为两部分：云端计算和本体控制。</p><p>云端计算主要包括语音识别、人脸识别、自然语言理解、知识图谱、多轮对话等。云端完成的工作就好比人对声音、文字、图像等输入信号的分析和思考，可以将其称之为机器人的大脑。</p><p>本体控制主要包括建图、导航、避障、音频采集、机械控制等。机器人本体一般基于ROS来开发，通过各种sensor采集到信号之后传送给云端(大脑)，云端经过分析处理后给本体下达指令，本体根据收到的指令来进行控制及输出，故将其称之为机器人的小脑。</p><p>目前机器人大脑部分技术比较成熟，比如语音识别、人脸识别都已经有很多落地的产品，NLP相关的技术近些年发展也比较迅速。相对来说本体控制相关的技术发展较为缓慢，例如导航部分，尽管有激光导航(实际上严格意义来说只用激光并不能导航)、UWB、vSLAM等技术，但在实际应用中仍需要踩很多坑。比如，由于激光的成本比较高我们想用基于计算机视觉的SLAM来解决室内导航的问题时发现，基于计算机视觉的SLAM本身就有很大缺陷，它对周围光线的强弱、物体位置的可变性等都有要求。还有语音的远场拾音，在比较嘈杂的环境下如何能够正确的拾音目前也是一个没有完全解决好的问题，这跟麦克风阵列的设计以及语音识别算法的调优都有关系。另外，如果声纹识别技术比较成熟的话那么机器人可以维持不同的上下文信息并同时跟多个人进行对话。类似的问题还有很多都值得我们去思考和解决。</p><p>实际上，机器人行业内、学术圈都知道目前技术水平距离媒体宣传的真正智能机器人还有巨大差距。机器人厂商活的也很辛苦，首先目前机器人的零配件的价格比较高，例如之前提到的激光雷达，一个4线的激光雷达动辄上万块，一个机器人的底盘也价格不菲再加上机器人外形磨具开模以及其他零配件等累计起来成本比较高，一个大型服务机器人不卖几万块连本钱都保不住，小型的家庭陪护型的机器人也要几千元。另外机器人的研发风险也比较高，除了工业机械臂外其他应用领域的机器人大家也都在探索，总的来说就是机器人研发周期长、成本高，所以目前迫切的需要一个可以降低研发成本的平台或解决方案，这需要整合硬件、软件、数据、服务等各个方面的资源，确实不容易。希望会有更多的公司来关注并加入机器人行业促进机器人行业的发展。</p><p>突然想到对于迎宾、服务查询办理等场景的服务机器人用全息投影+云端智能的方式或许能得到更好的效果，还记得生化危机里的Red Queue吗 :)</p>]]></content>
      
      
      <categories>
          
          <category> 此刻我在想什么 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>过剩的消费</title>
      <link href="/2018/01/28/consumption-upgrading/"/>
      <url>/2018/01/28/consumption-upgrading/</url>
      
        <content type="html"><![CDATA[<p>周末在收拾东西的时候发现桌子上、抽屉里不知不觉里多了好多东西，大部分是买回来就没怎么用过。最近几年流行一个词：消费升级，为什么要消费升级呢，那要从中国改革开放以来的快速发展说起。</p><p>近些年中国在近乎所有领域的制造方面碾压其他国家，好多从国外买回来的商品上也印有“made in china”的字样。这也导致了发达国家的实体制造业的萎缩，如果再遇上金融危机发达国家就会经济下滑，进而对中国订单的需求也跟着下滑导致中国产能过剩。为了使得经济能够继续前进只好选择拉动内需，让老百姓挺高消费水准和消费能力。</p><p>这几年市场也慢慢的形成了一种消费过剩的现象，简单来说就是买了好多从来没用过或者只用了一两次的东西。渐渐的出现一种现象：厂商们生产和制造廉价但质量不高的产品，然后用高大上的宣传手段把产品包装卖出去。比如走在大街上看到一些小饰品或者淘宝上发现一款看上去不错的电子设备，觉得挺有意思花几十或者一二百块钱买回去，买完之后用了几次就扔到一边再也没碰过。消费者对产品的体验基本上在挑选和购买阶段完成，哦，还有快递到了之后发个朋友圈。商家也意识到提升消费者的购物体验要比提升产品的使用体验更能吸引顾客，于是便想尽办法能够让用户愉悦的购物至于产品本身反而变得不那么重要。不知道这种现象还会持续多久。</p>]]></content>
      
      
      <categories>
          
          <category> 此刻我在想什么 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>写在2018年的第一天</title>
      <link href="/2018/01/01/2018-1-1/"/>
      <url>/2018/01/01/2018-1-1/</url>
      
        <content type="html"><![CDATA[<p>每年的第一天是极为普通的一天，但同时人们又为它赋予特别重要的意义。第一天意味着过去的结束也代表着新的开始，人们习惯性的在这个时候总结在刚过去的这一年有哪些收获，计划新的一年里要完成哪些目标。so, let’s do it.</p><p>大致数了一下，在刚过去的一年里读完了5本书，没有读完的有6本，要读还没有开始读的书有好几本，博客更新了18篇，这一年读书写字的量算是比较少的。去了长沙、成都、深圳、西宁、青海等几个地方，没有认识新朋友但多了几个新同事。</p><p>工作上最大的变动是约等于换了新的工作，有了更广阔的视野。切切实实的用Go语言写了一个不大不小的项目，从某种角度来说也算是得到了心理上的满足，毕竟关注Go有挺长时间了。在AI大火的这一年，学习和做了一些NLP相关的落地项目，也算是跟上时代的脚步不要被落下。</p><p>过去的一年能反映出互联网行业发展的关键词有很多：共享经济、feed流新闻、短视频、内容付费、无人驾驶等等。其中内容付费是一件有趣的事情，开启了中国网民获取内容的新篇章，在以前大家对于从网上获取盗版、免费的内容习以为常，现如今对自己感兴趣的内容进行付费阅读的方式渐渐被网民接收，同时也诞生了许多的内容平台，如得到、喜马拉雅、极客时间、混沌大学等，听说今日头条也将上线一款类似的APP。付费从某种角度来看促进了内容创作与消费这个生态的可持续发展，也在改变着人们的生活。我自己也关注订阅了几个专栏，从内容质量方面来说基本上还是有保障的。那为什么大家愿意为这些内容付费呢，一定程度上可能跟焦虑有关。</p><p>这一年经常被提到的一个词是：焦虑。无论是年轻人还是中年大叔都无时无刻不感到焦虑，我自己也一样。生活成本的增长速度远远高于收入水平的增长速度，社会的快速发展总让人觉得好像一不小心就会被淘汰。所以每个人都十分的忙碌，抓紧一切碎片化的时间来看新闻、阅读技术文章，但是碎片化阅读并不利于通过逻辑化的思考将所接收到的信息系统的组织起来并在将来需要的时候拿出来使用，每天都会见到新的新闻、新的技术，但是它跟昨天看到的新闻有什么联系我们并没有想的很清楚，碎片化阅读所带来的更多的是让人在不断碎片化的信息中被淹没而感到杂乱无章、无从下手，反而加剧了焦虑不安。所以如果真的对一个东西感兴趣那么系统化的学习是必不可少的，这个时候就体现出读书的重要性，好的书籍或内容专栏内容上都是脉络清晰、有始有终。通过一些书籍或付费内容可以比较系统全面的了解一种技术、一个领域。有人说焦虑=未来的不确定性×事情的重要性×自己无能为力的程度，通过阅读可以增加对事物发展趋势的了解，降低不确定性的同时增加自己对其的掌控能力。未知的东西最容易让人产生恐惧害怕进而变的焦虑，当你看清一个事物的全貌和发展趋势时就不会感到焦躁心里也会踏实许多。所以，18年还是要多读书。</p><p>这一年还有一个比较大的变化是，从来不玩游戏的我玩上了王者荣耀，甚至有段时间痴迷于这个游戏，在这上面花费了不少时间。我发现这款游戏跟赌博有些类似：赢了还想赢，输了还想赢回来，如此下去直到手机没电为止，有时候充电器就在旁边插上电接着玩，简直难以自拔，新的一年不能再沉迷于此，否则太耽误事了。</p><p>这一年跑步没有坚持下来，天气暖和的时候还在小区里跑几步，最多的时候也只能跑5公里，天冷了之后直接就放弃了。相比于跑步熬夜反而变多了，一旦熬夜早上便会起得晚，起得晚就来不及吃早餐，如此恶性循环身体就会一天不如一天，这个得改。</p><p>17年初的时候定的目标是聚焦，一个人很难事事都做的好，聚焦在某个点上反而比较容易做成事情，当然前提是你见过许多东西知道自己想要什么。18年的目标是自律，少熬夜，少放纵自己，按计划行事。</p><p>17年最后一个晚上一个人去看了《再见前任3》，电影还不错，看完出来的时候刚好跨过了2017。岁月不饶人，愿我也未曾绕过岁月。再见2017！</p><p>最后奉上一首自己训练的神经网络作的诗，愿新的一年有新的收获，虽然我也不知道它到底想说啥：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">暖风迎新春，红花不可闻。</span><br><span class="line">不知天上去，不见一人行。</span><br><span class="line">何处见山上，何人无此身。</span><br><span class="line">不知天地外，不得一相看。</span><br><span class="line">一里一行客，何人无旧人。</span><br><span class="line">何人有山寺，一事不无心。</span><br><span class="line">白日多多处，孤舟不是君。</span><br><span class="line">不知人事少，不得不相逢。</span><br></pre></td></tr></table></figure><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=525572100&auto=1&height=66"></iframe>]]></content>
      
      
      <categories>
          
          <category> 此刻我在想什么 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>关于chatbot</title>
      <link href="/2017/12/16/chatbot/"/>
      <url>/2017/12/16/chatbot/</url>
      
        <content type="html"><![CDATA[<h3 id="什么是Chatbot"><a href="#什么是Chatbot" class="headerlink" title="什么是Chatbot"></a>什么是Chatbot</h3><p>Chatbot，宽泛的来讲叫做聊天机器人也有人叫他对话机器人，从16年开始Chatbot发展的比较火热成为大家关注的焦点，国外的有微软的小冰、Amazon的Alex，国内有百度的度秘等。如果说上述这些你还比较陌生的话，那么提到iPhone、iPad以及Mac等系统自带的Siri你应该就比较熟悉了。Chatbot的最大的优势在于他的对话式的交互方式，通过语言对话来交流已经发展成为人类的一种本能，通过像人与人之间交流的方式来与软件、机器等进行交互可以大大降低用户学习使用成本，这也是Chatbot这些年比较火热的一个原因。Chatbot常见的形态有：个人助手、家人陪伴、客服问答等。</p><h3 id="如何实现一个Chatbot"><a href="#如何实现一个Chatbot" class="headerlink" title="如何实现一个Chatbot"></a>如何实现一个Chatbot</h3><p>目前对于Chatbot的实现方案有两种：一种是基于IR，也就是基于检索的方式；另一种是基于机器学习生成式的模式。</p><h4 id="基于检索的实现方式"><a href="#基于检索的实现方式" class="headerlink" title="基于检索的实现方式"></a>基于检索的实现方式</h4><p>用检索的方式来实现Chatbot的前提是拥有较多的问答对来构建知识库，针对用户的输入在知识库中找到能够回答用户问题的答案。其基本流程是：<br><code>输入-&gt;明确用户意图-&gt;识别实体-&gt;retrieval-&gt;matching-&gt;ranking-&gt;response</code></p><p>其中matching和ranking阶段需要好的模型来保证最后输出的准确性。这种实现方式得到的Chatbot更偏向于问答场景的对话，当然了，从某种角度来看人与人之间的交流也可以看做是一问一答式的对话。问答类的对话对于有明确答案的事实类问题是比较容易做到的，难的是如何回答好“为什么”、“怎么做”这一类的问题。</p><p>值得一提的是，吴军博士在《智能时代》里提到在12年他回到Google后Google希望他能做一些跟机器智能相关的事情，经过一段时间的调查他们决定用Google强大的搜索引擎来尝试着回答一些比较复杂的问题。当时的做法是：首先根据网页来确定用户的哪些问题Google可以回答哪些问题Google回答不了，缩小要解决问题的范围，使问题得到解决变得可能。然后通过机器学习的方法来把问题和网页来做匹配，类似于上述的learn to matching的过程。最终通过NLP的技术来合成最后的答案。经过吴军博士及其团队的努力使得计算机能够回答30%的复杂问题，并通过评测计算机的回答跟人的回答已经相当接近甚至很难区分哪个是机器回答的哪个是人回答的，算是一定程度上通过了图灵测试。</p><h4 id="基于生成式的实现方式"><a href="#基于生成式的实现方式" class="headerlink" title="基于生成式的实现方式"></a>基于生成式的实现方式</h4><p>基于生成式的方式主要得益于近些年深度学习在NLP方面长足的发展，首先需要收集大量的对话、问答语料，然后将语料中的文字转成向量，在这些向量矩阵上做卷积以及GRU操作得到最终的答案，是一种sequence2sequence的方案。这种通过分析和学习语言元素的组成进而组合生成回答的方式相比基于IR的方式的好处是不需要构建和维护大规模的知识库，可以理解为通过不断的学习和训练的方法将知识库消化掉了，它比较灵活也更像是人的思考模式，同时它的缺点是结果不具有较强的可读性，有的时候会产生一些常人不能理解的句子，类似于出现之前报道的Facebook的两个机器人用人类看不懂的方式来对话的这种情况。</p><h3 id="Alexa和度秘是怎么做的"><a href="#Alexa和度秘是怎么做的" class="headerlink" title="Alexa和度秘是怎么做的"></a>Alexa和度秘是怎么做的</h3><p>严格意义上来说Alexa和度秘并非单纯只采用上述两种方案中的某一种。相对于宽泛的聊天而言，Alexa和度秘更偏向于task oriented的对话系统，聊天只是其中的一个功能，更多的是在一问一答的过程中完成用户的指令、向用户提供服务或者与用户闲聊。</p><p>为了更好的服务好用户，度秘将提供不同垂类服务的模块分别作为单独的bot，Alexa称之为skill。当用户与其交互时通过分析用户的意图调用不同的bot来满足用户的需求，这当中除了涉及到意图识别还涉及到多轮对话的管理和bot之间的调度。从大的层面上来看大家所采用的技术都差不多，细节上的差别则是针对各自产品面向的场景不同所采用的训练语料也有所不同。当然，如果用户问到了bot无法回答的问题度秘也会通过检索的方式来尝试回答(暂不确定同样的情况下Alexa是否也采用检索的方式来尝试回答)。所以从工业的角度出发一定是结合学术界的多种方法来完成现阶段的产品。过于宽泛的聊天并不好控制，最糟糕的就是出现Chatbot胡乱回答，驴唇不对马嘴甚至是南辕北辙的情况，缩小业务范围聚焦在某一个领域反而问题比较容易得到解决。</p><h3 id="未来"><a href="#未来" class="headerlink" title="未来"></a>未来</h3><p>目前深度学习和NLP并没有那么完美，Chatbot看起来也还是有点傻傻的甚至有些“人工智障”，但是对话的交互方式必将带来变革，通过对话式的交互方式我们再也不需要去教用户如何来使用我们的产品。有些人也可能觉得这是人工智能的泡沫，但不是还有那么一句话么：No beer no bubbles.</p>]]></content>
      
      
      <categories>
          
          <category> 此刻我在想什么 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python vitrualenv setuptools pip wheel failed with error code 1的问题</title>
      <link href="/2017/12/03/vitualenv-error/"/>
      <url>/2017/12/03/vitualenv-error/</url>
      
        <content type="html"><![CDATA[<p>在用vituralenv新建Python虚拟环境时遇到如下报错信息：<br><code>setuptools pip wheel failed with error code 1</code><br>看了一下virtualenv的版本是15.1.0。网上查了一下，发现遇到该问题的大部分版本都是V1.11，卸载重新用pip安装还是报同样的错，最后用easy_install安装V1.10.1的virtualenv：<code>easy_install &quot;virtualenv&lt;1.11&quot;</code>问题得以解决。</p>]]></content>
      
      
      <categories>
          
          <category> 怪小兽的日常 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>闲聊NLP</title>
      <link href="/2017/11/26/something_about-nlp/"/>
      <url>/2017/11/26/something_about-nlp/</url>
      
        <content type="html"><![CDATA[<p>无论在工程界还是学术界自然语言处理(NLP)一直是一个比较热的话题，尤其随着近些年深度学习的发展给NLP也带来一些新思路。对于这个话题随便聊聊，想到哪写到哪。</p><h3 id="其实自然语言理解很难"><a href="#其实自然语言理解很难" class="headerlink" title="其实自然语言理解很难"></a>其实自然语言理解很难</h3><p>为什么说让机器真正的理解自然语言很难呢？</p><p>人类语言从出现至今经过上万年的演变，规则极其错综复杂，就连人类自己在学习一门外语的时候还经常发语法错误更不用说机器了。例如，一个句子由多个词语组成，通过各种组合能够得到更为复杂的句子并且如何理解一句话需要根据语境来判断，相同的词在不同的上下文中往往会产生不同的语义。同时，随着社会的发展不停的会有新词出现，退回5年前谁也不知道老铁还会双击666，哈哈。</p><h3 id="NLP做哪些事情"><a href="#NLP做哪些事情" class="headerlink" title="NLP做哪些事情"></a>NLP做哪些事情</h3><p>NLP的范围很广，包括但不限于：文本匹配、分类、实体预测等。具体应用有：分词、文本分类、语义分析、机器翻译、多轮对话，问答系统等等。</p><h3 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h3><p>特征工程在ML中十分耗时但又十分重要，同时又不具备通用性，同样是分类问题，在文本分类上好使的特征在商品分类上就完全不靠谱。而在NLP领域的特征工程主要包括：文本预处理、文本特征提取、文本表示。</p><h4 id="文本预处理"><a href="#文本预处理" class="headerlink" title="文本预处理"></a>文本预处理</h4><p>中文文本的预处理主要包括切词和去掉停用词。由于中文不像英文字母之间有空格分开，所以对于中文的切词需要用复杂的算法来解决，例如：最大匹配、基于统计信息的CRF及深度学习的一些方法。去停用词则是去掉文本中高频的连词介词等，这些词对于文本分析没有太多的价值，通常做法是维护一个停用词列表。</p><h4 id="文本表示"><a href="#文本表示" class="headerlink" title="文本表示"></a>文本表示</h4><p>计算机不能直接处理文字，但计算机可以处理数字。文本表示主要是将文本转换成计算机可以处理的方式。例如常用的词袋或者向量空间模型等，但最大的缺点是缺失上下文信息，词与词之间相互独立无法表征语义同时向量的维度和稀疏性都比较高。</p><h4 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h4><p>文本的表示依赖于特征的提取，主要包括特征选择和权重计算。特征选择一般是根据某个评价指标对文本进行评分排序选择评分较高的特征项，例如：词频、文档频率、互信息等。最经典的就是TF-IDF。</p><h3 id="深度学习在NLP中的应用"><a href="#深度学习在NLP中的应用" class="headerlink" title="深度学习在NLP中的应用"></a>深度学习在NLP中的应用</h3><p>深度学习在图像分类、语音识别的应用中取得了很大的成功。相比于传统的文本，表示图像和语音的数据是比较稠密的，而对于高度稀疏的one-hot文本向量深度学习不善于处理此类数据。所以要用深度学习解决NLP问题首先要解决的是文本表示问题。Distributed Representation，其基本思想是将每个词表达成 n 维稠密、连续的实数向量，他具有很强的特征表示能力。具有代表性的是word2vec，他有两种模式：CBOW和Skip-Gram。word2vec极大的推动了文本分析的发展，其提出的Hierarchical Softmax和Negative Sample两个方法很好的解决了耗时漫长的大规模计算问题。但word2vec通过语料中的上下文信息学习得到的词向量还不能表示真正的语义，例如通过word2vec得到的相似的词更多的是具有相似上下文的词，“好”与“坏”的相似度经常也很高。</p><p>解决了文本表示的问题，则可以通过CNN/RNN来进一步解决自动特征提取进而完成文本分类等问题。</p><h3 id="关于文本分类及实体识别"><a href="#关于文本分类及实体识别" class="headerlink" title="关于文本分类及实体识别"></a>关于文本分类及实体识别</h3><p>文本分类和实体识别是NLP里一个老生常谈的话题，最早开始人们通过规则匹配的方式来做，到后来随着数据量的增长和机器性能的提升，运用统计学知识的机器学习方法开始渐渐成为处理此类问题的一个主要手段。但依旧避不开特征工程这个步骤。</p><p>例如在句子分类中，首先要把句子表示成TF-vector或者是WordCountVector进而利用LR或者SVM等分类器进行分类。而在NER中则更为复杂：当前词的前序词、后续词、是否大写、是否是Title、词的前缀和后缀，词性等等，这些都是大家在不断的摸索中发现的比较好的特征。</p><p>利用深度学习网络自动提取特征的技能可以帮助人们更好的完成之前的文本处理任务。例如：利用word2vec将词转成词向量，然后利用CNN进行卷积计算，在卷积的过程中不同size的卷积核可以自动获取n取值不同的n-gram信息，通过不同的卷积层捕捉局部相关性可以更好的来进行分类。详见：<a href="https://arxiv.org/abs/1408.5882" target="_blank" rel="noopener">Yoon Kim发表的论文</a></p><h3 id="问答系统和多轮对话系统"><a href="#问答系统和多轮对话系统" class="headerlink" title="问答系统和多轮对话系统"></a>问答系统和多轮对话系统</h3><p>问答系统早期的做法是通过模板、规则匹配的方法，这种方法比较适合命令式的场景，例如家电控制等。</p><p>目前还有一种常用做法是基于检索的方法：将Q&amp;A索引起来，新来的question在索引上做一次检索，在候选集上用匹配模型去匹配，最后做一个排序，一般把第一个答案返回给用户。</p><p>还有一种方法是通过神经网络来对问题和答案做卷积，判断两句话里哪些局部的词语是互相对应的，最终判断问题和答案是否相关。</p><p>多轮对话可以看做是广义上的一个问答系统，目前开放式的多轮对话还是基于检索的方式来做，但还做的不够好。尤其对于一个闲聊的、开放式的对话目前还没有一个很好的模型来描述和刻画。</p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>目前看来在广义的NLP中，从语音到文字(语音识别)做的比较成功，从文字到语义及从语义到回答还有很长的路要走。人工智能的发展未来可期。</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go与TLS的那些事</title>
      <link href="/2017/10/21/TLS-Go/"/>
      <url>/2017/10/21/TLS-Go/</url>
      
        <content type="html"><![CDATA[<p>安全一直是一件很重要的事情，现在大部分正经公司的网站都已经跑在HTTPS上。所以这里分享一下如何用Go创建自签名证书并用自签名证书来实现一个支持HTTPS的服务。</p><h3 id="公私钥加解密"><a href="#公私钥加解密" class="headerlink" title="公私钥加解密"></a>公私钥加解密</h3><p>公私钥加密除了能保证内容的安全性以外还用来证明你自己是你自己，因为只有用你的私钥才能解密由你公钥加密的内容，公钥是对所有人公开，而私钥只有你自己知道。</p><p>在Go中有一个<code>crypto/rsa</code>包，提供了非对称加密的实现，首先我们生成一对公私钥：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> Use crypto/rand not math/rand</span></span><br><span class="line">privKey, err := rsa.GenerateKey(rand.Reader, <span class="number">2048</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Fatalf(<span class="string">"generating random key: %v"</span>, err)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>用公钥加密的内容只能用对应的私钥解开，主要原理是基于大质数的分解，有兴趣的可以查看相关资料，这里先按下不表。</p><p>用公钥加密：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plainText := []<span class="keyword">byte</span>(<span class="string">"Hi I'm Xiaoming"</span>)</span><br><span class="line"><span class="comment">// use the public key to encrypt the message</span></span><br><span class="line">cipherText, err := rsa.EncryptPKCS1v15(rand.Reader, &amp;privKey.PublicKey, plainText)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Fatalf(<span class="string">"could not encrypt data: %v"</span>, err)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样我们就得到了密文<code>cipherText</code>，如果你打印密文的话将看到一串类似于乱码的内容。</p><p>用秘钥解密：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">decryptedText, err := rsa.DecryptPKCS1v15(<span class="literal">nil</span>, privKey, cipherText)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">"error decrypting cipher text: %v"</span>, err)</span><br><span class="line">&#125;</span><br><span class="line">fmt.Printf(<span class="string">"%s\n"</span>, decryptedText)</span><br></pre></td></tr></table></figure><p>那么如何证明你自己是你自己呢？如果我想要跟你通信首先要证明你的身份，我用你的公钥来加密一个内容发送给你，然后你用私钥解开后将内容返回给我，如果你能将我发送的内容正确无误的返回给我那就证明即将要跟我通信的人确实是你。</p><p>但是，如果我获取了公钥的时候被中间人攻击，我拿到的公钥不是你的而是中间人的怎么办呢？这样我会误认为中间人是你。这个时候就需要CA证书了。</p><h3 id="数字签名"><a href="#数字签名" class="headerlink" title="数字签名"></a>数字签名</h3><p>数字签名的作用是用来校验内容的正确性，保证内容没有被篡改过。</p><p>数字签名生成的过程是对要发送的内容来做hash得到一个指纹，然后用私钥对指纹进行计算得到签名。</p><p>验证签名的过程是，对接到内容做相同的hash得到一个指纹，用私钥对应的公钥来得到签名里的指纹信息，比对两个指纹，如果两个指纹能对上则证明内容没有被篡改过。</p><p>有人会问为什么不直接对发送的内容算签名而是要先得到一个hash值，首先hash计算得到的值比较短，对这个值进行签名计算比较快。另外RSA在计算签名时对签名内容的长度也有限制，如果直接将一本《红楼梦》的内容来计算签名那是很难想象的。</p><p>同样我们可以用<code>crypto/rsa</code>包来计算签名：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">plainText:=<span class="string">"Hi, I'm Xiaoming"</span></span><br><span class="line">h := sha1.New()</span><br><span class="line">h.Write([]<span class="keyword">byte</span>(plainText))</span><br><span class="line">digest := h.Sum(<span class="literal">nil</span>)</span><br><span class="line">fmt.Printf(<span class="string">"The hash of my message is: %s\n"</span>, <span class="keyword">string</span>(digest))</span><br><span class="line"></span><br><span class="line"><span class="comment">// generate a signature using the private key</span></span><br><span class="line">signature, err := rsa.SignPKCS1v15(rand.Reader, privKey, crypto.SHA1, digest)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Fatalf(<span class="string">"error creating signature: %v"</span>, err)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>验证签名：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Verify</span><span class="params">(pub *rsa.PublicKey, data, signature []<span class="keyword">byte</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">h := sha1.New()</span><br><span class="line">h.Write(data)</span><br><span class="line">digest := h.Sum(<span class="literal">nil</span>)</span><br><span class="line"><span class="keyword">return</span> rsa.VerifyPKCS1v15(pub, crypto.SHA1, digest, signature)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么对于之前说的中间人替换了证书的情况，就可以用数字签名来解决。首先服务提供方需要去wellknown CA那里申请一张证书，这个证书的内容是服务提供方的相关信息和公钥，然后用CA的私钥对这些内容做一个签名附在证书里。在建立HTTPS连接的时候服务端需要向客户端提供他的证书，客户端首先验证证书的合法性：由wellknow CA签发，并且通过数字签名校验证书内容的正确性，没有问题后就可以认为证书的公钥确实是服务端的公钥而不是被中间人篡改的其他公钥。</p><h3 id="自签名证书-amp-HTTPS服务"><a href="#自签名证书-amp-HTTPS服务" class="headerlink" title="自签名证书&amp;HTTPS服务"></a>自签名证书&amp;HTTPS服务</h3><p>在开发的过程中我们可能需要先用一个自签名的证书来满足开发需求，或者我们要自建CA来为其他服务签发证书(k8s中可以用自签证书来做认证)这个时候就可以用<code>crypto/x509</code>来生成一张自签名的证书。</p><p>首先要创建生成证书的请求：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">CertTemplate</span><span class="params">()</span> <span class="params">(*x509.Certificate, error)</span></span> &#123;</span><br><span class="line">    serialNumberLimit := <span class="built_in">new</span>(big.Int).Lsh(big.NewInt(<span class="number">1</span>), <span class="number">128</span>)</span><br><span class="line">    serialNumber, err := rand.Int(rand.Reader, serialNumberLimit)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, errors.New(<span class="string">"failed to generate serial number: "</span> + err.Error())</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    tmpl := x509.Certificate&#123;</span><br><span class="line">        SerialNumber:          serialNumber,</span><br><span class="line">        Subject:               pkix.Name&#123;Organization: []<span class="keyword">string</span>&#123;<span class="string">"Siglecool, Inc."</span>&#125;&#125;,</span><br><span class="line">        SignatureAlgorithm:    x509.SHA256WithRSA,</span><br><span class="line">        NotBefore:             time.Now(),</span><br><span class="line">        NotAfter:              time.Now().Add(time.Hour),         BasicConstraintsValid: <span class="literal">true</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> &amp;tmpl, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来需要创建一对公私钥，并完善生成证书请求的内容：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">rootKey, err := rsa.GenerateKey(rand.Reader, <span class="number">2048</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">"generating random key: %v"</span>, err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">rootCertTmpl, err := CertTemplate()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">"creating cert template: %v"</span>, err)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// describe what the certificate will be used for</span></span><br><span class="line">rootCertTmpl.IsCA = <span class="literal">true</span></span><br><span class="line">rootCertTmpl.KeyUsage = x509.KeyUsageCertSign | x509.KeyUsageDigitalSignature</span><br><span class="line">rootCertTmpl.ExtKeyUsage = []x509.ExtKeyUsage&#123;x509.ExtKeyUsageServerAuth, x509.ExtKeyUsageClientAuth&#125;</span><br><span class="line">rootCertTmpl.IPAddresses = []net.IP&#123;net.ParseIP(<span class="string">"127.0.0.1"</span>)&#125;</span><br></pre></td></tr></table></figure><p>接下来创建根证书：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">CreateCert</span><span class="params">(template, parent *x509.Certificate, pub <span class="keyword">interface</span>&#123;&#125;, parentPriv <span class="keyword">interface</span>&#123;&#125;)</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    cert *x509.Certificate, certPEM []<span class="keyword">byte</span>, err error)</span></span> &#123;</span><br><span class="line"></span><br><span class="line">    certDER, err := x509.CreateCertificate(rand.Reader, template, parent, pub, parentPriv)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    cert, err = x509.ParseCertificate(certDER)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line">    b := pem.Block&#123;Type: <span class="string">"CERTIFICATE"</span>, Bytes: certDER&#125;</span><br><span class="line">    certPEM = pem.EncodeToMemory(&amp;b)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">rootCert, rootCertPEM, err := CreateCert(rootCertTmpl, rootCertTmpl, &amp;rootKey.PublicKey, rootKey)</span><br></pre></td></tr></table></figure><p>然后可以用根证书来签发httpserver的证书：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">servKey, err := rsa.GenerateKey(rand.Reader, <span class="number">2048</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">"generating random key: %v"</span>, err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// create a template for the server</span></span><br><span class="line">servCertTmpl, err := CertTemplate()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">"creating cert template: %v"</span>, err)</span><br><span class="line">&#125;</span><br><span class="line">servCertTmpl.KeyUsage = x509.KeyUsageDigitalSignature</span><br><span class="line">servCertTmpl.ExtKeyUsage = []x509.ExtKeyUsage&#123;x509.ExtKeyUsageServerAuth&#125;</span><br><span class="line">servCertTmpl.IPAddresses = []net.IP&#123;net.ParseIP(<span class="string">"127.0.0.1"</span>)&#125;</span><br><span class="line"></span><br><span class="line">_, servCertPEM, err := CreateCert(servCertTmpl, rootCert, &amp;servKey.PublicKey, rootKey)</span><br></pre></td></tr></table></figure><p>用httpserver证书来创建HTTPS服务：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">servKeyPEM := pem.EncodeToMemory(&amp;pem.Block&#123;</span><br><span class="line">Type: <span class="string">"RSA PRIVATE KEY"</span>, Bytes: x509.MarshalPKCS1PrivateKey(servKey),</span><br><span class="line">&#125;)</span><br><span class="line">servTLSCert, err := tls.X509KeyPair(servCertPEM, servKeyPEM)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">"invalid key pair: %v"</span>, err)</span><br><span class="line">&#125;</span><br><span class="line">handler := <span class="function"><span class="keyword">func</span><span class="params">(w http.ResponseWriter, r *http.Request)</span></span> &#123; w.Write([]<span class="keyword">byte</span>(<span class="string">"Hello World!"</span>)) &#125;</span><br><span class="line">s := httptest.NewUnstartedServer(http.HandlerFunc(handler))</span><br><span class="line">s.TLS = &amp;tls.Config&#123;</span><br><span class="line">Certificates: []tls.Certificate&#123;servTLSCert&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个时候请求这个server会报错：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">s.StartTLS()</span><br><span class="line">_, err = http.Get(s.URL)</span><br><span class="line">s.Close()</span><br><span class="line">fmt.Println(err)</span><br><span class="line"><span class="comment">// x509: certificate signed by unknown authority</span></span><br></pre></td></tr></table></figure><p>由于我们的证书不是知名CA签发的所以在client请求serve时在校验证书环节会报错，同时服务端也会提示：<code>http: TLS handshake error from 127.0.0.1:53844: remote error: bad certificate</code></p><p>为了让client信任server的证书，我们需要在client中用我们的root证书来替代系统的root证书，因为server的证书使用我们自己生成的root证书签发的，这样server证书就可以验证通过：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">certPool := x509.NewCertPool()</span><br><span class="line">certPool.AppendCertsFromPEM(rootCertPEM)</span><br><span class="line">client := &amp;http.Client&#123;</span><br><span class="line">Transport: &amp;http.Transport&#123;</span><br><span class="line">TLSClientConfig: &amp;tls.Config&#123;RootCAs: certPool&#125;,</span><br><span class="line">&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">s.StartTLS()</span><br><span class="line">resp, err := client.Get(s.URL)</span><br><span class="line">s.Close()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">"could not make GET request: %v"</span>, err)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">defer</span> resp.Body.Close()</span><br><span class="line">body, err := ioutil.ReadAll(resp.Body)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatalf(<span class="string">"could not response: %v"</span>, err)</span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(<span class="keyword">string</span>(body))</span><br></pre></td></tr></table></figure><p>这次我们就可以收到<code>Hello World</code>啦。</p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> TLS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>go 域名解析过慢</title>
      <link href="/2017/09/16/go-dns/"/>
      <url>/2017/09/16/go-dns/</url>
      
        <content type="html"><![CDATA[<p>这几天发现一个问题，用go的HttpClient向<code>某个URL</code>发送post请求超时，经过一番排查，发现主要是在DNS解析的时候很慢要5S左右。但是同样的环境用Python和Java发送请求可以很快的返回结果，&lt;1S。</p><p>首先看/etc/resolv.conf文件，默认配置了两个nameserver。strace执行过程发现在请求nameserver时有timeout，并且整个过程只请求了一个nameserver，同样的Python执行过程却没有这种情况。把resolv.conf中的option timeout从2设置为1之后，请求时间变为3S.如果增加一个nameserver：114.114.114.114，go的程序便可很快返回。</p><p>看了一下go关于域名解析的代码，觉得没毛病！ 可是为什么同样的环境下go跟Python的时间差这么多:( 而且目前只发现这个域名会出现这个问题。网上找了好久也没发现有人遇到这种问题。昨天跟leader讨论这个问题的时候，leader又提出用Java重写整个项目。心累，蓝瘦。</p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>go upgrade on fly</title>
      <link href="/2017/09/16/go-upgrade-on-fly/"/>
      <url>/2017/09/16/go-upgrade-on-fly/</url>
      
        <content type="html"><![CDATA[<p>作为一个服务端程序在修改配置时最好能够支持优雅的重启，这样避免给用户带来糟糕的体验。即使不能优雅重启，那么在停止服务做配置修改时，也要做到优雅的停止，而不是粗暴的kill掉进程，这种粗暴的做法会lost正在处理的请求，对用户也是不友好的。</p><h3 id="目标："><a href="#目标：" class="headerlink" title="目标："></a>目标：</h3><ol><li>不掐断当前处理中的连接</li><li>不中断socket的监听</li><li>新版本的程序能够接替老版本的程序</li></ol><h3 id="要做的事情："><a href="#要做的事情：" class="headerlink" title="要做的事情："></a>要做的事情：</h3><ol><li>启动新的进程并监听到对应的address</li><li>老进程停止接收新的连接</li><li>老进程完成ongoing请求</li><li>停止老进程</li></ol><h3 id="怎么做："><a href="#怎么做：" class="headerlink" title="怎么做："></a>怎么做：</h3><ol><li><p>通过Signal与进程交互，在程序中通过signal.Notify注册要接收的信号和接收信号的channel，向进程发送HUP signal通知其进行reload</p></li><li><p>go本身不支持端口复用，但是netListener支持从一个FD中开启监听。</p></li><li><p>通过exec.Command来执行新的binary，子进程继承父进程的句柄，但是句柄里存在CloseOnExec问题，也就是在执行exec的时候，所有的句柄都关闭了，好在netListener.File()返回一个dup(2)的FD，该FD没有设置FD_CLOEXEC，通过Cmd的ExtraFile来传递FD。</p></li><li><p>新启动的程序如何知道是从继承的FD监听还是新开一个socket？老进程在执行exec时设置一个环境变量，新进程通过该环境变量来进行判断</p></li><li><p>停止老进程对端口的监听，调用老进程的netListener.Close()。该方法会使得所有被block住的Accept()方法不在被block住并返回一个error。</p></li><li><p>等待老进程中ongoing的请求处理结束。这里使用sync.WaitGroup计数的方法，在Listener Accept()的时候Add，conn close时Done，在结束老进程时进行Wait()等待处理完所有的request。</p></li></ol><p>fork-exec的方式存在一个问题是，新exec出来的是一个新的进程，如果用Systemd进行进程管理的话，Systemd会认为其已经dead了。为了避免这种情况需要维护一份pid文件，告诉Systemd PIDFile路径，Systemd通过该文件来监控。</p><p>除了fork-exec的方式外可以用master-worker的方式，master负责监听signal，worker负责处理请求。如果要进行升级master fork出新的worker转移env, listener, args等。程序还是那个程序，但是负责处理请求的进程则换成了新的worker进程</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://grisha.org/blog/2014/06/03/graceful-restart-in-golang/" target="_blank" rel="noopener">Graceful Restart in Golang</a></p><p><a href="http://blog.nella.org/zero-downtime-upgrades-of-tcp-servers-in-go/" target="_blank" rel="noopener">Zero Downtime upgrades of TCP servers in Go</a></p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>只不过是一场生活</title>
      <link href="/2017/09/03/just-a-kind-life/"/>
      <url>/2017/09/03/just-a-kind-life/</url>
      
        <content type="html"><![CDATA[<p>九月，伴随着凉爽的秋风一同扑面而来的是一堆婚礼请柬。或许真的是到了年龄了，忽然之间身边的亲戚朋友都要结婚了。</p><p>生活真是让人捉摸不透，记忆里已经有些模糊的那些年那些事真要回味起来还是蛮下酒的。谁也没曾想到亲密会戛然而止，然后便相忘于江湖；谁也没有料到会说散就散，随后便听到了婚讯。听到B哥的这首歌的时候，往事忽然涌上心头，然而转过头青春早已散场，剩下我们站在那里泪流满面。</p><p>婚姻到底是一场生活，一场命运还是一场游戏？不得而知。</p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=26508184&auto=1&height=66"></iframe><br><p>鬼知道接下来参加九月的婚礼需要顶着多大的压力。</p><p>走过八月，曾经的那个少年会继续走在九月的街头，他始终相信要找的答案会出现在下一个车站。</p><p>对他而言，或许这不只是一场生活，也或许这一切仅仅只是一场生活。</p><p>PS：比较喜欢这个版本: <a href="http://music.163.com/#/song?id=424477863" target="_blank" rel="noopener">结婚 (2016 unplugged)</a>，尤其朱格乐的声音，但是版权问题无法生成外链播放器。</p>]]></content>
      
      
      <categories>
          
          <category> 此刻我在想什么 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Go使用感受</title>
      <link href="/2017/08/29/golang-using-experience/"/>
      <url>/2017/08/29/golang-using-experience/</url>
      
        <content type="html"><![CDATA[<p>使用Go有一段时间了，说一下感受。</p><h3 id="语法方面"><a href="#语法方面" class="headerlink" title="语法方面"></a>语法方面</h3><ol><li>语法比较简洁，有点像Python，这一点比Java要好。</li><li>多返回值。这一点使得go语言程序不需要像用单返回值语言写的程序那样将多个返回值封装到一个对象里，一定程度上减少了代码量。</li><li>函数是一级公民，可以将函数作为参数来传递。</li><li>语言级别支持并发，减少程序员心智负担。</li><li>比较完善的工具包，比如net/http，用简单的几行代码便可以实现一个http server服务。</li><li>……</li></ol><p>除了上述之外还有其他好多不错的地方，比如支持交叉编译，运行速度快，占用资源少等。下面说一下在开发过程中遇到的与其他语言开发习惯不太一样的地方。</p><h3 id="error处理"><a href="#error处理" class="headerlink" title="error处理"></a>error处理</h3><p>作为一门simple language，go对error的处理也十分的简单。我们知道在Java语言里使用try-catch-finally来处理错误和异常，而C语言则以返回错误码的方式来对错误作处理。go在这方面继承了C的风格，但与C不同的是go不是用整型来作为返回值而是用error这个interface类来作为返回值。<br>但是go的error处理方式从一开始就成为被人吐槽的点，有的人认为go的这种处理方式太古老了，使得处理错误的代码冗长且重复，例如：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">err := func1()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="comment">//handle error...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">err = func2()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="comment">//handle error...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">err = func3()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="comment">//handle error...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Go 作者之一，Russ Cox对于这种观点进行过驳斥：当初选择返回值这种错误处理机制而不是try-catch这种机制，主要是考虑前者适用于大型软件，后者更适合小程序。当程序变大，try-catch会让错误处理更加冗长繁琐易出错。不过Russ Cox也承认Go的错误处理机制对于开发人员的确有一定的心智负担。</p><p>所以在开发过程中对于error有以下几个trick：</p><ul><li>checkError</li></ul><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">checkError</span><span class="params">(err error)</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        fmt.Println(<span class="string">"Error is "</span>, err)</span><br><span class="line">        <span class="built_in">panic</span>(err)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">echo</span><span class="params">()</span></span> &#123;</span><br><span class="line">    err := func1()</span><br><span class="line">    checkError(err)</span><br><span class="line"></span><br><span class="line">    err = func2()</span><br><span class="line">    checkError(err)</span><br><span class="line"></span><br><span class="line">    err = func3()</span><br><span class="line">    checkError(err)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以在需要的地方进行recover处理，防止由于某个panic导致了整个程序退出。当然了，在开发阶段也不要忘记“让其崩溃，crash is awesome!!!”的思想。</p><ul><li>Errors are values</li></ul><p>标准库里就用了这种思想，例如bufio的Writer：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">b := bufio.NewWriter(fd)</span><br><span class="line">    b.Write(p0[a:b])</span><br><span class="line">    b.Write(p1[c:d])</span><br><span class="line">    b.Write(p2[e:f])</span><br><span class="line">    .....</span><br><span class="line">    <span class="keyword">if</span> b.Flush() != <span class="literal">nil</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> b.Flush()</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Writer <span class="keyword">struct</span> &#123;</span><br><span class="line">    err error</span><br><span class="line">    buf []<span class="keyword">byte</span></span><br><span class="line">    n   <span class="keyword">int</span></span><br><span class="line">    wr  io.Writer</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(b *Writer)</span> <span class="title">Write</span><span class="params">(p []<span class="keyword">byte</span>)</span> <span class="params">(nn <span class="keyword">int</span>, err error)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">len</span>(p) &gt; b.Available() &amp;&amp; b.err == <span class="literal">nil</span> &#123;</span><br><span class="line">        ... ...</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> b.err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> nn, b.err</span><br><span class="line">    &#125;</span><br><span class="line">    ......</span><br><span class="line">    <span class="keyword">return</span> nn, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>error作为一个状态值封装到了Writer里面，并且在Write方法入口处对Writer进行状态检查，如果error!=nil则直接return。</p><ul><li>exported Error变量</li></ul><p>在开发过程中会遇到根据不同的error来进行不同的处理，所以一种做法就是exporte error:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">var (</span><br><span class="line">    ErrInvalid    = errors.New(&quot;invalid argument&quot;)</span><br><span class="line">    ErrPermission = errors.New(&quot;permission denied&quot;)</span><br><span class="line">    ErrExist      = errors.New(&quot;file already exists&quot;)</span><br><span class="line">    ErrNotExist   = errors.New(&quot;file does not exist&quot;)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>这样就可以直接使用判断是否相等的方式来做处理：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> err == os.ErrInvalid &#123;</span><br><span class="line">    <span class="comment">//handle invalid</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>或者使用type switch：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span> t:=err.(<span class="keyword">type</span>)  &#123;</span><br><span class="line">    <span class="keyword">case</span> ErrInvalid:</span><br><span class="line">        <span class="comment">//handle invalid</span></span><br><span class="line">    <span class="keyword">case</span> ErrPermission:</span><br><span class="line">        <span class="comment">//handle no permission</span></span><br><span class="line">    ... ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>自定义error</li></ul><p>通过自定义error可以增加更丰富的context，例如net包里，除了实现error interface的方法外还实现了Timeout，Temporary方法，可以通过type switch和type assertion来进行类型转换：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span>  err := err.(<span class="keyword">type</span>) &#123;</span><br><span class="line">   <span class="keyword">case</span> *url.Error:</span><br><span class="line">  err2, ok := err.Err.(net.Error)</span><br><span class="line">  <span class="keyword">if</span> ok &amp;&amp; err2.Timeout() &#123;</span><br><span class="line">  <span class="comment">// handle timeout</span></span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>error OR bool?</li></ul><p>当函数失败的原因只有一个，所以返回值的类型应该为bool，而不是error。</p><ul><li>错误还是异常？</li></ul><p>什么是错误？什么是异常？什么时候使用错误？什么时候使用异常？错误和异常如何转换？<br>个人理解，错误是指出现的问题我们意料之中的，例如：文件打开错误，连接失败等。异常是出现了意料之外的错误，例如：空指针，下标越界等。对于错误程序可以进行自动处理，对于异常我们可以在上游进行recover，避免服务终止。</p><p>错误转异常，例如尝试请求某个URL，最多尝试三次，尝试三次的过程中请求失败是错误，尝试三次还不成功则失败就被提升为异常。</p><p>异常转错误，例如panic触发的异常被recover恢复后，对函数返回值中error类型变量进行赋值并返回，以此告诉上游本次调用发生了错误，上游程序走错误处理流程。</p><h3 id="依赖包管理"><a href="#依赖包管理" class="headerlink" title="依赖包管理"></a>依赖包管理</h3><p>go的包管理跟Java的maven不太一样，go使用GOPATH来管理依赖，无论是自己写的代码还是go get下来的代码都在一个GOPATH下面。这样就存在很大的问题：</p><ol><li>如果项目的依赖包发生了修改就可能会影响到自己的代码。</li><li>无法满足GOPATH下的两个工程分别依赖同一个包的不同版本。</li></ol><p>从go1.6版本开始正式引入了vendor机制，使得在编译时先从源码根目录下的vendor中寻找依赖，如果没找到再去GOPATH中寻找。这样可以解决上述的两个问题。但使用vendor还存在以下问题：</p><ol><li>缺少外部依赖包的版本信息，无法进行版本管理和升级。</li><li>无法使用指定版本的依赖包</li><li>无法列出项目所有依赖的外部包</li></ol><p>为了解决上述问题，社区里在vendor机制基础上开发了多个包管理工具，例如：govendor,godep,glide等。go也在开发官方的<a href="https://github.com/golang/dep" target="_blank" rel="noopener">dep</a> 使用这些管理工具可以较好的解决上述问题。</p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>go语言HttpClient中的https证书</title>
      <link href="/2017/08/18/golang-https/"/>
      <url>/2017/08/18/golang-https/</url>
      
        <content type="html"><![CDATA[<p>关于HTTPS中SSL/TLS具体原理就不具体说了，可以看一下阮一峰老师的<a href="http://www.ruanyifeng.com/blog/2014/09/illustration-ssl.html" target="_blank" rel="noopener">文章</a></p><p>这里我们主要说一下HTTPS中的证书，HTTPS开始的握手阶段是基于非对称加密，也就是公钥加密的数据要用私钥才能解开，同理用私钥加密的数据用公钥才能解开。</p><p>然而有一肚子坏水的家伙可以进行中间人劫持然后用自己的公钥来替换要访问的服务器的公钥，这样本来要发给服务器的数据发给了中间人，信息就被他们给窃取走了，所以有了CA这个机构来负责管理和签发证书。CA会将申请者的一些信息和公钥用CA自己的私钥加密并附上CA的一些信息生成数字证书给申请者。client在向服务器发出加密请求的时候，服务器会将数字证书一起返回给client，client在受信任的根证书颁发机构列表里来查看解开数字证书的公钥是否在列表之内，如果这张数字证书不是由受信任的机构颁发的会发出警告，如果数字证书是可靠的，客户端就可以使用证书中的服务器公钥。</p><p>通过CA的数字签名来保证公钥的有效性，而黑客的公钥是很难通过CA的认证。CA证书具有层级结构，它建立了自上而下的信任链，下级CA信任上级CA，下级CA由上级CA颁发证书并认证。数字证书最常见的格式是X.509，这种公钥基础设施又称之为PKIX。在用HttpClient进行数字证书认证出错的时候会提示：<code>PKIX path building failed</code></p><p>我们知道浏览器保存了一个常用的CA证书列表，那么用golang的HttpClient请求HTTPS的服务时，它所受信任的证书列表在哪里呢？</p><p>查看golang的源码发现在目录<code>src/crypto/x509</code>下有针对各个操作系统获取根证书的实现，例如root_linux.go中记录了各个Linux发行版根证书的存放路径：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Copyright 2015 The Go Authors. All rights reserved.</span></span><br><span class="line"><span class="comment">// Use of this source code is governed by a BSD-style</span></span><br><span class="line"><span class="comment">// license that can be found in the LICENSE file.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> x509</span><br><span class="line"></span><br><span class="line"><span class="comment">// Possible certificate files; stop after finding one.</span></span><br><span class="line"><span class="keyword">var</span> certFiles = []<span class="keyword">string</span>&#123;</span><br><span class="line"><span class="string">"/etc/ssl/certs/ca-certificates.crt"</span>,                <span class="comment">// Debian/Ubuntu/Gentoo etc.</span></span><br><span class="line"><span class="string">"/etc/pki/tls/certs/ca-bundle.crt"</span>,                  <span class="comment">// Fedora/RHEL 6</span></span><br><span class="line"><span class="string">"/etc/ssl/ca-bundle.pem"</span>,                            <span class="comment">// OpenSUSE</span></span><br><span class="line"><span class="string">"/etc/pki/tls/cacert.pem"</span>,                           <span class="comment">// OpenELEC</span></span><br><span class="line"><span class="string">"/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem"</span>, <span class="comment">// CentOS/RHEL 7</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>root_unix.go中写了类Unix系统的证书路径：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Possible directories with certificate files; stop after successfully</span></span><br><span class="line"><span class="comment">// reading at least one file from a directory.</span></span><br><span class="line">  <span class="keyword">var</span> certDirectories = []<span class="keyword">string</span>&#123;</span><br><span class="line">  <span class="string">"/etc/ssl/certs"</span>,               <span class="comment">// SLES10/SLES11, https://golang.org/issue/12139</span></span><br><span class="line">  <span class="string">"/system/etc/security/cacerts"</span>, <span class="comment">// Android</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>对应的还有root_darwin.go，root_windows.go等分别实现了MacOS及Windows平台下的根证书的获取。</p><p>另外，Java在JRE的安装目录下也有一份默认的可信任证书列表，这个列表一般是保存在 $JRE/lib/security/cacerts 文件中，随着JDK版本的升级而更新。</p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
            <tag> https </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搜索引擎系列(三)---用户行为分析</title>
      <link href="/2017/08/13/user-behavior/"/>
      <url>/2017/08/13/user-behavior/</url>
      
        <content type="html"><![CDATA[<p>搜索引擎主要是帮助用户找到想要的信息或者服务，所以这里面涉及到三件事情，理解用户搜索意图，理解资源，匹配用户意图和资源。在一开始的时候搜索引擎主要通过对文本的统计分析，如TF-IDF,BM25等，来满足二者之间的匹配。后来发现除了文本统计之外还可以通过对页面质量的分析，外链的分析，如PageRank，来提升对资源的理解改善搜索效果。再到后来发现通过分析用户在搜索时的行为可以更好的了解用户意图并以此来提升搜索结果的相关度。为什么呢？用户选择搜索结果的过程是一次人类智慧的体现，通过观察多个用户的这种行为并从中找出规律可以提升搜索结果的相关度，毕竟人还是要比机器更加有智慧，这也是典型的利用集体智慧的例子。</p><h3 id="用户行为有哪些"><a href="#用户行为有哪些" class="headerlink" title="用户行为有哪些"></a>用户行为有哪些</h3><p>用户在使用搜索引擎的过程中会有浏览，点击结果，翻页，变换query，点击相关搜索等行为，这些行为便是我们要记录和分析的行为。</p><h3 id="基础数据"><a href="#基础数据" class="headerlink" title="基础数据"></a>基础数据</h3><p>通过对用户行为的记录我们会得到展现日志，点击日志，搜索日志等数据。例如我们得到点击日志格式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">时间 | 行为 | query | URL List</span><br><span class="line">time | Search | 薛之谦 | ...</span><br><span class="line">time | 点击第二条结果 | 薛之谦 | ...</span><br><span class="line">time | 点击相关搜索第二条 | 火星情报局 | ...</span><br><span class="line">time | 点击第一条结果 | 爱奇艺在线观看 | ...</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>将日志按照userID和时间戳排序就可以看到每个用户的一系列搜索行为。</p><h3 id="用户行为理解"><a href="#用户行为理解" class="headerlink" title="用户行为理解"></a>用户行为理解</h3><p>有了用户行为之后我们对用户行为进行一个简单的分析可以得出：</p><ol><li>顺序浏览模式，大多数用户倾向于从前到后顺序浏览。</li><li>点击行为代表对结果投票，用户通过标题、摘要、飘红等信息对结果进行预判，感觉有兴趣可能会满足需求才会点击。</li><li>点击不一定能满足，通过点击进入落地页之后发现内容不满足需求，可能会重新搜索。</li><li>重视最后一次点击，在同一次搜索的多次点击中，最后一次点击对应的结果往往最好，其次是第一次点击的结果。</li><li>搜索行为的关联性，用户的后一次搜索(query变换，点击相关搜索等)往往是对之前搜索需求的细化或者拓展。</li></ol><h3 id="用户行为分析"><a href="#用户行为分析" class="headerlink" title="用户行为分析"></a>用户行为分析</h3><p>考虑如下case：对于一个query，有两个结果A和B，A排在B前面，理论上说A会得到的点击数量比B要多，如果B比A的点击数多，那么说明B比A的相关性要好，需要调换二者的顺序。但是简单的通过点击数来衡量会存在如下的问题：</p><ol><li>点击质量，对于不同结果的点击权重应该不同。</li><li>位置偏见，排在前面的结果本身倾向于受到更多的点击，对后面的结果不公平。<br>所以，对每一个query-url对，根据点击结果在结果列表的位置和点击动作在点击序列中的位置给不同的打分：</li><li>搜索结果排序越靠后，对应的被点击的分值越高。</li><li>在点击序列中，越前面的点击分值越高，但最后一次点击的分值最高</li><li>如果本次搜索没有满足用户的需求，后续出现了点击相关搜素，变换query等情况，则对本次的打分做相应的惩罚。</li></ol><p>思考：这样的打分标准是不是就完美了？</p><p>通过对用户点击行为的分析，根据结果的整体点击率，前三条结果点击率，相关搜索点击等信息来对query整体满意度进行打分。对于在一个session中共现的query pair A和B，如果A的满意度低于B，可以选择B的结果列表中较好的结果插入到A的搜索结果列表中。同时也会引入新的问题，如果“范爷”和“大黑牛”经常同现，但搜索“范爷”的用户并不想看到跟大黑牛相关的新闻，如果将“大黑牛”的结果插入到“范爷”的结果列表中，反而使得搜索的满意度下降。所以在进行结果插入前可以先判断Query A与Query B文本相似度。</p><h3 id="调优结果排序"><a href="#调优结果排序" class="headerlink" title="调优结果排序"></a>调优结果排序</h3><p>有了点击打分之后如何来改善结果的排序呢(点击调权)？<br>例如可以建立一个神经网络模型，简单一点建立一个三层的神经网络，<br>第一层为输入层，每个节点为一个term<br>第二次为隐藏层，每个节点与一组term相连<br>第三层为输出层，每个节点代表一个URL，与隐藏层节点相连<br>每个URL的目标值是计算得到的点击分值，通过反向传播算法来训练更新神经网络中各个边的权重。对于之后的query可以通过该神经网络模型来计算结果的点击排序。</p><h3 id="冷门-VS-热门"><a href="#冷门-VS-热门" class="headerlink" title="冷门 VS 热门"></a>冷门 VS 热门</h3><p>对于热门query和URL可以很容易获得大量的数据支撑，但如果一个query-URL很冷门则获取到的点击数据也很少，则很难对其相关性做出有效的判断，并且如果一个query很冷门即使我们做的效果很好，但是这个query很少出现，投入产出比上也不划算。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过对用户行为的分析可以更好的理解用户行为意图并利用用户的智慧来改善结果排序，此外，用户点击可以作为LTR的一个feature，提升LTR的准确度。</p>]]></content>
      
      
      <categories>
          
          <category> search </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搜索引擎系列(二)---相关搜索</title>
      <link href="/2017/07/29/RelevantSearch/"/>
      <url>/2017/07/29/RelevantSearch/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是相关搜索"><a href="#什么是相关搜索" class="headerlink" title="什么是相关搜索"></a>什么是相关搜索</h2><p>在使用搜索引擎的时候，输入一个关键词之后经常在页面底部或者右侧会出现相关搜索提示。例如搜索”万达”会提示“万达广场”，“万达影院”等。<br>相关搜索的作用是帮助用户更加快速的找到想要的东西，提升用户体验。当你通过一个关键词找不到想要的结果时相关搜索会帮到你，它会推荐你换一个关键词试试，所以它更像是搜索引擎中的一个推荐系统。搜索与推荐是不分家的，在搜索引擎中相关搜索的点击量还是很可观的。</p><h2 id="如何实现相关搜索"><a href="#如何实现相关搜索" class="headerlink" title="如何实现相关搜索"></a>如何实现相关搜索</h2><h3 id="数据思考"><a href="#数据思考" class="headerlink" title="数据思考"></a>数据思考</h3><p>相关搜索要做的事情是根据用户输入的query理解其搜索意图，为用户推荐更多与其意图相近的query。<br>那么如何来找到其他意图相近的query呢？首先我们要收集用户行为数据：搜索日志，展现日志，点击日志等。有了数据之后考虑以下情况：</p><ol><li>在我们使用搜索引擎的时候，输入一个关键词后发现没有我们想要的内容，这个时候我们一般会尝试再换一个关键词来搜索，例如，搜索“spark教程”之后发现不能满足你的需求，又输入“spark视频教程”来搜索，这个动作叫做<code>query变换</code>，后面出现的query就有可能是与前面query的语义相近词。</li><li>不同的用户有不同的搜索习惯，同一件事情，不同的用户也会用不同的词语来描述，如果不同query搜出来的结果相似，那么这些query也是相近的。</li><li>如果同一条结果出现在不同的query的搜索结果集中，那么这些query之间也是有联系的。尤其在不同query的结果集中，同一条结果都被点击了，那么更能表明这两个query是相近的了。</li><li>搜索了A query的多数用户也搜索了B query，那么A跟B存在一定的相似度。</li><li>根据query返回的网页内容相似度来推荐其他query。</li><li>……</li></ol><h3 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h3><p>有了以上的思考之后，接下来看一下如何利用用户行为数据实现相关搜索。</p><h4 id="1-根据query变换"><a href="#1-根据query变换" class="headerlink" title="1. 根据query变换"></a>1. 根据query变换</h4><p>根据之前的分析，在一次搜索行为中一个query之后的其他query可能是我们要找的词。那么首先如何定义<code>一次搜索行为</code>呢。通常在一定的时间跨度内，例如5分钟，用户的搜索行为定义为一次搜索行为，即一个session。搜索日志格式为：<br><code>UA querytime userID IP query result：A B C D E...</code><br>从搜索日志中将用户行为按照session进行分割合并，得到如下结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">userID：1 query：A afterwords:[B,C,D...]</span><br><span class="line">userID：2 query：C afterwords:[E,G,Q...]</span><br></pre></td></tr></table></figure><p>假如一个用户思维比较天马行空，上一秒搜索词为成龙，下一秒换成了人大代表（成龙做过人大代表），但并不能说明二者有很大的联系，所以要统计多个用户的搜索日志，并加入置信度等阈值过滤掉噪音。可得到如下结果：</p><p><code>spark教程：spark入门|spark基础教程|spark教程pdf</code></p><h4 id="2-协同过滤"><a href="#2-协同过滤" class="headerlink" title="2. 协同过滤"></a>2. 协同过滤</h4><p>通过日志我们可以得到如下的数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">user1 query:A,B,C,D</span><br><span class="line">user2 query:B,D,H,K</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>基于UserCF可以给搜索A query的用户推荐H query。</p><p>另外，我们还可以得到如下日志：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">query：A result：url1 url2 url3 ...</span><br><span class="line">query：B result：url2 url3 url4 ...</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>假设我们只取每个query结果的前十条，根据以上数据每个query可由一个由URL组成的向量来表示，每一维的向量值为URL的点展比，通过引入用户的点击行为数据，可以使得结果更加可靠。接下来就可以计算向量的相似度来进行相关推荐。<br>该方法本质也是一种CF：将query看做user，URL看做item，点击行为看做user like item的行为。可以用LFM等机器学习算法来得到相似度。</p><h4 id="3-词向量"><a href="#3-词向量" class="headerlink" title="3. 词向量"></a>3. 词向量</h4><p>有了上述的query得应的URL向量后可以用K-means方法来进行聚类，然后在同一个簇内进行相关搜索推荐。</p><p>另外可以根据词向量来进行相似度计算，首先从日志中得到如下数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">URL1: query1 query2 query3 ...</span><br><span class="line">URL2: query2 query4 query4 ...</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>每个URL可以由多个不同的query来召回，将其合并，一条记录可以看做是一个doc，每个doc由多个词(query)组成，用word2vec计算每个词的词向量，然后根据向量来计算相似度，进行相关搜索推荐。这个word2vec就比较厉害了，在得到的结果里，你搜范冰冰他会推荐给你李晨，你搜李晨除了给你推荐范冰冰之外还会推荐给你大黑牛、跑男等，有意思吧。</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>相关搜索承担着扩展搜索，召回更多结果和帮助用户找到更准确的结果等责任。上述的算法部分算作是离线数据处理部分，处理完后可以将结果推到数据库中供在线部分查询使用。在线部分对用户输入的query进行分词，针对某些长尾词进行词干提取，然后去离线产生的数据中查询获取相关推荐。所以类似的系统设计一般都是重离线，轻在线，使得在线部分能够快速响应用户请求。另外，在线部分要记录用户的行为数据，将其给离线部分使用，形成一个闭环。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>相关搜索是搜索引擎中的一小部分，通过相关搜索可以提升用户搜索体验，并能够反馈给搜索引擎，提升搜索效果。所以，搜索和推荐是分不开的，当然啦，还有广告。上述只是写了一些思路，实际上做起来还有好多需要注意的地方。</p>]]></content>
      
      
      <categories>
          
          <category> search </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>7月盛夏</title>
      <link href="/2017/07/09/2017%E4%B8%8A%E5%8D%8A%E5%B9%B4/"/>
      <url>/2017/07/09/2017%E4%B8%8A%E5%8D%8A%E5%B9%B4/</url>
      
        <content type="html"><![CDATA[<p>转眼已到7月盛夏的季节，2017已经过了一半。前几天跟同事说，到了这个年龄，最让人感到恐惧的就是时间的飞逝。</p><p>所谓一年之计在于春，今年春天的时候回顾自己过去一年的工作与成长，感觉略有失望，跟leader沟通过后，在春末夏初的时候工作上做了新的调整。希望在下一个风口到来时自己不掉队并且能够做些事情。</p><p>比较幸运的是，在过去的一年多做过两个新项目，并且自己是其中一个项目的owner。虽然项目都不算大，但是这种从零到一的经验是宝贵的，尤其在大公司里。最大的一个体会是，即使是一名新人也不能期望别人给你过多的帮助，要学会自己去push。</p><p>闲暇的时候跟朋友聊天，问道：人活着的意义是什么？发现对于这个问题，不同年龄段的人都很难给出属于自己的那份答案。每天都疲于奔波，到了夜深人静的时候扪心自问却不知为何如此。前段时间去青海，在塔尔寺看到了那些虔诚的朝拜者，一步一跪，五体投地的进行朝拜，忽然感悟到人生就是一场修行，急不得。</p><p>后来我在想为什么在青海、西藏等地能够看到让人肃然起敬的信仰，为什么人们想要洗涤心灵的时候都是去青海湖、拉萨而不是去鸟巢和东方明珠塔。或许是因为在青海、西藏地处高原，远离纷扰，所以那里的人更淳朴、更虔诚。人待在大城市之所以会产生困惑和心烦意乱或许是因为周围的喧嚣使得自己过于着急的想要得到某些东西。</p><p>早上醒来看到书架上的书，其中有一半都只是读了一部分，或许自己犯了读书不多，想的太多的毛病。即使思考，也不要停下来思考。</p><p>2017的上半场让我想明白了一些事情，2017的下半场要努力做好全力以赴。</p>]]></content>
      
      
      <categories>
          
          <category> 此刻我在想什么 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go多个pkg的单元测试覆盖率</title>
      <link href="/2017/06/11/golang-test/"/>
      <url>/2017/06/11/golang-test/</url>
      
        <content type="html"><![CDATA[<p>在go test命令后面添加 -cover参数开启测试覆盖率统计，其结果如下：<br><code>ok      models  0.012s  coverage: 71.4% of statements in models</code><br>-coverpkg 标记来指定要被统计的代码包之后，未被指定的代码则肯定不会被统计，即使是被直接测试的那个代码包。<code>go test -coverpkg=./... pkg2</code>可以跑pkg2下的所有单元测试及pkg2所用到的其他包的覆盖率情况。<br>但是由于go不支持<code>go test -coverpkg=./... ./...</code>如果我们有多个pkg，则无法一次性统计出所有的测试覆盖率和跑完全部单元测试。所以需要挨个跑完单元测试然自己来合并覆盖率的结果：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">src</span><br><span class="line">├── pkg1</span><br><span class="line">│   ├── pkg11</span><br><span class="line">│   └── pkg12</span><br><span class="line">└── pkg2</span><br><span class="line">    ├── pkg21</span><br><span class="line">    └── pkg22</span><br><span class="line">    </span><br><span class="line"><span class="keyword">go</span> test -coverprofile=pkg1.cover.out -coverpkg=./... pkg1</span><br><span class="line"><span class="keyword">go</span> test -coverprofile=pkg1.cover.out -coverpkg=./... pkg2</span><br></pre></td></tr></table></figure><p>-coverprofile用来指定统计测试覆盖率信息的输出路径，其内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mode: set</span><br><span class="line">models/bot.go:32.40,46.18 12 1</span><br><span class="line">models/bot.go:49.2,57.35 5 1</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>第一行是测试覆盖的mode，可取值为：set,count,atomic。剩下的行遵循以下的格式：<br>name.go:line.column,line.column numberOfStatements count<br>所以对每个pkg跑完单元测试后可以用以下的命令来合并：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;mode: set&quot; &gt; coverage.out &amp;&amp; cat *.cover.out | grep -v mode: | sort -r | \</span><br><span class="line">awk &apos;&#123;if($1 != last) &#123;print $0;last=$1&#125;&#125;&apos; &gt;&gt; coverage.out</span><br></pre></td></tr></table></figure><p>然后用go自带的工具来将其输出为HTML：<br><code>go tool cover -html=coverage.out -o cover.html</code><br>把整个流程串起来写成脚本如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">set -e</span><br><span class="line"></span><br><span class="line">profile=&quot;cover.out&quot;</span><br><span class="line">htmlfile=&quot;cover.html&quot;</span><br><span class="line">mergecover=&quot;merge_cover&quot;</span><br><span class="line">mode=&quot;set&quot;</span><br><span class="line"></span><br><span class="line">for package in $(go list ./...|grep -v src); do</span><br><span class="line">    coverfile=&quot;$(echo $package | tr / -).cover&quot;</span><br><span class="line">    go test -covermode=&quot;$mode&quot; -coverprofile=&quot;$coverfile&quot; -coverpkg=&quot;$package&quot; &quot;$package&quot;</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line"># merge all profiles</span><br><span class="line">grep -h -v &quot;^mode:&quot; *.cover | sort &gt; $mergecover</span><br><span class="line"></span><br><span class="line"># aggregate duplicated code-block data</span><br><span class="line">echo &quot;mode: $mode&quot; &gt; $profile</span><br><span class="line">current=&quot;&quot;</span><br><span class="line">count=0</span><br><span class="line">while read line; do</span><br><span class="line">    block=$(echo $line | cut -d &apos; &apos; -f1-2)</span><br><span class="line">    num=$(echo $line | cut -d &apos; &apos; -f3)</span><br><span class="line">    if [ &quot;$current&quot; == &quot;&quot; ]; then</span><br><span class="line">        current=$block</span><br><span class="line">        count=$num</span><br><span class="line">    elif [ &quot;$block&quot; == &quot;$current&quot; ]; then</span><br><span class="line">        count=$(($count + $num))</span><br><span class="line">    else</span><br><span class="line">        echo $current $count &gt;&gt; $profile</span><br><span class="line">        current=$block</span><br><span class="line">        count=$num</span><br><span class="line">    fi</span><br><span class="line">done &lt; $mergecover</span><br><span class="line"></span><br><span class="line">if [ &quot;$current&quot; != &quot;&quot; ]; then</span><br><span class="line">    echo $current $count &gt;&gt; $profile</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># save result</span><br><span class="line">go tool cover -html=$profile -o $htmlfile</span><br><span class="line">go tool cover -func=$profile</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ssh远程执行nohup命令不退出</title>
      <link href="/2017/06/11/ssh-nohup/"/>
      <url>/2017/06/11/ssh-nohup/</url>
      
        <content type="html"><![CDATA[<h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h2><p>在本机执行<code>ssh target &quot;nohup sh test.sh &amp;&quot;</code>,ssh并没有立即结束退出，而是等着test.sh执行完才退出，如果提前断开ssh则执行失败。使用<code>nohup</code>和<code>&amp;</code>是想让test.sh在后台执行，并忽略<code>SIGHUP</code>信号，即使执行命令的console退出了，执行命令的进程也可以继续执行。而ssh远程执行nohup的命令不立即退出跟nohup没有太大的关系。将上面的命令换成下面的命令就会立即返回：<br><code>ssh target &quot;nohup sh test.sh &gt;/dev/null 2&amp;1 &amp;&quot;</code></p><h2 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h2><p>ssh在执行远程的命令时，首先在远程的机器上建立一个sshd的进程，然后由这个sshd进程启动一个bash进程来执行传过来的命令。bash进程的0，1，2三个fd通过管道与sshd的相应的文件描述符关联起来。如果远程命令是后台执行会发现其父进程变为1，输入fd重定向到了/dev/null，但是输出和错误的fd是管道，与sshd进程关联，所以这次启动的sshd进程不会结束，必须重定向输出和错误fd。</p><p>对于命令：<code>ssh target &quot;for i in 1 2 3;do sh ./test.sh;done&quot;</code> 在targe机器上执行<code>ps -ef | grep &#39;test\|sshd&#39;</code> 看到下面结果:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">work      14766     1  0 12:42 ?        00:00:00 /bin/bash .test.sh</span><br><span class="line">root      18185  2387  0 16:24 ?        00:00:00 sshd: work [priv] </span><br><span class="line">work      18377 18185  0 16:24 ?        00:00:00 sshd: work@pts/0  </span><br><span class="line">work      18406 18377  0 16:24 pts/0    00:00:00 bash -c <span class="keyword">for</span> i <span class="keyword">in</span> 1 2 3;<span class="keyword">do</span> sh ./test.sh;<span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>由此可以看到进程的递进关系：sshd –&gt; bash -c –&gt; bash。所以本机执行<code>ssh target &quot;cmd&quot;</code>要能够立刻返回要满足：sshd进程没有要等着结束的子进程，这一点靠<code>&amp;</code>来保证。其次，没有其他正在执行的进程与它有管道关系，这点靠重定向来保证。因为重定向只对单个简单命令或单个复合命令有效，对于组合的命令需要放到{}中：<code>ssh target &quot;{ ./test.sh &amp;&amp; ./test.sh; } &gt;/dev/null 2&gt;&amp;1 &amp;&quot;</code>。</p><p>示例一：<br><code>ssh target &quot;for i in 1 2 3; do ./test.sh &gt;/dev/null 2&gt;&amp;1 0&lt;/dev/null; done &amp;&quot;</code><br>ssh不会立即退出，test.sh挨个执行，bash-c是后台执行但是1和2fd跟sshd有管道相连。</p><p>示例二：<br><code>ssh target &quot;for i in 1 2 3; do ./test.sh ; done &gt;/dev/null 2&gt;&amp;1 &amp;&quot;</code><br>ssh立即退出，test.sh挨个执行，执行test.sh的bash由bash-c启动，bash-c进行了重定向，所以子bash继承了重定向。</p><p>示例三：<br><code>ssh target &quot;for i in 1 2 3; do ./test.sh &amp; done &gt;/dev/null 2&gt;&amp;1 &amp;&quot;</code><br>与上面的示例不同的是这里的test.sh不是顺序执行而是近似的同时执行。</p>]]></content>
      
      
      <categories>
          
          <category> bash </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ssh </tag>
            
            <tag> nohup </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搜索引擎系列(一)---Rank的概率模型</title>
      <link href="/2017/05/13/RankModel/"/>
      <url>/2017/05/13/RankModel/</url>
      
        <content type="html"><![CDATA[<h2 id="Rank是干啥的"><a href="#Rank是干啥的" class="headerlink" title="Rank是干啥的"></a>Rank是干啥的</h2><p>Rank是搜索引擎中的精髓模块，Rank所做的事情就是根据用户的query对所有的doc(常见的如网页)进行打分排序。打分排序的依据是doc与query的相关性，而相关性怎么计算呢？把搜索这个动作可拆为两件事情：</p><ol><li>用户给出一个query</li><li>某个doc满足用户的搜索需求</li></ol><p>rank排序依据可以用一个条件概率来表示: $P(d_{i}|q)$其中q是用户给定的一个查询，$d_i$代表doc i满足用户的需求。这个条件概率的描述是：<strong>在给定一个用户查询时，一个特定的doc满足用户需求的概率</strong></p><p>rank要做的就是对所有的doc按照$P(d_i|q)$值的大小进行排序。根据贝叶斯公式可以得到：<br>$$P(d_i|q)=\frac{P(q|d_i)P(d_i)}{P(q)}\tag{1}$$</p><p>这个公式告诉我们：</p><ol><li>不同的doc在同一个query查询下的值是可以比较的</li><li>$P(d_i)$是一个与查询无关的值，这个值可以理解为doc满足用户query的能力，可以在不同的doc间进行比较</li><li>$P(q|d_i)$可以理解为已知一个doc满足了用户的一些query，那么用户查询是q的概率是多少。就好比站长查看用户是从搜索引擎中的哪些query引到自己的网站。这个值反映的是一个doc对不同的query满足程度的比较，非doc间可比较。该值难以直接计算，它将一个已知query求条件概率的线上计算问题变成了一个已知doc求条件概率的线下计算问题。</li><li>$P(q)$是指一个特定查询出现的概率。该值较大时代表一个热门query，(1)式中的分子必须较大才能满足用户需求。如果该值较小，(1)式中分子无需太大也能满足用户的需求。</li></ol><h2 id="PageRank"><a href="#PageRank" class="headerlink" title="PageRank"></a>PageRank</h2><p>传统的TF*IDF算法，TF代表词频，IDF代表逆向文档频率，它主要思想为：</p><ol><li>某个词或短语在一篇文章中出现的次数越多，越相关。</li><li>整个文档集合中包含某个词的文档数量越少，这个词越重要。</li></ol><p>可见主要是针对(1)式中的$P(q|d_i)$，对$P(d_i)$考虑的比较少。而$P(d_i)$是一个查询无关的值，理解为在完全不知道用户查询的情况下，一个doc满足用户需求的情况，也可以理解为无查询推荐。它表示，即使在不知道用户想要什么，或者对用户的需求分析错的情况下，仍然可以尽量给出满足用户需求的doc。对于$P(d_i)$，google 利用一个随机浏览模型（即pagerank）进行计算，即认为这个值近似等于一个不断随着超链随机浏览的人看到网页i的概率。这个值的加入显著地提升了搜索质量。<br>由此可以窥见，推荐与搜索本来就是不分家的，有推荐的搜索才是真正的搜索，才体现出搜索的“情感”(query解析、排序、页面展示)，搜索引擎的难点(用户意图理解、有价值信息的展示)。<br>目前由于链接作弊等原因PageRank与真正想要值的差距已经越来越大了，渐渐的被其他算法所替代。</p><h2 id="页面因子"><a href="#页面因子" class="headerlink" title="页面因子"></a>页面因子</h2><p>我们认为对于一个doc先验的满足用户需求的概率由很多因素决定，如：页面质量、被其他页面链接数等。我们可以将其抽象为一系列页面因子组成的向量，对于一个doc w=&lt; X1…Xn &gt;,令S为用户得到满足的事件。<br>$$p(d)=p(s|w)=p(s|x_1,x_2,…x_n)=\frac{p(x_1..x_n|s)p(s)}{p(x_1..x_n)}$$<br>假设各页面因子是相互独立的<br>$$p(s|&lt; x_1,..x_n &gt;）=\frac{p(x_1|s)p(x_2|s)…p(x_n|s)p(s)}{p(x_1)…p(x_n)})$$<br>其中p(xi|s)是对于满足用户需求的某一个页面因子的值，例如：用户点击数等。<br>在(1)式中如果p(di)=0，无论其他值如何这个doc满足用户需求的概率都是0，这种doc就是属于垃圾doc，没必要参与rank。</p><h2 id="query分析"><a href="#query分析" class="headerlink" title="query分析"></a>query分析</h2><p>一个query可以被拆分为多个term，那么(1)式中p(q|di)的线下计算可以拆分为p(t|di)的计算。通过对query的分解变换将其转换为好计算的近似值，一个query可以分解为q=&lt; t1..tn &gt;,分解方式可以为：</p><ol><li>完全不分解：$$p(q|d_i)=p(&lt; t_1..t_n &gt;|d_i)\tag2$$</li><li>分解为相互独立的term：$$p(q|d_i)=p(t_1|d_i)..p(t_n|d_i)$$</li><li>每个term都只跟前一个term相关:<br>$$p(q|di)=p(t1|di)p(t2|di,t1)p(t3|di,t2)…p(tn|di,t_{n-1})$$</li><li>查询的term必须按照一定顺序出现</li></ol><h2 id="多样性"><a href="#多样性" class="headerlink" title="多样性"></a>多样性</h2><p>如果一个doc可以满足多个query，那么：$\sum_jp(q_j|d_i)=1$ 实际情况中我们要根据query来分析用户的真正查询意图，同一个字符串可能对应多个用户需求。例如：对于“人人”这个查询，可能对应两种需求：人人网和人人车。假设其中对人人车的需求要高于对人人网的需求，(1)式中的排序会偏袒热门需求，因为对于冷门需求(1)式中对分子的权值要求比较低，如果不考虑“人人”对两种需求各自出现的概率那么满足“人人网”的doc在排序处于不利的位置。针对多样性，可以参考以下公式，其中$q_s$代表查询字符串：<br>$$p(d_i|q_s)=p(q_1|q_s)p(d_i|q_1)+P(q_2|q_s)p(d_i|q_2)=p(q_1|q_s)\frac{p(q_1|d_i)}{p(q_1)}+p(q_2|q_s)\frac{p(q_2|d_i)p(d_i)}{p(q_2)}$$</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>在搜索引擎中可以引入其他的因素来扩展这个概率模型，比如引入时效性、权威性、引入地域等各种用户个性化信息。<br>另外目前各大搜索引擎希望在第一页(前10条)或者前3条结果中来满足用户需求，而不仅仅局限于某一个doc满足用户需求概率的最大化。<br>除了返回网页链接外，还可以通过增加返回结果类型的方式来满足用户的需求，例如：返回阿拉丁，框应用等。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>该模型解释了rank的排序依据以及如何将其分解为子目标进行计算，对于不好计算的变量，可以通过将其与好算的变量关联起来或者想办法近似的计算。近似计算就会用到一些假设，如果结果不对那么之前的假设就可能有问题。</p><p><strong>各种近似的计算都是对理论模型的逼近，理论模型存在的意义之一在于，它让我们的思考系统化，告诉我们在逼近什么，努力的方向在哪，离目标还有多远。想尽一切办法，越来越精确地逼近理论值，这就是进步。</strong></p>]]></content>
      
      
      <categories>
          
          <category> search </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据与人工智能</title>
      <link href="/2017/04/22/BigData-And-AI/"/>
      <url>/2017/04/22/BigData-And-AI/</url>
      
        <content type="html"><![CDATA[<p>前些年大数据这个词很火，最近一两年AI又火了起来，现在出门不谈点AI 都不好意思跟人Say Hi。</p><p>为什么经历了两个冬天的AI在大数据火了之后迎来了新的春天？</p><h3 id="仿生学不是出路"><a href="#仿生学不是出路" class="headerlink" title="仿生学不是出路"></a>仿生学不是出路</h3><p>AI已经出现几十年了，而最近五年发展十分迅速，为什么？早期研究人工智能的学者认为要让机器获得智能，首先要了解人类是如何产生智能的，然后让计算机按照人的思路去做，要让机器像人一样思考才能获得智能。这种方法论被称为『鸟飞派』，看看鸟是怎么飞的，模仿鸟的动作人就能飞上天。而实际上飞机的发明依靠的是空气动力学而不是仿生学。</p><h3 id="数据-统计"><a href="#数据-统计" class="headerlink" title="数据+统计"></a>数据+统计</h3><p>后来人类又找到了另一条路子：数据+统计，即采用数据驱动和超级计算的方法。数据最大的作用在于承载信息。在远古时代尼罗河畔的土著居民通过观察天象来准确推测洪水到来和退去的时间，以此来判断一年农耕的时间和节气。但是由于能采集到数据量（例如音频、图像）有限或者计算能力不够无法处理大规模数据导致AI在早些年没有得到快速的发展。</p><p>近些年大数据技术得到快速发展，人类可以获得到越来越多的数据。这些数据无论在体量、多维度还是完备性都超过以往。在一些无法确定的因果关系中，数据所包含的信息可以帮助我们消除一些不确定性，甚至数据之间所呈现出的相关性可以取代原来的因果关系，帮助我们得到答案。例如：在图像识别方面，学术上常用的基准测试是一百万幅，所用图像最多的学术论文是1500万幅，而百度用来训练最先进的人脸识别系统所用的数据量为：两亿幅！可见，数据已经开始成为公司的一种资产。</p><p>大数据技术带来的另一个红利是对大规模数据的处理能力，近几年对GPU的使用是异构计算发展的一个典型代表，在此技术之上实现了能够利用巨大数据集的机器学习平台。</p><p>所以，大数据技术带来的两样东西：大规模数据集和高性能计算，促进了AI的发展。</p><h3 id="现在的AI"><a href="#现在的AI" class="headerlink" title="现在的AI"></a>现在的AI</h3><p>现在的AI能做什么？除了AlphaGo打败了李世石之外，在语音识别、图像识别、自动驾驶等方面也取得了较好的发展。Andrew Ng 指出AI进展最快的领域是人类能做到的领域，而人类难以做到的事情，目前AI也很难做到。原因有三：</p><ol><li>人类能做的，至少是可行的。</li><li>可以利用人类的经验数据作为培训样本</li><li>人类可以提供指导、校验，进而改善AI</li></ol><p>很多领域一旦超过人类自身的能力，AI发展也变得缓慢。由此引发的矛盾：<strong>如果AI一直在做人类可以做的事情，实际上是在跟人类进行竞争</strong>。</p><h3 id="未来的AI"><a href="#未来的AI" class="headerlink" title="未来的AI"></a>未来的AI</h3><p>在未来人工智能相关的技术和工具会如同水电一样，由专门的公司向全社会提供，各行各业的人们将用这个技术来改变自己所在的行业，就如同利用电力来改变制造业一样，由此将会带动整个人类社会的升级和变迁。</p>]]></content>
      
      
      <categories>
          
          <category> 此刻我在想什么 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>躁动的季节，躁动的心</title>
      <link href="/2017/03/26/RestlessHeart/"/>
      <url>/2017/03/26/RestlessHeart/</url>
      
        <content type="html"><![CDATA[<p>春天来了，又到了<del>动物们</del>人们开始躁动的季节，正所谓『金三银四』，又到了换工作最疯狂的季节了，地铁站里贴满的猎聘、直聘BOSS等广告彰显出人们躁动的荷尔蒙。而我，在这个躁动的季节里也觉得格外焦虑。</p><p>为什么会感到焦虑呢？因为对自己的现状感到不满，想变得更好，可是又没有明确的路，摸索前行的过程中时常会感到迷茫。</p><p>回头审视了一下过去的一年，自己感觉并没有做出什么让自己满意的成绩，尽管组里的人都觉得我去年表现的不错，但是从自身成长的角度来说，提升不多，做的事情依靠之前的经验和能力就能够cover住。看了一下公司内外高级职位的招聘JD觉得自己离岗位要求还有一定的差距，这个时候我有点方了。。。</p><p>正常来说，一个人但凡有点上进心，如果发现自己在较长的一段时间里没有明显的提升就应该会感到焦虑。技术方面的成长，我个人比较倾向于Application-Oriented，所以如果所做的事情只是在重复之前的技能对于自身的提升几乎是毫无促进作用的。</p><p>可能是时候换个环境了。换工作是一件比较纠结的事情，想要找到跟自己match度比较高的岗位、业务、老大那是可遇而不可求的。同时还要考虑到薪酬、晋升、未来发展等问题。或许又要逼近下一个人生的十字路口了吧，至于怎么选，还没想好。</p>]]></content>
      
      
      <categories>
          
          <category> 此刻我在想什么 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么更新频率降低了呢？</title>
      <link href="/2017/03/01/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9B%B4%E6%96%B0%E9%A2%91%E7%8E%87%E9%99%8D%E4%BD%8E%E4%BA%86%E5%91%A2/"/>
      <url>/2017/03/01/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9B%B4%E6%96%B0%E9%A2%91%E7%8E%87%E9%99%8D%E4%BD%8E%E4%BA%86%E5%91%A2/</url>
      
        <content type="html"><![CDATA[<h2 id="Status"><a href="#Status" class="headerlink" title="Status"></a>Status</h2><p>自从将博客从<a href="http://blog.163.com/xh_ding/" target="_blank" rel="noopener">旧地址</a>搬过来之后更新速度明显下降了好多，在过去的2016年里总共也没写几篇，甚至连年度总结都省去了。为什么博文更新频率降低了呢？为什么呢！？</p><h2 id="Why"><a href="#Why" class="headerlink" title="Why"></a>Why</h2><p>为什么会这样呢？</p><p>1.<em>懒</em><br>    过去的一年确实有些变懒了，除了写东西偷懒，在思维上也有些偷懒了，思考不够勤奋。<br>2.<em>不够聚焦</em><br>    这也是老毛病了，总是思绪乱飞，经常被一些被热捧的技术吸引眼球，但又浅尝辄止，没有深入的学习。皮毛的东西不足道之。<br>3.<em>阅读量降低</em><br>    跟之前的状态相比，每天专注的阅读量下降了不少，时间都去哪了呢？除了工作及聊天扯淡外，发现自己最近比较喜欢发呆，总期望在发呆中能想明白些什么事，可真要想起来思绪像一团找不到头的毛线团，比较乱。<br>4.<em>希望能够提升文章质量，持续输出高质量作品</em><br>    这点跟第二点是有些关联的，不聚焦便也不能够产生高质量的内容。回看之前的博客内容，尤其<a href="http://blog.163.com/xh_ding/" target="_blank" rel="noopener">旧地址</a>有许多是一些比较基础的知识介绍，并且文章的质量也并不是特别高，希望以后能不断的提高文章质量。</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>反思一下，如何解决以上的问题呢？</p><p>1.<em>focus</em><br>    年初的时候仔细想了一下，『聚焦』是今年核心主题，无论是工作还是生活。<br>    人类科技文明经过千年的发展自身体系已十分的庞大，任你心再狂野，想要做到在多方面的精通乃至博古通今都是非常困难的，其中任何一个分支的深入学习所花费的时间都足以吞噬一个人的一生。<br>    所以需要聚焦，把能量集中才有可能产生爆发。<br>2.<em>勤思考</em><br>    不能用行动上的勤奋来掩盖思维上的懒惰。<br>3.<em>多阅读</em><br>    多阅读，尤其是技术方面系统的学习某个领域的知识。另外，通过阅读也可以学习到别人是如何用通俗易懂的语句将一个问题描述清楚的。希望能把之前收藏的书单都能看完。时间从哪来呢？四个字：多读少浪。<br>4.<em>多练习</em><br>    多联系写作。斯蒂芬·平克曾经说过：写作之难，在于把网状的思考，用树状的结构，体现在线性展开的语句里。多练习写作可以使思维逻辑得到极大的锻炼。在勤思考、多阅读的基础上定期的有产出，文章不急于一次就写好，写的过程多想想如何用简单的语言来讲清楚一件事情。</p><p>2017的第一个Q就剩最后一个月了，不能再这样蹉跎下去了。</p>]]></content>
      
      
      <categories>
          
          <category> 此刻我在想什么 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>分布式锁设计</title>
      <link href="/2016/12/19/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E8%AE%BE%E8%AE%A1/"/>
      <url>/2016/12/19/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<p>分布式环境下，多台机器上多个线程对同一份数据进行操作如果不做处理防范，就有可能出现类似『数据重复入库』、『商品超卖』等情况，在这种情况下需要分布式锁来对分布式环境下临界资源做互斥。</p><p>那么如何来做呢？</p><p>想想单机多线程的时候我们是如何保证互斥的，单机多线程的情况下所有的线程都去尝试获取同一把锁。换到分布式环境下我们把局限于一台机器内的锁提出来，其实就是利用一个大家都能访问的公共资源来实现分布式锁。这个公共资源可以是redis，可以是zookeeper，也可以是其他的某个资源。这里我们主要考虑用redis的setnx来实现。</p><p>设计一个分布式锁主要考虑以下几点：</p><h2 id="互斥"><a href="#互斥" class="headerlink" title="互斥"></a>互斥</h2><p>分布式系统中运行着多个节点，必须确保在同一时刻只能有一个节点的一个线程获得锁，这是最基本的。</p><h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><p>用Redis来实现分布式锁最简单的方式就是在实例里用setnx命令来创建一个键值，当一个节点想要释放锁时，它只需要删除这个键值即可。</p><p>上述方案看上去很美好，在分布式环境里，当一个节点获取到锁之后宕机了，或者因为网络不通无法执行释放锁的操作，则其他节点都无法申请到锁。</p><p>（1）锁的时效性<br>所以这里要加一个锁的时效性，避免单点故障造成死锁，但同时也要保证一旦一个节点获取到锁，在节点存活时不能被其他节点解锁。</p><p>（2）避免误删锁<br>Case：一个节点获取到锁开始执行业务，不幸被某个操作阻塞了很长时间，过了超时时间后自动释放了这个锁，过了一段时间这个节点执行完之后又尝试删除这个其实已经被其他节点拿到的锁。所以简单粗暴的直接删除有可能造成一个节点删除了其他节点的锁。<br>为了避免误删可以给锁加一个节点ID+线程ID作为签名的属性（用hset命令），这样每个锁就只能被获取到锁的节点删除。<br>另外还可以给每个获取锁的线程设定一个TimerTask，在线程执行任务的过程中定时的延长锁的时效时间，这样就不会因为执行时间超过了超时时间导致锁自动释放，也就是续租锁。但为了提升性能应尽量避免加锁时间太长，尽量减少锁的粒度，如下面一条所说。</p><h2 id="锁的性能"><a href="#锁的性能" class="headerlink" title="锁的性能"></a>锁的性能</h2><p>（1）加锁的事务或者操作尽量粒度小，减少其他节点申请锁的等待时间，提高处理效率和并发性。<br>（2）降低获取锁的频率，尽量减少Redis压力。让节点申请锁的时候有一个等待时间，而不是不停的循环尝试获取锁。<br>（3）持锁的客户端解锁后，要能通知到其他等待锁的节点，而不是隔一段时间尝试获取一次锁。</p><p>针对上面后两条，Redisson采用Semaphore及Redis的订阅/发布消息来控制，通过订阅/发布可以避免空转。<br>如果锁当前是被占用的，那么等待释放锁的消息，当锁释放并发布释放锁的消息后，信号量的 release() 方法会被调用，此时被信号量阻塞的等待队列中的一个线程就可以继续尝试获取锁了。<br>此处虽然Semaphore只是进程内部粒度的锁的，但是也可以一定程度减轻Redis节点的压力，因为每个节点上的请求数量少了，Redis的压力也就少了。</p><h2 id="锁重入"><a href="#锁重入" class="headerlink" title="锁重入"></a>锁重入</h2><p>可重入锁，即在已经获取锁的基础之上，再次获取当前的锁。在释放时，之前获取了N次，那么也需要相应的unlock N次，才表示最终锁被成功释放。<br>分布式锁是否需要设计为可重入的要根据具体的业务来判断。通过上文所说的锁的签名可以判断当前线程是否已经获得锁，如果已经获得则count增加。</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>是否采用分布式锁及最终锁的实现方案还是要看具体的业务需求。<br>推荐看一下Redis官方文章：<a href="https://github.com/antirez/redis-doc/blob/master/topics/distlock.md" target="_blank" rel="noopener">Distributed locks with Redis</a><br>中文翻译：<a href="http://ifeve.com/redis-lock" target="_blank" rel="noopener">用Redis构建分布式锁</a><br>另外，<a href="https://github.com/redisson/redisson/wiki/Redisson%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D" target="_blank" rel="noopener">Redisson</a>实现了Redis官方提出的RedLock算法</p>]]></content>
      
      
      
        <tags>
            
            <tag> Distributed Locks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用户评论挖掘</title>
      <link href="/2016/12/04/%E7%94%A8%E6%88%B7%E8%AF%84%E8%AE%BA%E6%8C%96%E6%8E%98/"/>
      <url>/2016/12/04/%E7%94%A8%E6%88%B7%E8%AF%84%E8%AE%BA%E6%8C%96%E6%8E%98/</url>
      
        <content type="html"><![CDATA[<p>随着互联网的发展，越来越多的人选择在网上消费，并且越来越的证据表明商品的评论信息会影响到消费者的消费决定。评论挖掘的主要任务是从评论中了解到用户对产品的哪些功能、属性进行了怎样的评论，并抽取成简短有效的信息。</p><p>评论挖掘主要有以下几个子任务：</p><h2 id="识别、抽取产品特征"><a href="#识别、抽取产品特征" class="headerlink" title="识别、抽取产品特征"></a>识别、抽取产品特征</h2><p>产品特征分为显示特征和隐含特征。</p><ul><li>显示特征<br>显示特征是直接出现在产品的评论中，描述产品的性能或功能的名词或名词短语。</li><li>隐含特征<br>隐含特征没有在语句中直接进行描述，需要对句子进行语义理解才能得到，提取隐含特征需要自然语言的完全理解技术 。<br>特征词满足以下三个条件之一：<br>（1） 给定评论对象的一部分<br>（2） 给的评论对象的一个属性<br>（3）    给定评论对象的一个部分的一个属性<br>特征提取分为人工标记和自动提取两种方法。人工标记一般由领域专家来完成。<br>自动提取过程：对语料进行词性标注，提取其中的名词短语，利用关联规则挖掘出频繁项，在频繁项候选集上做密实度修剪和冗余修剪，去掉无用的短语和合并相似的短语。</li></ul><h2 id="特征语意去重"><a href="#特征语意去重" class="headerlink" title="特征语意去重"></a>特征语意去重</h2><p>首先介绍一下什么是词向量和语言模型。<br>（1） 词向量就是用来将语言中的词进行数学化的一种方式。有了词向量之后就可以对词进行聚类、分类、计算相似度等等。<br>（2） 语言模型就是用来计算一个句子的概率的模型，简单来说就是判断一句话是不是正常人说出来的。常见的应用场景：机器翻译、语音识别得到若干候选之后，可以利用语言模型挑一个尽量靠谱的结果。</p><p>特征词去重采用聚类的方法对特征词进行聚类，归属于同一类的即为同义词。其中判断词语的相似度，采用计算特征词的词向量，然后计算向量间的相似度（例如计算向量夹角）的方法。</p><p>关于同义词聚类，Google推出的Word2Vec是一个不错的工具，关于Word2Vec的介绍请参考之前的博文：<a href="http://blog.163.com/xh_ding/blog/static/1939032892014312102457581" target="_blank" rel="noopener">自然语言处理之Word2Vec</a> 。其中一个思路是：用word2vec的到词向量然后用kmeans进行同义词聚类。</p><h2 id="识别产品特征对应的观点词"><a href="#识别产品特征对应的观点词" class="headerlink" title="识别产品特征对应的观点词"></a>识别产品特征对应的观点词</h2><p>对评论语料进行词法和依存句法分析生成三元组：<br><code>&lt;Attribute, Subject, Value&gt;</code><br>Subject：产品<br>Attribute：特征<br>Value：特征观点</p><h2 id="分析评论的情感及强度"><a href="#分析评论的情感及强度" class="headerlink" title="分析评论的情感及强度"></a>分析评论的情感及强度</h2><p>把用户评论句子切分为只包含一个特征词的短句并将评论抽象概括为<code>&lt;Holder, Topic, Sentimentl&gt;</code>。<br>采用基于情感词典的方式计算短句的情感得分：</p><p>$$Score=\sum_{ w_i \in V} \frac{S_w}{dis(w_i, f)}$$</p><p>$w_i$ 代表句子中的情感词</p><p>V代表情感词典中情感词集合</p><p>$S_{w_i}$代表$w_i$在情感词典中的极性值</p><p>$f$代表该句子中的特征词</p><p>$dis(w_i, f)$代表在句子中情感词$w_i$与特征词f之间的距离，距离越远情感词$w_i$对特征词f的影响越小，因此赋予的权重也越小。</p><p>在此基础之上应用否定词、转折词规则以及基于上下文情感的连词规则和蕴含连词规则。最终计算得到短句的情感倾向得分。</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>以上是针对中文的用户评论挖掘的一个大致粗略的过程，也算是对之前一个回答的补充：<a href="https://www.zhihu.com/question/20905103/answer/16628186" target="_blank" rel="noopener">淘宝的评论归纳是如何做到的？ - 慕希颜的回答 - 知乎 </a><br>在进行挖掘前的一些数据清洗工作（例如计算评论的质量，去掉无效、低质量评论）就不详细介绍了，如有不对的地方请指正，谢谢。</p>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 评论挖掘 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机开机过程</title>
      <link href="/2016/12/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%82%B9%E4%BA%AE%E8%BF%87%E7%A8%8B/"/>
      <url>/2016/12/02/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%82%B9%E4%BA%AE%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>从按下计算机的电源按钮到出现欢迎页，这个过程都发生了什么？<br>我们知道计算机启动叫boot，重启叫reboot，这里的boot其实是bootstrap的缩写。计算机运行时其硬件交由软件来控制，所以计算机要启动必须要运行软件，但是计算机不启动就无法运行软件，这是一个鸡生蛋和蛋生鸡的过程。<br>有一句谚语：</p><blockquote><p>“pull oneself up by one’s bootstraps”</p></blockquote><p>意思是说拽着自己的鞋带把自己拉起来。这也充分反映了计算机的启动是一个矛盾的过程，时间久了就简称boot。</p><p>计算机启动的过程主要有四个阶段：</p><h2 id="一、BIOS"><a href="#一、BIOS" class="headerlink" title="一、BIOS"></a>一、BIOS</h2><p>内存包括随机存储器（RAM），只读存储器（ROM），以及高速缓存（CACHE）。开机程序被刷入ROM芯片中，按下电源键之后计算机首先去读取ROM，这段程序被称作基本的输入输出系统(Basic Input/Output System)简称BIOS.</p><p>BIOS程序首先检查计算机硬件能否满足运行的基本条件，这叫做”硬件自检”（Power-On Self-Test），缩写为POST。如果硬件出现问题，主板会发出不同含义的蜂鸣，中止启动。</p><p>在BIOS的菜单中有一项『设定启动顺序』，这个启动顺序实际上是一个外部存储设备的排序，在BIOS完成硬件自检后按照这个启动顺序将控制权优先交给排在前面的设备。</p><h2 id="二、主引导记录-MBR"><a href="#二、主引导记录-MBR" class="headerlink" title="二、主引导记录(MBR)"></a>二、主引导记录(MBR)</h2><p>BIOS按照『启动顺序』把控制权交给排在第一个的存储设备。计算机读取该设备的第一个扇区，即前512个字节，并判断该设备是否能用于启动（512个字节的最后两位是不是0x55和0xAA），如果不能则将控制权交给启动顺序中的下一个设备。</p><p>这512个字节主要用来告诉计算机哪个分区是激活分区，并将控制权交给激活分区，被称为『主引导记录』(Master boot record)，简称MBR。MBR由三部分组成：<br>（1） 第1-446字节：调用操作系统的机器码。<br>（2） 第447-510字节：分区表（Partition table）。<br>（3） 第511-512字节：主引导记录签名（0x55和0xAA）。</p><p>一个硬盘可以分成多个分区，其中分区表中记录了硬盘的分区信息。不同的分区可以安装不同的操作系统，因此MBR需要知道将控制权交给哪个分区。</p><p>分区表只有64个字节，分为4项，所以一个硬盘最多只能有四个一级分区，即主分区。每一项的16个字节记录的内容为：<br>（1） 第1个字节：如果为0x80，就表示该主分区是激活分区，控制权要转交给这个分区。四个主分区里面只能有一个是激活的。<br>（2） 第2-4个字节：主分区第一个扇区的物理位置（柱面、磁头、扇区号等等）。<br>（3） 第5个字节：主分区类型。<br>（4） 第6-8个字节：主分区最后一个扇区的物理位置。<br>（5） 第9-12字节：该主分区第一个扇区的逻辑地址。<br>（6） 第13-16字节：主分区的扇区总数。</p><p>随着硬盘越来越大四个分区已经不够用了，但分区表只有四项，因此规定其中只有一项可以设置为扩展分区。所谓”扩展分区”，就是指这个区里面又分成多个区。这种分区里面的分区，就叫做”逻辑分区”（logical partition）。<br>扩展分区的第一个扇区叫做”扩展引导记录”（Extended boot record），里面也包含了一张分区表，记录着下一个逻辑分区的位置，以此类推，直到某个逻辑分区分区表只包含自己。</p><h2 id="三、硬盘启动"><a href="#三、硬盘启动" class="headerlink" title="三、硬盘启动"></a>三、硬盘启动</h2><p>此时将计算机的控制权交给硬盘的某个分区了。计算机会读取激活分区的第一个扇区，叫做”卷引导记录”（Volume boot record），VBR告诉计算机操作系统位于该分区的哪个位置，然后计算机加载OS。</p><p>特殊情况下，计算机读取”主引导记录”前面446字节的机器码之后，不再把控制权转交给某一个分区，而是运行事先安装的”启动管理器”（boot loader），由用户选择启动哪一个操作系统，目前常用的启动管理器是Grub。</p><h2 id="四、操作系统"><a href="#四、操作系统" class="headerlink" title="四、操作系统"></a>四、操作系统</h2><p>最后控制器交给操作系统，首先载入操作系统的内核，例如Linux，先载入/boot下的kernel，然后运行/sbin/init，根据/etc/initab产生PID为1的init进程，他是所有进程的父进程。然后init进程加载各个模块，例如网络、XWindow等，直至运行/bin/login跳出登录界面等待用户输入用户名和密码。</p><p>至此，全过程结束。</p>]]></content>
      
      
      <categories>
          
          <category> OS </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>mysql的set names</title>
      <link href="/2016/11/13/mysql%E7%9A%84set%20names/"/>
      <url>/2016/11/13/mysql%E7%9A%84set%20names/</url>
      
        <content type="html"><![CDATA[<h2 id="为了Emoji"><a href="#为了Emoji" class="headerlink" title="为了Emoji"></a>为了Emoji</h2><p>最近写东西的时候需要支持Emoji表情，用MySQL作存储需要版本5.5.3+并且字符集设置为utf8mb4，由于是跟其他服务公用一个MySQL存储服务所以不能动MySQL的全局配置，在针对数据库和表设置完字符集设置后，应用程序连接数据库时指定default-character-set为utf8mb4会有报错提示（不知道是不是应用程序使用的MySQL驱动不支持的缘故），所以存储Emoji表情的时候还是会提示『Incorrect string value』，最后解决方案是在应用程序连接数据库的时候加上’set names utf8mb4’。<br>MySQL执行set names utf8mb4后等同于临时设置如下字符编码：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> character_set_client = utf8mb4;       </span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span> character_set_results = utf8mb4;      </span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span> character_set_connection = utf8mb4;</span><br></pre></td></tr></table></figure><p>在对MySQL进行数据插入和查询的时候经过如下的过程：<br>插入：client→connection→server<br>查询：server→connection→results</p><p>当三者保持一致的时候就不会出现乱码等问题了。</p>]]></content>
      
      
      <categories>
          
          <category> Database </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于密码保护</title>
      <link href="/2016/08/28/%E5%85%B3%E4%BA%8E%E5%AF%86%E7%A0%81%E4%BF%9D%E6%8A%A4/"/>
      <url>/2016/08/28/%E5%85%B3%E4%BA%8E%E5%AF%86%E7%A0%81%E4%BF%9D%E6%8A%A4/</url>
      
        <content type="html"><![CDATA[<p>作为一名开发者，开发一个用户账户系统很可能就是你工作内容的一部分，其中比较重要的事情就是如何保护用户的密码，当系统被攻破、数据库被拖库时如何降低泄露用户原始密码的风险是一件值得深思的问题（还记得当年CSDN被拖库后爆出系统存储了用户的明文密码吗？）。比较行之有效的办法是对用户密码进行加盐哈希。</p><h2 id="为什么要对密码进行哈希"><a href="#为什么要对密码进行哈希" class="headerlink" title="为什么要对密码进行哈希"></a>为什么要对密码进行哈希</h2><p>首先我们希望即使被拖库后用户的明文密码也不会遭到泄露，以免使得坏蛋们可以拿着这些明文密码再去撞别家的库。<br>哈希算法是一个单向函数，它可以将任何大小的数据转化为定长的“指纹”，并且无法被反向计算。而且只要数据源改动了一点，哈希的结果也会完全不同。这样的特性使得它非常适合用于保存密码，因为我们期望加密后的密码无法被解密，但同时也能保证正确校验每个用户的密码。（这里的哈希算法跟数据结构里hashmap中的哈希算法可不是同一回事哦）</p><h2 id="单纯的哈希安全吗？"><a href="#单纯的哈希安全吗？" class="headerlink" title="单纯的哈希安全吗？"></a>单纯的哈希安全吗？</h2><p>在用户的密码上做一次加密哈希函数实际上并不是十分的安全，因为目前已经有办法可以快速的把密码从简单的哈希值里恢复出来。例如：字典攻击、暴力攻击等。</p><ul><li><p>字典攻击</p><p>在一个字典文件里包含了常见的短语、单词和常用密码等字符串以及其对应的哈希值，用它们和密码的哈希值做对比，如果相同则对应字典里的值就是密码。例如用查表的方式，将预先计算好的哈希值和对应的密码存放到一个用于快速查询的数据结构中，厉害一点的即使存储了上亿个哈希值每秒也能进行数百次查询。</p></li><li><p>暴力攻击</p><p>暴力攻击会尝试每一个在给定长度下各种字符的组合。这种方式需要进行大量的计算，也通常是破解哈希加密中效率最低的办法，但是它最终会找到正确的密码。但只要密码需要足够长，以至于遍历所有可能的字符串组合将耗费太长时间，使得攻击者放弃这种暴力的方法。</p></li><li><p>彩虹表</p><p> 彩虹表是一种在时间和空间的消耗上找寻平衡的破解技术。它和查表法很类似，但是为了使查询表占用的空间更小而牺牲了破解速度。因为它更小，于是我们可以在一定的空间内存储更多的哈希值，从而使攻击更加有效。</p></li></ul><h2 id="加盐"><a href="#加盐" class="headerlink" title="加盐"></a>加盐</h2><p>加盐是目前常用的一种让查表法和彩虹表都失效的计数。即在密码中混入一段“随机”的字符串再进行哈希加密，这个被字符串被称作盐值。由于随机化了哈希值，攻击者不能预先生成彩虹表，增加了攻击成本。另外每个用户都是用一个独一无二的随机盐使得反向查表也变得很难。</p><h2 id="加盐哈希的误区"><a href="#加盐哈希的误区" class="headerlink" title="加盐哈希的误区"></a>加盐哈希的误区</h2><ul><li><p>盐值重复</p><p>如果盐值被硬编码到代码里或者用一个固定的随机值，那攻击者只要把盐值用到每个猜测密码上仍然可以用反向查表法或者针对这个系统生成一份彩虹表。</p></li><li><p>盐值太短</p><p> 如果盐值太短，攻击者可以构造一个查询表包含所有可能的盐值。为了使攻击者无法构造包含所有可能盐值的查询表，盐值必须足够长。一个好的做法是使用和哈希函数输出的字符串等长的盐值。</p></li><li><p>盐值随机性不够</p><p> 有人喜欢使用用户名、注册时间作为盐值，这些都不具有符合密码学要求的随机性。盐值应该使用基于加密的伪随机数生成器，例如：java中的java.security.SecureRandom。其他语言：PHP、C/C++、Python都有对应的实现。</p></li></ul><h2 id="关于组合哈希"><a href="#关于组合哈希" class="headerlink" title="关于组合哈希"></a>关于组合哈希</h2><p> 经常看到有人使用组合哈希函数，人们认为将哈希函数组合起来结果会更加安全，使用多种哈希函数会使得计算更慢，从而破解变慢。网上多见的组合有：</p><ul><li>md5(sha1(password))</li><li>md5(md5(salt) + md5(password))</li><li>sha1(sha1(password))</li><li>sha1(str_rot13(password + salt))</li><li>md5(sha1(md5(md5(password) + sha1(password)) + md5(password)))</li></ul><p><strong>但有人对此提出质疑：他们认为实际上这样做几乎没有好处，仅仅造成了函数之间互相影响的问题，甚至有时候会变得更加不安全。</strong></p><p>使用组合哈希函数是考虑到如果攻击者不知道系统用的哪种哈希函数就不会预先生成彩虹表，但是如密码学中著名的Kerckhoff准则所说，攻击者还是比较容易拿到源码的。</p><p> <strong>Kerckhoff准则：</strong>系统的保密性不依赖于加密体质或者算法的保密，而依赖于密钥。</p><h2 id="关于慢哈希"><a href="#关于慢哈希" class="headerlink" title="关于慢哈希"></a>关于慢哈希</h2><p>使用随机盐可以让攻击者无法使用查表和彩虹表的方式对大量hash进行破解，但是仍然不能阻止攻击者针对单个密码进行暴力和字典攻击，高端的显卡(GPUs)和一些定制的硬件每秒可以计算数十亿的hash。</p><p>为了避免针对单个密码的查表和暴力攻击，可以采用一种称为key扩展(key stretching)的技术。就是让hash的过程便得非常缓慢，即使使用高速GPU和特定的硬件，字典和暴力破解的速度也慢到没有实用价值，通过减慢hash的过程来防御攻击。</p><p>key扩展的实现是使用一种大量消耗cpu资源的hash函数。不要去使用自己创造的迭代hash函数，如果迭代不够多，是可以被高效的硬件快速并行计算出来的。要使用标准算法的hash函数，比如PBKDF2或者bcrypt。这类算法使用一个安全因子或迭代次数作为参数，这个值决定了哈希函数会有多慢。</p><p>同时应注意如果在web应用的服务器中做这类hash计算，密钥扩展也使得网站更容易遭受拒绝服务攻击（DoS）。当然也可以考虑在用户的浏览器运行hash函数，这样将计算量都分摊到了客户端，可以减轻服务器的压力，客户端的密钥扩展并不能免除服务端进行哈希加密的职责，服务器必须对客户端传来的哈希值再次进行哈希加密，就像看待一个普通密码一样，如果客户端不支持JS的时候，服务端应该接手计算。</p><h2 id="慢比较是怎么做的"><a href="#慢比较是怎么做的" class="headerlink" title="慢比较是怎么做的"></a>慢比较是怎么做的</h2><p>『慢比较』代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">slowEquals</span><span class="params">(<span class="keyword">byte</span>[] a, <span class="keyword">byte</span>[] b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> diff = a.length ^ b.length;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; a.length &amp;&amp; i &lt; b.length; i++) &#123;</span><br><span class="line">       diff |= a[i] ^ b[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> diff == <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码里使用异或来比较两个数字，将其应用到整数中每一位，当且仅当字节两个整数各位都相等，结果才是0。所以循环结束后diff是0的话只有一种可能，那就是循环前两个数组长度相等（a.length == b.length），并且数组中每一个字节都相同（每次异或的结果都非0）。</p><p>使用异或而不是”==”来作比较是因为”==”通常会被编译成带有分支的语句，例如C语言中的“diff &amp;= a == b”可能会被编译为如下汇编语言：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">MOV EAX, [A]</span><br><span class="line">CMP [B], EAX</span><br><span class="line">JZ equal</span><br><span class="line">JMP done</span><br><span class="line">equal:</span><br><span class="line">AND [VALID], 1</span><br><span class="line">done:</span><br><span class="line">AND [VALID], 0</span><br></pre></td></tr></table></figure><p>其中的分支导致代码运行的时间不固定，决定于两个整数相等的程度和CPU内部的跳转预测机制。<br>而C语言代码“diff |=a ^ b”会被编译为下面的样子，它执行的时间和两个整数是什么样的情况无关。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MOV EAX, [A]</span><br><span class="line">XOR EAX, [B]</span><br><span class="line">OR [DIFF], EAX</span><br></pre></td></tr></table></figure><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>对密码进行哈希加密的手段，不是为了保护网站免受入侵，而是在入侵已经发生时保护数据库中的用户密码，以免使得危害继续扩散（如果用户在多个网站使用相同的密码，就容易被撞库），至少我们要对用户负责。</p>]]></content>
      
      
      <categories>
          
          <category> 加解密 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 密码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>蓄水池抽样（Reservoir sampling）问题</title>
      <link href="/2016/08/20/Reservoir-Sampling/"/>
      <url>/2016/08/20/Reservoir-Sampling/</url>
      
        <content type="html"><![CDATA[<h3 id="蓄水池抽样"><a href="#蓄水池抽样" class="headerlink" title="蓄水池抽样"></a>蓄水池抽样</h3><p>** 问题：** 给出一个数据流，这个数据流的长度很大或者未知。并且对该数据流中数据只能访问一次。请写出一个随机选择算法，使得数据流中所有数据被选中的概率相等。</p><p><strong>思路：</strong> 解决方案就是蓄水池抽样（reservoir sampling）。主要思想就是保持一个集合作为蓄水池，依次遍历所有数据的时候以一定概率替换这个蓄水池中的数字。</p><p>对这个问题首先从最简单的情况出发：</p><ol><li><p>数据流只有一个数据。直接返回该数据，该数据返回的概率为1。</p></li><li><p>假设数据流里有两个数据。  读到了第一个数据，这次不能直接返回该数据，因为数据流没有结束。继续读取第二个数据，发现数据流结束了。因此只要保证以相同的概率返回第一个或者第二个数据就可以满足题目要求。因此我们生成一个0到1的随机数R,如果R小于0.5就返回第一个数据，如果R大于0.5，返回第二个数据。</p></li><li><p>接着分析有三个数据的数据流的情况。假设流中的数据命名为1、2、3。我们陆续收到了数据1、2和前面的例子一样，只能保存一个数据，所以必须淘汰1和2中的一个。首先按照二分之一的概率淘汰一个，例如淘汰了2。继续读取流中的数据3，发现数据流结束了，我们知道在长度为3的数据流中，如果返回数据3的概率为1/3,那么才有可能保证选择的正确性。也就是说，目前我们手里有1,3两个数据，我们通过一次随机选择，以1/3的概率留下数据3，以2/3的概率留下数据1，那么数据1被最终留下的概率是：</p><p> 数据1被留下：（1/2）*(2/3) = 1/3</p><p> 数据2被留下概率：（1/2）*(2/3) = 1/3</p><p> 数据3被留下概率：1/3</p></li></ol><p>因此结论如下：假设当前正要读取第n个数据，则以1/n的概率留下该数据，否则留下前n-1个数据中的一个。以这种方法选择，所有数据流中数据被选择的概率一样。证明如下：</p><p>假设n-1时候成立，即前n-1个数据被返回的概率都是1/n-1。<br>当前正在读取第n个数据，以1/n的概率返回它。那么前n-1个数据中数据被返回的概率为返回n-1个数据中的一个且第n个数据不被选中，即：(1/(n-1))*((n-1)/n)= 1/n，假设成立。</p><p><strong>问题扩展：</strong>给你一个长度为N的链表。N很大，但你不知道N有多大。你的任务是从这N个元素中随机取出k个元素。你只能遍历这个链表一次。你的算法必须保证取出的元素恰好有k个，且它们是完全随机的（出现概率均等）。<br>这次与上面唯一的不同是：总共需要取k个元素。</p><p><strong>方案：</strong>以1的概率取前k个元素放到蓄水池中，从i=k+1开始，以k/i的概率取第i个元素，若被取，以均等的概率替换先前被取的k个元素。</p><p><strong>证明：</strong>当i=k+1时：第k+1个元素以k/k+1概率被取，前k个元素被取的概率=1 - 被第k+1个元素替换的概率=1-k/(k+1)*1/k=k/(k+1) 符合条件。</p><p>设i=p时符合条件，即前p个元素都以k/p的概率被取。</p><p>则i=p+1时：对第p+1个元素，被取概率为k/(p+1)符合条件。 对于前p个元素，每个元素被取的概率=被取并且没有被第p+1个元素替换的概率= k/p<em>((1-k/(p+1))+k/(p+1)</em>(1-1/k))=k/p+1同样符合条件。</p><p>综上所述：得证。</p><h3 id="分布式蓄水池抽样"><a href="#分布式蓄水池抽样" class="headerlink" title="分布式蓄水池抽样"></a>分布式蓄水池抽样</h3><p>要进行容量为k的分布式蓄水池抽样，使用mapreduce 模拟sql中的ORDER BY RAND (随机抽取)。对于集合中的每一个元素，都产生一个0-1的随机数，之后选取随机值最大的前k个元素。这种方法在对大数据集进行分层抽样的时候非常管用。这里每一个分层都都是一些分类变量如性别，年龄，地理信息等的组合。注意如果输入的数据集分布极端的不均匀，那么抽样可能不能覆盖到所有的层级。</p><h3 id="加权分布式蓄水池抽样"><a href="#加权分布式蓄水池抽样" class="headerlink" title="加权分布式蓄水池抽样"></a>加权分布式蓄水池抽样</h3><p><strong>问题：</strong>集合中的数据是有权重的，算法希望数据被抽样选中的概率和该数据的权重成比例。</p><p><strong>思路：</strong>对于每个数据计算一个0-1的值R，并求r的n次方根作为该数据的新的R值。这里的n就是该数据的权重。最终算法返回前k个R值最高的数据然后返回。根据计算规则，权重越大的数据计算所得的R值越接近1，所以越有可能被返回。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>基于词图的最大概率中文分词方法</title>
      <link href="/2016/07/31/%E5%9F%BA%E4%BA%8E%E8%AF%8D%E5%9B%BE%E7%9A%84%E6%9C%80%E5%A4%A7%E6%A6%82%E7%8E%87%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95/"/>
      <url>/2016/07/31/%E5%9F%BA%E4%BA%8E%E8%AF%8D%E5%9B%BE%E7%9A%84%E6%9C%80%E5%A4%A7%E6%A6%82%E7%8E%87%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id="分词方法分类"><a href="#分词方法分类" class="headerlink" title="分词方法分类"></a>分词方法分类</h2><p>中文分词大致分为三类：</p><ul><li>基于字符串匹配：最大正向匹配法、逆向最大匹配法、最少切分法、双向匹配法等</li><li>基于统计：基于词频度统计的分词方法</li><li>基于规则：基于知识理解，利用神经网络等分词方法</li></ul><h2 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h2><p>基于词图的最大概率分词方法源于概率统计语言模型。<br>从统计思想的角度来看，分词问题的输入是一个字串C=C1,C2,……,Cn，输出是一个词串S=W1,W2,……,Wm，其中m&lt;=n。对于一个特定的字符串C，会有多个切分方案S对应，分词的任务就是在这些S中找出概率最大的一个切分方案，也就是对输入字符串切分出最有可能的词序列。</p><p>$$Seg(c)argmax_{S \epsilon G} P(S|C)=argmax_{S \epsilon G}\frac{P(C|S)P(S)}{P(C)}<br>$$</p><p>例如对于输入『小红马上下来』，切分可能有：</p><ul><li>S1: 小红/马上/下来</li><li>S2: 小红马/上/下来</li><li>S3: 小红马/上下/来</li><li>……</li></ul><p>计算条件概率P(S1|C)，P(S2|C)和P(S3|C)，然后采用概率大的值对应的切分方案。根据贝叶斯公式：</p><p>$$P(S|C)=\frac{P(C|S)P(S)}{P(C)}$$</p><p>其中P(C)是字符串在语料库中出现的概率为一固定值，从词串恢复到汉字串的概率只有唯一的一种方式，所以P(C|S)=1。因此，比较P(S1|C)和P(S2|C)的大小变成比较P(S1)和P(S2)的大小。<br>概率语言模型分词的任务是：在全切分所得的所有结果中求某个切分方案S，使得P(S)最大。为了容易实现，假设每个词之间的概率是上下文无关的。（<strong>注意此处</strong>）</p><p>$$P(S)=P(W_1,W_2,W_3 \ldots)=P(W_1)*P(W_2)* \cdots*P(W_m)$$</p><p>计算任意一个词出现的概率如下：</p><p>$$P(W_i)=\frac{W_i在语料库中出现的次数n_i}{语料库中总词数N}$$</p><h2 id="词典"><a href="#词典" class="headerlink" title="词典"></a>词典</h2><p>词典中存储了词的text，出现次数，词性等信息，结构如下：</p><table><thead><tr><th>词</th><th align="right">出现次数</th><th align="center">词性</th></tr></thead><tbody><tr><td>小红马</td><td align="right">113</td><td align="center">nr</td></tr><tr><td>巴塞尔</td><td align="right">113</td><td align="center">nr</td></tr><tr><td>巴塞爾</td><td align="right">113</td><td align="center">nr</td></tr><tr><td>文明史</td><td align="right">113</td><td align="center">nr</td></tr></tbody></table><p>为了能够快速查找字典采用双数组Trie树来存储，关于Trie树相关内容请自行百度。</p><h2 id="构建词图"><a href="#构建词图" class="headerlink" title="构建词图"></a>构建词图</h2><p>根据字典构建的trie树，扫描待分词句子生成DAG（有向无环图），就是对待分词句子，根据给定的词典进行查词典操作，找出所有可能的句子切分。<br>如果待切分的字符串有m个字符，考虑每个字符左边和右边的位置，则有m+1个点对应，点的编号从0到m。把候选词看成边，可以根据词典生成一个切分词图。例如『小红马上下来』形成的词图如下：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/img/WordSeg.png" alt="WordSeg" title>                </div>                <div class="image-caption">WordSeg</div>            </figure><p>路径1： 0-3-4-6  小红马/上/下来<br>路径2： 0-2-4-6  小红/马上/下来<br>……<br>切分词图中的边都是词典中的词，边的起点和终点分别是词的开始和结束位置。</p><h2 id="计算最大概率"><a href="#计算最大概率" class="headerlink" title="计算最大概率"></a>计算最大概率</h2><p>因为假设每个词之间的概率是上下文无关的，因此满足动态规划求解所要求的最优子结构性质和无后效性。求出值最大的P(Si)后，利用回溯的方法直接输出Si。图用邻接矩阵存储，伪代码如下：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">type</span> Token <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">//分词的字串</span></span><br><span class="line">text []<span class="keyword">byte</span></span><br><span class="line"><span class="comment">//该分词概率</span></span><br><span class="line">Prod <span class="keyword">float32</span></span><br><span class="line"><span class="comment">// 词性标注</span></span><br><span class="line">pos <span class="keyword">string</span></span><br><span class="line"><span class="comment">//分词开始节点的概率</span></span><br><span class="line">PredProd <span class="keyword">float32</span></span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">segmentWords(<span class="keyword">byte</span> []s) []Segment&#123;</span><br><span class="line">    <span class="keyword">for</span> i:=<span class="number">0</span>; i&lt;<span class="built_in">len</span>(s); i++ &#123;</span><br><span class="line">        <span class="comment">// 从Trie树中得到以当前字元开头的所有分词</span></span><br><span class="line">        tokens = dict.getPrev(i)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> j:=<span class="number">0</span>; j&lt;<span class="built_in">len</span>(token); j++ &#123;</span><br><span class="line">            newProd := token[j].PrevProd + token[j].Prod</span><br><span class="line">            <span class="keyword">if</span>(newProd &gt; dis[token.end].prod) &#123;</span><br><span class="line">                dis[token.end].prod = newProd</span><br><span class="line">                dis[token.end].token = token[j]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//从右向左扫描</span></span><br><span class="line">    numSegments := <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> index := <span class="built_in">len</span>(text) - <span class="number">1</span>; index &gt;= <span class="number">0</span>; &#123;</span><br><span class="line"></span><br><span class="line">location := index - <span class="built_in">len</span>(dis[index].token.text) + <span class="number">1</span></span><br><span class="line">numSegments++</span><br><span class="line">index = location - <span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line">output := <span class="built_in">make</span>([]Segment, numSeg)</span><br><span class="line">    <span class="keyword">for</span> index:=<span class="built_in">len</span>(s)<span class="number">-1</span>; index&gt;=<span class="number">0</span>; &#123;</span><br><span class="line">        location := index - <span class="built_in">len</span>(dis[index].token.text) + <span class="number">1</span></span><br><span class="line">numSegments--</span><br><span class="line">output[numSegments].text = dis[index].token.text</span><br><span class="line">index = location - <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从右向左扫描是因为汉语句子的重心经常落在后面，这种扫描方式能提高分词的准确性。</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>该模型有一个前提条件：『假设每个词之间的概率是上下文无关的』，这一点是不严谨的，一句话当中相邻词之间上下文无关很难做到。</p><p>搜索引擎中的中文分词十分复杂，分词的过程中需要考虑：</p><ul><li>切分的正确性</li><li>粒度的合理性</li><li>切分的一致性</li><li>词条关系分析</li><li>词条属性分析  </li><li>歧义词处理</li><li>……</li></ul>]]></content>
      
      
      <categories>
          
          <category> NLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分词 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenSSL</title>
      <link href="/2016/06/19/openssl/"/>
      <url>/2016/06/19/openssl/</url>
      
        <content type="html"><![CDATA[<h3 id="SSL"><a href="#SSL" class="headerlink" title="SSL"></a>SSL</h3><hr><p>SSL 是一个缩写，代表的是 Secure Sockets Layer。它是支持在 Internet 上进行安全通信的标准，并且将数据密码术集成到了协议之中。数据在离开您的计算机之前就已经被加密，然后只有到达它预定的目标后才被解密。证书和密码学算法支持了这一切的运转，如果连接传输敏感信息，则应使用 SSL。</p><h3 id="OpenSSL"><a href="#OpenSSL" class="headerlink" title="OpenSSL"></a>OpenSSL</h3><hr><p>openssl是一个开源程序的套件、这个套件有三个部分组成：</p><ul><li>一是libcryto，这是一个具有通用功能的加密库，里面实现了众多的加密库；</li><li>二是libssl，这个是实现ssl机制的，它是用于实现TLS/SSL的功能；</li><li>三是openssl，是个多功能命令行工具，它可以实现加密解密，甚至还可以当CA来用，可以让你创建证书、吊销证书。</li></ul><p>要获得关于如何使用 OpenSSL 命令行工具的资料，请参阅<a href="https://www.openssl.org/docs/manmaster/apps/openssl.html" target="_blank" rel="noopener">官方手册</a></p><h3 id="密钥、证书请求、证书概要说明"><a href="#密钥、证书请求、证书概要说明" class="headerlink" title="密钥、证书请求、证书概要说明"></a>密钥、证书请求、证书概要说明</h3><hr><p>在申请证书过程中，涉及到密钥，证书请求，证书这几个概念，它们之间的联系是：</p><ul><li>首先，生成客户端的密钥，即客户端的公私钥对，且要保证私钥只有客户端自己拥有。</li><li>然后以客户端的密钥和客户端自身的信息(国家、机构、域名、邮箱等)为输入，生成证书请求文件。其中客户端的公钥和客户端信息是明文保存在证书请求文件中的，而客户端私钥的作用是对客户端公钥及客户端信息做签名，自身是不包含在证书请求中的。然后把证书请求文件发送给CA机构。</li><li>最后CA机构接收到客户端的证书请求文件后，首先校验其签名，然后审核客户端的信息，最后CA机构使用自己的私钥为证书请求文件签名，生成证书文件，下发给客户端。此证书就是客户端的身份证，来表明用户的身份。</li></ul><p>其中，证书签发机构CA，CA是被绝对信任的机构。<br>自签名证书就是自己给自己签发的证书，例如12306网站，它用的自签名证书，以为12306不是浏览器所信任的证书签发机构，所以浏览器会有提示证书有问题，将其的证书导入到电脑中，浏览器就不会报该错误。除非特别相信某个机构，否则不要在机器上随便导入证书，这种做法存在安全风险。</p><h3 id="OpenSSL使用"><a href="#OpenSSL使用" class="headerlink" title="OpenSSL使用"></a>OpenSSL使用</h3><hr><p>生成RSA密钥对。使用DES3加密，密钥使用密码保护，长度为1024，输出到rsaprivatekey.pem</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -des3 -out rsaprivatekey.pem -passout pass:123456 1024</span><br></pre></td></tr></table></figure><p>openssl可以将这个文件中的公钥提取出来:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl rsa -in rsaprivatekey.pem -pubout -out test_pub.key</span><br></pre></td></tr></table></figure><p>当使用-new选取的时候，说明是要生成证书请求，当使用x509选项的时候，说明是要生成自签名证书。</p><p>生成证书请求文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl req -new -key rsaprivatekey.pem -out rsaCertReq.csr</span><br></pre></td></tr></table></figure><p>或者生成1024位RSA密钥，并生成证书请求文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl req -new -newkey rsa:1024 -out rsaCertReq.csr -keyout RSA.pem -batch</span><br></pre></td></tr></table></figure><p>生成自签证书并指定过期时间</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl x509 -req -days 3650 -in rsaCertReq.csr -signkey rsaprivatekey.pem -out rsaCert.crt</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl req -new -x509 -key rsaprivatekey.pem -out rsaprivatekey.cert -days 1095</span><br></pre></td></tr></table></figure><p>证书里有对应的公钥和国家、地区等信息。验证证书：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl verify rsaprivatekey.cert</span><br></pre></td></tr></table></figure><p>从证书中提取公钥：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl x509 -in rsaprivatekey.cert  -noout -pubkey &gt; pubkey.pem</span><br></pre></td></tr></table></figure><p>生成pem结尾的私钥供Java使用:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl pkcs8 -topk8 -inform PEM -outform DER -in ca.key.pem -out ca.private.der -nocrypt</span><br></pre></td></tr></table></figure><h3 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h3><hr><p>产生1024位RSA私匙，用3DES加密它，口令为123456。输出到文件rsaprivatekey_pass.pem：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl genrsa -out rsaprivatekey_pass.pem -passout pass:123456 -des3 1024</span><br></pre></td></tr></table></figure><p>生成证书,days为有效天数，输出证书文件到rsaprivatekey.cert：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl req -new -x509 -key rsaprivatekey_pass.pem -out rsaprivatekey.cert -days 1095 -passin pass:123456</span><br></pre></td></tr></table></figure><p>此证书文件中包含公钥，用于和对方进行公开的交换。</p><p>使用私钥对test.txt文本内容进行数字签名，输出到test.sign</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl rsautl -sign -in test.txt -out test.sign -inkey rsaprivatekey_pass.pem -passin pass:123456</span><br></pre></td></tr></table></figure><p>使用公钥证书对数字签名进行验证，输出到test.vfy，此时test.vfy和test.txt的内容应完全一样:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl rsautl -verify -in test.sig -out test.vfy -inkey rsaprivatekey.cert -certin</span><br></pre></td></tr></table></figure><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><hr><p>这里只是简单介绍了openssl的一些用法，其他内容推荐查看官方文档。</p><p>关于数字签名的详细介绍，推荐[阮一峰的一篇日志][2]<br>[2]:<a href="http://www.ruanyifeng.com/blog/2011/08/what_is_a_digital_signature.html" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2011/08/what_is_a_digital_signature.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> opnessl </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AngularJS中ui-router如何传递参数</title>
      <link href="/2016/04/09/AngularJS%E4%B8%ADui-router%E5%A6%82%E4%BD%95%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0/"/>
      <url>/2016/04/09/AngularJS%E4%B8%ADui-router%E5%A6%82%E4%BD%95%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<p>ui-router是AngualrJS中常用的路由框架。其中ui-sref 一般使用在 a标签中，$state.go(‘someState’)一般使用在controller里面。这两个本质上是一样的东西，查看ui-sref的源码，ui-sref最后调用的还是$state.go()方法。</p><h3 id="如何传递参数"><a href="#如何传递参数" class="headerlink" title="如何传递参数"></a>如何传递参数</h3><p>首先定义路由状态：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">.state(<span class="string">'monitorInstance'</span>, &#123;</span><br><span class="line">   url: <span class="string">"/monitorInstance/:instanceId/:templateId"</span>,</span><br><span class="line">   views: &#123;</span><br><span class="line">    <span class="string">"appContent"</span> :&#123;</span><br><span class="line">       templateUrl: baseUrl +<span class="string">'/tpl/monitorInstance.html'</span>,</span><br><span class="line">       controller: MonitorInstanceCtrl</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>ui-sref传参：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;a ui-sref=<span class="string">"monitorInstance(&#123;instanceId: &#123;&#123;instance.id&#125;&#125;,  templateId: &#123;&#123;instance.template.id&#125;&#125; &#125;)"</span>&gt;</span><br><span class="line">    &lt;span&gt;&#123;&#123;instance.name&#125;&#125;&lt;<span class="regexp">/span&gt;</span></span><br><span class="line"><span class="regexp">&lt;/</span>a&gt;</span><br></pre></td></tr></table></figure><p>$state.go传参：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$state.go(<span class="string">'monitorInstance'</span>, &#123;<span class="attr">instanceId</span>: instance.id, <span class="attr">templateId</span>:instance.template.id&#125;);</span><br></pre></td></tr></table></figure><p>接收参数：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">listInstanceCtrl</span>(<span class="params">$scope,$stateParams,listInstanceServices</span>) </span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log($stateParams.instanceId);</span><br><span class="line">    <span class="built_in">console</span>.log($stateParams.templateId);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AngularJS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go语言的接口</title>
      <link href="/2015/12/02/Go%E8%AF%AD%E8%A8%80%E7%9A%84%E6%8E%A5%E5%8F%A3/"/>
      <url>/2015/12/02/Go%E8%AF%AD%E8%A8%80%E7%9A%84%E6%8E%A5%E5%8F%A3/</url>
      
        <content type="html"><![CDATA[<p>在计算机的世界里，同一类工具不同的实现所体现出背后的哲理也是不一样的，例如 Linux 与 windows，都是操作系统，但是如果用使用windows的习惯去操作Linux是玩不转的。编程语言也一样，对于面向对象不同的语言也同过不同的方式来实现。java不支持类的多重继承，但是可以通过接口的多重继承来弥补。Python干脆在语言层面上就不提供接口这样的特性，所以要想实现接口的效果可以采用继承只有方法空实现的父类并重写父类方法来达到目的。而Go语言提供了更加灵活和抽象的接口特性。</p><p>C++、Java使用的是“侵入式”的接口，即实现类需要显式的声明自己所实现的接口，而Go采用的是“非侵入式”的接口，从语言角度看，接口是一种类型，它指定一个方法集。只要类型T的公开方法完全满足接口I的要求，就可以把类型T的对象用在需要接口I的地方，所谓类型T的公开方法完全满足接口I的要求，也就是如果一个接口里的所有方法都被类型T实现了，那么我们就说该类型实现了该接口。这种做法的学名叫做Structural Typing，有人也把它看作是一种静态的Duck Typing。</p><h2 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h2><p>定义一个接口如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Driver <span class="keyword">interface</span>&#123;</span><br><span class="line">    Drive()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们定义了一个接口Driver，该接口中声明了一个方法Drive，接下来我们看如何定义一个struct来实现该接口。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Person sturct&#123;</span><br><span class="line">    Name stirng</span><br><span class="line">    Car  <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Person)</span> <span class="title">Drive</span><span class="params">()</span></span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">"Drive my"</span>, p.Car)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义了一个方法，该方法的Receiver是Person，并且该方法完全符合接口Driver的要求所以Person就实现了该接口。</p><p>下面我们定义一个方法用来接受任意一个实现Driver接口的类型的值或者指针。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">p := Person&#123;<span class="string">"Grace"</span>, <span class="string">"BMW"</span>&#125;</span><br><span class="line"></span><br><span class="line">DriveCar(p)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">DriveCar</span><span class="params">(d Driver)</span></span> &#123;</span><br><span class="line">d.Drive()</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//OutPut:</span></span><br><span class="line">cannot use p (<span class="keyword">type</span> Person) as <span class="keyword">type</span> Driver in argument to DriveCar:</span><br><span class="line">Person does not implement Driver (Drive method has pointer receiver)</span><br></pre></td></tr></table></figure><p>诶？为什么编译器不考虑值是实现该接口的类型？这就涉及到Go语言规范里的一些规则：</p><ul><li>类型 <code>*T</code>的可调用方法集包含接受者为 <code>*T</code> 或 <code>T</code> 的所有方法集</li></ul><p>这条规则是说如果用来调用特定接口方法的接口变量是一个指针类型，那么方法的接受者可以是值类型也可以是指针类型。显然刚才的例子不符合该规则，因为我们传入 <code>DriveCar</code> 函数的接口变量是一个值类型。</p><ul><li>类型 <code>T</code> 的可调用方法集包含接受者为 <code>T</code> 的所有方法</li></ul><p>这条规则是说如果用来调用特定接口方法的接口变量是一个值类型，那么方法的接受者必须也是值类型该方法才可以被调用。显然上面的例子也不符合这条规则，因为我们 <code>Drive</code> 方法的接受者是一个指针类型。<br>由此可以得出以下结论：</p><ul><li>类型 <code>T</code>的可调用方法集不包含接受者为 <code>*T</code> 的方法</li></ul><p>所以我们只需将Person的地址传给DriveCar即可</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">p := &amp;Person&#123;<span class="string">"Grace"</span>, <span class="string">"BMW"</span>&#125;</span><br><span class="line"></span><br><span class="line">DriveCar(p)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">DriveCar</span><span class="params">(d Driver)</span></span> &#123;</span><br><span class="line">d.Drive()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>类型的指针同样可以调用接受者是值的方法。Go调整和解引用指针使得调用可以被执行。注意，当接受者不是一个指针时，该方法操作对应接受者的值的副本(意思就是即使你使用了指针调用函数，但是函数的接受者是值类型，所以函数内部操作还是对副本的操作，而不是指针操作）</p><h2 id="内嵌类型"><a href="#内嵌类型" class="headerlink" title="内嵌类型"></a>内嵌类型</h2><p>struct中的一个属性为另一个struct即为内嵌，定义一个新类型然后潜入Person：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Manager <span class="keyword">struct</span> &#123;</span><br><span class="line">Person</span><br><span class="line">Age <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种方式是组合而不是集成，现在修改调用方法：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"></span><br><span class="line">m := &amp;Manager&#123;</span><br><span class="line"></span><br><span class="line">Person: Person&#123;</span><br><span class="line">Name: <span class="string">"xiaoming"</span>,</span><br><span class="line">Car:  <span class="string">"BMW"</span>,</span><br><span class="line">&#125;,</span><br><span class="line">Age: <span class="number">22</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DriveCar(m)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//OutPut:</span></span><br><span class="line">Drive my BMW</span><br></pre></td></tr></table></figure><p>解释如下</p><blockquote><p>当我们嵌入一个类型，这个类型的方法就变成了外部类型的方法，但是当它被调用时，方法的接受者是内部类型(嵌入类型)，而非外部类型。— Effective Go</p></blockquote><p>我们可以用 <code>Manager</code> 类型的一个指针来调用 <code>DriveCar</code> 函数。现在 <code>Manager</code> 类型也通过来自嵌入的 <code>Person</code> 类型的方法提升实现了该接口。</p><p>Go 语言中内部类型方法集提升的规则有如下三条：</p><p>给定一个结构体类型<code>S</code>和一个命名为<code>T</code>的类型，方法提升像下面规定的这样被包含在结构体方法集中：</p><ul><li>如果 <code>S</code> 包含一个匿名字段<code>T</code>，<code>S</code>和<code>*S</code>的方法集都包含接受者为T的方法提升。</li></ul><p>意思是当嵌入一个类型时嵌入类型的接受者为值类型的方法将被提升，可以被外部类型的值和指针调用。</p><ul><li>对于 <code>*S</code> 类型的方法集包含接受者为 <code>*T</code> 的方法提升</li></ul><p>这条规则说的是当外部类型使用指针调用内部类型的方法时，只有接受者为指针类型的内部类型方法集将被提升。</p><ul><li>如果 <code>S</code> 包含一个匿名字段 <code>*T</code>，<code>S</code> 和 <code>*S</code> 的方法集都包含接受者为 <code>T</code> 或者 <code>*T</code> 的方法提升</li></ul><p>这条规则说的是嵌入类型的接受者为值类型或指针类型的方法将被提升，可以被外部类型的值或者指针调用。</p><p>所以如果外部类型包含了符合要求的接口实现，它将会被使用。否则，通过方法提升，任何内部类型的接口实现可以直接被外部类型使用。</p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库表空间</title>
      <link href="/2015/08/16/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%A9%BA%E9%97%B4/"/>
      <url>/2015/08/16/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%A9%BA%E9%97%B4/</url>
      
        <content type="html"><![CDATA[<p>数据库表空间允许数据库管理员定义存储数据库对象的文件在文件系统中的位置。一旦创建了表空间，当创建数据库时就可以引用这个表空间。</p><p>通过表空间来控制数据库的磁盘存储位置有一下好处：</p><ol><li>如果数据库初始安装所在的分区或卷耗尽了空间，并且已经无法扩展，可以在另外的分区上面创建和使用一个新的表空间，直到系统重新被配置。</li><li>表空间可以允许管理员根据已知的数据库对象使用模式优化系统性能。比如，将频繁使用的index放在快速高可用的固态硬盘上;将存储很少使用或者对性能要求不高的数据放在廉价低速的磁盘上。</li></ol><p>下面以PostgresSQL为例讲一下表空间的使用。</p><h3 id="创建表空间"><a href="#创建表空间" class="headerlink" title="创建表空间"></a>创建表空间</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLESPACE</span> tablespace_name [ OWNER user_name ] LOCATION <span class="string">'directory'</span>;</span><br></pre></td></tr></table></figure><p>参数</p><ul><li>tablespace_name 表空间的名字，不能以pg_开头，这是为系统表空间保留的。</li><li>user_name 表空间所有者的名字，如果省略，缺省为执行命令的用户。只有数据库超级用户才可以创建表空间</li><li>directory 表空间使用的路径，目录必须是空的，并且owner为PostgreSQL操作系统用户。通常情况PostgreSQL默认安装的系统用户为postgres。目录必须是一个绝对路径。</li></ul><p>注意</p><ul><li>只有支持符号链接的系统才能创建表空间</li><li>CREATE TABLESPACE不能在一个事务块中执行</li></ul><p>示例</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLESPACE</span> ts_mydbspace OWNER testuser LOCATION <span class="string">'/var/data/postgres'</span>;</span><br></pre></td></tr></table></figure><h3 id="使用表空间"><a href="#使用表空间" class="headerlink" title="使用表空间"></a>使用表空间</h3><p>只有数据库超级用户才可以创建表空间，但是创建之后，普通的数据库用户就可以使用它了，只要用户有相应的CREATE权限。比如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> testdb <span class="keyword">TABLESPACE</span> ts_mydbspace;</span><br></pre></td></tr></table></figure><p>设置缺省的表空间参数</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> default_tablespace = ts_mydbspace;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> testdb;</span><br></pre></td></tr></table></figure><p>数据库创建时指定的表空间为其默认表空间，如果没有指定，则其默认表空间与生成该数据库的模板数据库的默认表空间是同一个。</p><h3 id="查看表空间"><a href="#查看表空间" class="headerlink" title="查看表空间"></a>查看表空间</h3><p>当PostgeSQL初始化时，自动创建两个表空间。pg_global用于存储共享的系统目录信息。pg_default是模板数据库template0和template1默认的数据库表空间，也是其他数据库默认的表空间。</p><p>也就是说在执行initdb时，pg的后端（无需经过SQL查询编译）以bootstrap模式执行，在bootstrap模式下，从零开始创建数据库模板template1、创建系统视图、系统表、template0和postgres数据库。template0和postgres数据库都是从template1创建的，这3个都是pg的系统数据库，其中template1在initdb完成之后是可以由用户修改的，template0则始终提供一个未被修改的干净模板。postgres数据库提供一个初始的可供用户连接的数据库。</p><p>由于CREATE DATABASE dbname语句并没有指明数据库模板，所以系统将默认克隆template1数据库，得到新的数据库dbname。（By default, the new database will be created by cloning the standard system database template1）.而template1数据库的默认表空间是pg_default，这个表空间是在数据库初始化时创建的，所以所有template1中的对象将被同步克隆到新的数据库中，新的数据库的表空间也是pg_default。相对完整的语法如下:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> dbname OWNER username <span class="keyword">TEMPLATE</span> template1 <span class="keyword">TABLESPACE</span> tablespacename;</span><br></pre></td></tr></table></figure><p>查看表空间：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">postgres=<span class="comment"># select oid, spcname from pg_tablespace;</span></span><br><span class="line"> oid  |  spcname   </span><br><span class="line"><span class="comment">------+------------</span></span><br><span class="line"> 1663 | pg_default</span><br><span class="line"> 1664 | pg_global</span><br><span class="line">(2 rows)</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">postgres=<span class="comment"># \db</span></span><br><span class="line">       List of tablespaces</span><br><span class="line">    Name    |  Owner   | Location </span><br><span class="line"><span class="comment">------------+----------+----------</span></span><br><span class="line"> pg_default | postgres | </span><br><span class="line"> pg_global  | postgres | </span><br><span class="line">(2 rows)</span><br></pre></td></tr></table></figure><h3 id="PG数据库的文件目录"><a href="#PG数据库的文件目录" class="headerlink" title="PG数据库的文件目录"></a>PG数据库的文件目录</h3><p>PGDATA下的目录，最基本的是base和global。base中放了每个数据的文件，每个数据库会在base目录下有一个以该数据库oid（object id，pg具有面向对象数据库的一些特性，其中的数据库、视图、数据表，甚至某些元组都被作为数据对象管理，每个数据对象有一个唯一oid）命名的子目录。其中命名为1的子目录是pg中的模板数据库template1，pg中的数据库都会以template1作为模板，也就是说template1中的内容会被复制到所有的数据库中。global目录下存放了该实例的共享系统表，如pg_database（存放该实例中所有数据库的元信息）。</p><p>可以通过 查看 pg_database 这张表查看每一个 数据库的 oid</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">postgres=<span class="comment"># select oid , datname from pg_database;</span></span><br><span class="line">  oid  |  datname  </span><br><span class="line"><span class="comment">-------+-----------</span></span><br><span class="line">     1 | template1</span><br><span class="line"> 12067 | template0</span><br><span class="line"> 12072 | postgres</span><br><span class="line"> 16385 | testdb</span><br><span class="line">(4 rows)</span><br></pre></td></tr></table></figure><p>每一张表的数据（大部分）又是放在 base/(dboid)/(relfilenode) 这个文件里面，连接testdb数据库：<code>\c testdb</code>，查看该数据库表信息：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">testdb=<span class="comment"># select relname, relowner, relfilenode from pg_class where relowner = 16384;</span></span><br><span class="line">      relname       | relowner | relfilenode </span><br><span class="line"><span class="comment">--------------------+----------+-------------</span></span><br><span class="line"> book               |    16384 |       16402</span><br><span class="line"> book_pkey          |    16384 |       16405</span><br><span class="line"> hibernate_sequence |    16384 |       16407</span><br><span class="line">(3 rows)</span><br></pre></td></tr></table></figure><p>其中16384是数据库用户的oid。由此可见book这张表的数据存放在<code>base/16385/16402</code>文件中。也可以用 pg_relation_filepath 这个函数查询：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">testdb=<span class="comment"># select pg_relation_filepath('book');</span></span><br><span class="line"> pg_relation_filepath </span><br><span class="line"><span class="comment">----------------------</span></span><br><span class="line"> base/16385/16402</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure><p>数据库中的每张数据表的索引和数据都存放同一个文件中。每张表除了存放数据和索引的文件外，还会有一个_fsm文件(free space map)，其中存放了数据表文件中空闲空间的信息，还有一个_vm文件(visibility map)，标记了数据表文件中哪些文件块没有失效的元组。</p><p>对于数据表文件，pg采取段页式管理方式，每个段的默认大小是1GB。每个段都是一个文件，也就是说，默认配置下，pg中的一个数据表超过1GB时会分为多个1GB大小的文件，第一个段文件名依然是filenode number，第二个段文件是filenode number.1，依此类推。如 24589 24589.1 24589.2。</p><p>对于数据表中的大对象，pg会将其存放在另外的一个TOAST表中，因为大对象不适合与其他属性一起按行存放在段页中。</p>]]></content>
      
      
      <categories>
          
          <category> Database </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PostgreSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库的schema</title>
      <link href="/2015/08/16/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84schema/"/>
      <url>/2015/08/16/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84schema/</url>
      
        <content type="html"><![CDATA[<p>schema是对数据库逻辑的分割，schema隶属于数据库。一个数据库可以包含多个schema。</p><p>schema可以包含多种命名对象，例如：数据类型、函数等。不同的schema中可以包含相同的对象名而不会冲突。</p><p>使用schema的原因主要有：</p><ol><li>允许多个用户使用同一个数据库而互不干扰</li><li>将数据库对象进行逻辑分组，便于管理</li><li>第三方应用放在单独的schema，不与其他对象发生冲突</li></ol><p>下面以PostgresSQL为例说一下schema的使用</p><h3 id="创建schema"><a href="#创建schema" class="headerlink" title="创建schema"></a>创建schema</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">SCHEMA</span> schema_name [ AUTHORIZATION user_name ] [ schema_element [ ... ] ]</span><br></pre></td></tr></table></figure><ul><li>schema_name<br> 将要创建的schema的名字，在当前数据库中schema的名字不能冲突。如果忽略此参数，则以当前数据库用户的名字命名新创建的schema。schema的名字不能以pg_开头，这是系统保留的名字。</li><li>user_name<br> 拥有新创建schema的角色名字，如果不指定则为执行当前命令的数据库用户。</li><li>schema_element<br> 创建schema名字空间下其他对象的SQL语句。与创建schema完毕后执行单独的SQL来创建对象是一样的，除了如果指定AUTHORIZATION,那么新创建的对象都有指定的角色拥有</li></ul><p>每个新建数据库包含一个默认的public模式，数据库中没有指定的schema对象都归属于public schema</p><h3 id="查询schema"><a href="#查询schema" class="headerlink" title="查询schema"></a>查询schema</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">postgres-<span class="comment"># \dn</span></span><br><span class="line">  List of schemas</span><br><span class="line">  Name  |  Owner   </span><br><span class="line"><span class="comment">--------+----------</span></span><br><span class="line"> public | postgres</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure><h3 id="删除schema"><a href="#删除schema" class="headerlink" title="删除schema"></a>删除schema</h3><p>如果schema已经为空对象，可以用一下语句删除schema</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">SCHEMA</span> myschema;</span><br></pre></td></tr></table></figure><h3 id="schema搜索路径"><a href="#schema搜索路径" class="headerlink" title="schema搜索路径"></a>schema搜索路径</h3><p>全限定的名字写起来十分冗长，系统通过一个搜索路径来决定到底使用的是哪一张表，搜索路径是schema的一个列表。搜索路径中第一个匹配的表即是要访问的表。如果搜索路径中没有匹配，会报告一个错误，即使在数据库的其他schema中有相匹配的表。</p><p>查看当前额搜索路径：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">postgres=<span class="comment"># SHOW search_path;</span></span><br><span class="line">  search_path   </span><br><span class="line"><span class="comment">----------------</span></span><br><span class="line"> "$user",public</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure><p>默认情况下，搜索路径的第一个schema是与当前用户同名的schema,第二个则是public schema。</p><p>可以这样设置搜索路径：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> search_path <span class="keyword">TO</span> myschema,<span class="keyword">public</span>;</span><br></pre></td></tr></table></figure><p><strong>官方建议是这样的：</strong>在管理员创建一个具体数据库后，应该为所有可以连接到该数据库的用户分别创建一个与用户名相同的模式，然后，将search_path设置为”$user”，这样，任何当某个用户连接上来后，会默认将查找或者定义的对象都定位到与之同名的模式中。这是一个好的设计架构。</p><p>默认情况下，用户不能访问不属于他的schema中的任何对象。要允许访问，schema的拥有者必须授予用户在这个schema上的USAGE权限。不同访问权限需要不同的授权。</p><h3 id="System-Catalog-Schema"><a href="#System-Catalog-Schema" class="headerlink" title="System Catalog Schema"></a>System Catalog Schema</h3><ul><li>如果不创建任何schema，则所有用户隐式的使用public schema。这等同于不使用schema。这在数据库中只有一个或者极少的用户时推荐使用。</li><li>可以为每一个用户创建一个与其用户名相同的schema。如果每个用户有一个与其名字相同的单独的schema，则默认他们只能访问自己所属的schema。使用这种schema范式，可以撤销掉对public schema的访问许可，甚至把public schema直接移除，这样每个用户就真正的限定在了他们自己的schema里</li></ul>]]></content>
      
      
      <categories>
          
          <category> Database </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PostgreSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于前后端分离的一些想法</title>
      <link href="/2015/07/30/%E5%85%B3%E4%BA%8E%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E7%9A%84%E4%B8%80%E4%BA%9B%E6%83%B3%E6%B3%95/"/>
      <url>/2015/07/30/%E5%85%B3%E4%BA%8E%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E7%9A%84%E4%B8%80%E4%BA%9B%E6%83%B3%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h3 id="为什么要前端分离？"><a href="#为什么要前端分离？" class="headerlink" title="为什么要前端分离？"></a>为什么要前端分离？</h3><p>　　伴随着软件行业的快速发展，其所涉及到的方方面面的技术也越来越细分和专业化。从各公司的招聘信息便可见一斑，例如：前端工程师、算法工程师、java工程师等。</p><p>　　除此之外，当下的Web系统开发模式跟以往已经有了很大的不同，早期的Web项目是一个封闭的项目，用户从浏览器里看到的页面直到后台数据库都是在一个项目里集成。而现在Web系统的规模越来越大，其架构也发生了变化，大型的Web系统可能会是一个分布式、开放式的系统。数据的请求可能不会直接请求数据库，而是访问的缓存服务器，这些基本都是服务端的变化。如果依旧按照之前前后端耦合度很高的项目结构来构建系统，因其后端服务的复杂度的提升必然带来了Web前端的复杂度的提升。</p><p>　　B端和S端从技术体系角度而言异构性很大，不适于同一个体系，将前后端放到一起很难做到专业分工，如果项目开发过程中管控不到位，就有可能会影响到整个项目的开发质量。因此Web前端从系统架构的角度也需要更加专业的管控，管控的作用之一就是前后端进行分离，降低前端对服务端的依耐性，做到专业化分工，提高项目的质量和开发效率。</p><p>　　各类用于web开发的语言都有自己的MVC框架，例如java就有Struts、SpringMVC等MVC框架。像这样的框架实际上做了太多的浏览器就可以完成的工作，例如：页面渲染。这也就限制了web前端技术的深入运用，很多的前端优化技术和提升用户体验的技术就很难派上用场。尽管MVC中的View层是想把界面开发工作专业化，让界面设计人员能专心于界面开发，但是传统的MVC框架下的View层的本质却是一个服务端技术。例如，java的web开发中的jsp，全称为Java Server Pages.其根本是一个简化的Servlet设计，它是java里动态网页的技术标准，这就说明jsp虽然看起来像html，其实它并不是真正的html，它需要被java的web容器进行解析转化为浏览器可以解析的html页面，然后通过网络传输到浏览器后，浏览器才能正确的展示这个jsp页面。我们使用它时候就是让web前端技术被服务端技术所绑架，这也就是为什么每个招聘web前端工程师的岗位都要问你是否会java，php语言的源头。随着互联网的发展，我们需要web前端更高的专业化，而不希望web前端工程师被服务端技术束缚的更多而限制了自身能力的发展，这就导致前后端分离技术的出现。</p><h3 id="什么是前后端分离？"><a href="#什么是前后端分离？" class="headerlink" title="什么是前后端分离？"></a>什么是前后端分离？</h3><p>　　所谓的前后端分离，其主要关注的重点就是页面的渲染工作。之前后端渲染好页面交给前端来显示。前后端分离后拼装html及页面渲染的事情完全交由前端来负责。后端只负责数据的处理。</p><h3 id="如何做到前后端分离？"><a href="#如何做到前后端分离？" class="headerlink" title="如何做到前后端分离？"></a>如何做到前后端分离？</h3><p>　　前面提到服务器端抢了许多前端做的事，我们需要的不是一个服务器端的MVC框架也不是一个前端的MVC框架，我们要的是一个总体的MVC，是一个传统web项目中MVC模式的进一步演进。控制层是前端和服务端的交互边界。因此要前后端解耦就要划清控制层的边界。我们看一下控制层主要做什么工作：</p><ol><li>控制路由，找到具体的模型层处理请求</li><li>http报文信息格式转换</li><li>参与页面渲染工作</li></ol><p>　　在MVC模式里控制层作用是调度而不是写业务逻辑的地方，控制层是前端和服务端通讯的桥梁，其实控制层是参入了前端的工作任务，既然控制层不做具体的业务逻辑实现并且涉及到了页面渲染，那么将控制层归为前端的一部分是合理的。<br>   要实现前后分离要做到以下几点：</p><h4 id="1-前端静态化"><a href="#1-前端静态化" class="headerlink" title="1. 前端静态化"></a>1. 前端静态化</h4><p>　　前端有且仅有静态内容，只有HTML/CSS/JS. 其内容来自于完全静态的资源而不需要任何后台技术进行动态化组装。前端内容的运行环境和引擎完全基于浏览器本身。</p><h4 id="2-后端数据化"><a href="#2-后端数据化" class="headerlink" title="2.后端数据化"></a>2.后端数据化</h4><p>　　后端可以用任何语言、技术和平台实现，但它们必须遵循一个原则：只提供数据，不提供任何和界面表现有关的内容。后台提供的数据可以用于任何其他客户端无论是本地化程序还是web程序、移动端程序。前后端通过后端实现符合RESTful风格的接口和交互Json数据来进行交互。</p><h4 id="3-工程-架构分离化"><a href="#3-工程-架构分离化" class="headerlink" title="3.工程/架构分离化"></a>3.工程/架构分离化</h4><p>　　前后端分离的终极目标应该是前端和服务端是完全独立的项目，由于前台是纯静态内容，大型构架方面可以考虑使用CDN。后端的RESTful Api方面可以考虑负载均衡。而数据,业务实现等可以考虑数据库优化和分布式缓存等。</p><hr><p>　　随着前端开发技术难度的越来越高，前端工程师也成为一个独立的技术岗位。而nodejs的出现更加促进了前后端的分离，node.js是出现在前端技术和服务端技术鸿沟之上的一座桥梁，为前后端两套不同技术体系进行真正意义的解耦提供了无限的可能性。前后端的分离就是不要让前端工程师被一些不可控的外在因素所影响（例如：前后端的耦合性），最后导致前端不能专心致志做出更加好的作品。所以，前后端分离是让前后端更加专业化一条必由之路。</p><p>　　前后分离以后，前后端的集成、部署、调试、服务间的相互调用都是我们要考虑的问题。</p><h2 id="所以，问题来了：前后端分离了，然后呢？"><a href="#所以，问题来了：前后端分离了，然后呢？" class="headerlink" title="所以，问题来了：前后端分离了，然后呢？"></a>所以，问题来了：前后端分离了，然后呢？</h2>]]></content>
      
      
      <categories>
          
          <category> 系统设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Architecture &amp; Design </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello SingleX</title>
      <link href="/2015/06/27/HelloSingle/"/>
      <url>/2015/06/27/HelloSingle/</url>
      
        <content type="html"><![CDATA[<p><strong>用Hexo搭建博客完毕，以后会将博客慢慢迁移至此。</strong><br><strong>感谢GitHub，感谢Hexo！</strong><br><strong>Hello SingleX!</strong></p>]]></content>
      
      
      <categories>
          
          <category> archives </category>
          
      </categories>
      
      
        <tags>
            
            <tag> single </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
